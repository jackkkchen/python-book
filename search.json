[
  {
    "objectID": "index.html#文档目录",
    "href": "index.html#文档目录",
    "title": "Python新手文档",
    "section": "文档目录",
    "text": "文档目录\n\nPython简介\n\nPython的特点和应用领域\n安装Python和开发环境\nPython基础知识\n\n\n\n数据类型和变量\n\n运算符和表达式\n条件语句和循环\n函数和模块\n数据处理与分析入门\n\n\n\nPandas 基本操作\n\nPandas库介绍和安装\nPandas处理什么样的数据\n读取和写入\n选取和筛选\n增删和排序\n分组和聚合\n处理时间序列数据\n处理文本数据\n数据可视化\n\n\n\nPandas 实际应用案例\n\n从实际数据集中读取数据\n数据清洗和预处理\nPlotly可视化展示\nDash应用程序展示\n扩展学习资源\n\n\n\n推荐的Pandas学习资源\n\npandas官方文档(自译版)\nPandas对比SQL\nPlotly可视化官方文档\nW3schools for Pandas\n JackB站超级多的视频"
  },
  {
    "objectID": "index.html#结语",
    "href": "index.html#结语",
    "title": "Python新手文档",
    "section": "结语",
    "text": "结语\n通过本文的学习，你将建立起对Python编程语言的基本理解，掌握Pandas库进行数据处理和分析的技能。无论你是想进入数据科学领域、进行数据挖掘，还是对数据处理和分析有兴趣，Python和Pandas都是你的理想选择。开始你的编程之旅吧，让Python和Pandas帮助你实现数据的无限可能！\n\n\n\n\n\n\nNote\n\n\n\n本文档主要针对编程小白，将以简洁易懂的语言和实例进行解释。每个主题都会提供充足的示例代码和实践案例，以便读者能够实际运用所学知识。在学习过程中，不断实践和探索将是提高编程能力的关键，鼓励读者积极动手并勇于尝试。"
  },
  {
    "objectID": "intro.html#主要特点",
    "href": "intro.html#主要特点",
    "title": "Python简介",
    "section": "主要特点",
    "text": "主要特点\nPython是一种高级编程语言，以其简洁、易读、易学和灵活性而受到广泛欢迎。以下是Python的一些主要特点：\n\n简洁易读：Python采用清晰简洁的语法，使得代码易于阅读和理解。它使用缩进来表示代码块，而不是使用大括号，这使得代码更加易读。\n易学性：Python的语法简单明了，相对于其他编程语言来说，学习曲线较低。这使得初学者能够快速入门并开始编写实用的程序。\n跨平台性：Python可以在多个操作系统上运行，包括Windows、macOS和各种Linux发行版。这意味着开发人员可以在不同的平台上编写一次代码，并在不同的环境中运行。\n大量的库和框架：Python拥有庞大且活跃的社区，为各种用途提供了大量的库和框架。这些库和框架使得开发人员能够快速构建各种应用，例如Web应用、科学计算、数据分析和人工智能等。\n可扩展性：Python可以与其他语言（如C/C++和Java）轻松集成，这使得开发人员能够使用现有的代码库和资源，以提高应用程序的性能和功能。"
  },
  {
    "objectID": "intro.html#应用领域",
    "href": "intro.html#应用领域",
    "title": "Python简介",
    "section": "应用领域",
    "text": "应用领域\nPython具有广泛的应用领域，从Web开发到科学计算和人工智能等各种领域都能发挥其优势。它的简洁性和强大的库生态系统使得开发人员能够快速构建各种类型的应用程序。\n\nWeb开发：Python的Web框架（如Django和Flask）使得构建功能强大的Web应用程序变得简单。Python还可以用于服务器端编程、网页爬虫和API开发等。\n数据科学和机器学习：Python在数据科学和机器学习领域非常受欢迎。它提供了许多用于数据处理、数据可视化和机器学习算法的库，如NumPy、Pandas、Matplotlib、Scikit-learn和TensorFlow等。\n科学计算：Python在科学计算领域也得到广泛应用。科学计算库如NumPy和SciPy提供了许多数值计算、优化和统计分析的功能，适用于物理学、数学、生物学等领域。\n自动化和脚本编写：Python的简洁性和易用性使得它成为自动化任务和脚本编写的理想选择。可以使用Python编写脚本来自动执行重复性的任务、处理文件、操作系统和网络等。\n游戏开发：Python也可以用于游戏开发。有一些专门的库和框架，如Pygame，使得使用Python编写2D游戏变得相对容易。"
  },
  {
    "objectID": "周一环境搭建.html#anaconda环境安装强烈推荐",
    "href": "周一环境搭建.html#anaconda环境安装强烈推荐",
    "title": "1  Python环境搭建",
    "section": "Anaconda环境安装（强烈推荐）",
    "text": "Anaconda环境安装（强烈推荐）\n强烈推荐小白使用Anaconda平台学习Python。\nAnaconda提供了简化环境配置、跨平台支持、库和工具管理以及丰富的科学计算库等优势，使得小白学习Python更加便捷和高效。它是一个功能强大且易于使用的平台，可以帮助您快速入门Python编程并进行数据处理和分析。\n官方免费提供在线编辑器-jupyterlab 无需手动安装环境，即可直接上手编写代码。\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nAnaconda的安装路径和用户名最好使用英文"
  },
  {
    "objectID": "周一环境搭建.html#plotly",
    "href": "周一环境搭建.html#plotly",
    "title": "1  Python环境搭建",
    "section": "Plotly",
    "text": "Plotly\nPlotly是一种用于创建交互式可视化的开源Python图形库，它提供了丰富的图表类型和功能，可以生成高质量、可交互的图形，用于数据分析和呈现。 Plotly支持的图表类型有很多，包括我们常用的散点图、线图、条形图、面积图、箱线图等等。在使用Plotly的过程中，我们可以通过选择合适的图表类型进行数据可视化。另外，Plotly提供了强大的交互式功能，用户可以通过鼠标交互、缩放、平移等操作来和图标进行交互。同时，我们还可以通过添加悬停提示信息、点击事件和自定义工具栏等交互元素，增强用户体验。 由于Plotly可以和Python中的各种数据分析和科学计算库(如NumPy、Pandas等)无缝集成，因此，在使用Python进行数据可视化工作的进程中，Plotly可以很好地帮助到我们。\n在后面的课程中，我们会详细介绍Plotly的相关内容，现在，让我们一起来看看Plotly可以实现的效果吧。\n\n使用conda安装Plotly\n如果你的电脑上安装了Anaconda，那么我们可以使用conda来安装Plotly。打开终端或者Jupyter文件，输入以下代码\nconda install -c plotly plotly\n这将从Anaconda的默认渠道安装Plotly。\n\n\n使用pip安装Plotly\n如果您的电脑上没有安装Anaconda，您也可以使用pip来安装Plotly。打开终端以后，输入以下代码\npip install plotly\n\n\n验证安装\n安装完成以后，可以使用以下命令来验证是否成功安装了Plotly\npip show plotly\n如果成功安装，这行代码将为我们显示Plotly的版本号。 在安装完成以后，您就可以在Python中使用Plotly来创建交互式可视化图表了。另外，在使用Plotly时，通常还需要安装Pandas或numpy，我们将在后面的章节中带领您安装。\nplotly.express官方介绍可以先本地尝试下官方给的案例～\n\n\n1. Lines on Maps\n\n\n\n\n\n\nWarning\n\n\n\nplotly在本地运行无法显示图片的话，可以尝试直接使用fig.show()，去掉renderer=\"notebook\"\n\n\n\nimport plotly.express as px\ndf = px.data.gapminder().query(\"year == 2007\")\nfig = px.line_geo(df, locations=\"iso_alpha\",\n                  color=\"continent\", # \"continent\" is one of the columns of gapminder\n                  projection=\"orthographic\")\nfig.show(renderer=\"notebook\")\n\n\n                                                \n\n\n\n\n2. Funnel Chart\n\nfrom plotly import graph_objects as go\n\nfig = go.Figure(go.Funnel(\n    y = [\"Website visit\", \"Downloads\", \"Potential customers\", \"Requested price\", \"Finalized\"],\n    x = [39, 27.4, 20.6, 11, 2],\n    textposition = \"inside\",\n    textinfo = \"value+percent initial\",\n    opacity = 0.65, marker = {\"color\": [\"deepskyblue\", \"lightsalmon\", \"tan\", \"teal\", \"silver\"],\n    \"line\": {\"width\": [4, 2, 2, 3, 1, 1], \"color\": [\"wheat\", \"wheat\", \"blue\", \"wheat\", \"wheat\"]}},\n    connector = {\"line\": {\"color\": \"royalblue\", \"dash\": \"dot\", \"width\": 3}})\n    )\n\nfig.show(renderer=\"notebook\")\n\n\n                                                \n\n\n\n\n3. Scatter Plots\n\nimport plotly.express as px\n\ndf = px.data.iris()\nfig = px.scatter(df, x=\"sepal_width\", y=\"sepal_length\", color='petal_length')\nfig.show(renderer=\"notebook\")"
  },
  {
    "objectID": "周一基础语法.html#如何使用python",
    "href": "周一基础语法.html#如何使用python",
    "title": "2  Python基础语法",
    "section": "如何使用Python",
    "text": "如何使用Python\n\n运行python文件\n\n\n\n\nPython文件的后缀为 .py\n\n\n\n在代码编辑器中输入python指令\n比如在jupyterlab，在终端或者vscode中输入代码\n如图，Shift + Enter执行代码块\n\n\n\n\n\n\n\nNote\n\n\n\n在终端中，输入python进入python解释器后，即可运行python代码\n\n\n\n\n如何运行ipynb文件\n\n从微信中下载每日作业\n使用JupyterLab打开文件\n\n\n\n\n\n我们可以写一个简单的表达式，在编程中，表达式是一段产生值的代码，类似计算机功能，例如\n\n2023 + 4090\n\n6113\n\n\n除了输出值外，还有另外一种表达式，比如查看是否 9 大于 1？\n\n9 &gt; 1\n\nTrue\n\n\n上面这个表达式对9和1的大小进行了判断。因为9 &gt; 1，所以，程序返回了True；反之，如果我们编写1 &gt; 9，则会返回False。在这里，True和False统称为布尔值，在之后的数据类型课程中，我们会详细地对其进行介绍。\n写代码总少不了报错。假如我的是空值呢？\n\n9 &gt; \n\nSyntaxError: invalid syntax (1639543893.py, line 1)\n\n\n我们进行了一个比较运算，但是只填入了一个值。这时 程序就报错了。终端里显示我们的代码出现了一个语法错误，报错提示中的SyntaxError在编程中代表着语法错误。就像自然语言中的语法一样，Python作为一门编程语言，也具有自己的语法。在接下来的日子里，我们会带你详细学习。"
  },
  {
    "objectID": "周一基础语法.html#变量赋值",
    "href": "周一基础语法.html#变量赋值",
    "title": "2  Python基础语法",
    "section": "变量赋值",
    "text": "变量赋值\n在Python中，变量用于存储和表示数据。变量赋值是将一个值与一个变量关联起来的过程。通过变量，我们可以在程序中存储和操作数据。\n\n变量的命名规则\n在Python中，变量的命名需要遵循以下规则：\n\n变量名只能包含字母（大小写敏感）、数字和下划线（_）。\n变量名不能以数字开头。\n变量名不能使用Python关键字和保留字，如if、for、while等。\n变量名应具有描述性，能够清晰地表示变量的含义。\n\n\n\n变量的赋值\n在Python中，使用等号（=）进行变量赋值操作。等号 ( = ) 运算符左边是一个变量名,等号 ( = ) 运算符右边是存储在变量中的值\n\n\n\n\n下面是一个例子，将数字5赋值给变量x：\n\nx = 5\n\n\n\n变量的使用\n一旦变量被赋值，我们可以在程序中使用它来表示和操作存储的值。\n下面是一个例子，使用变量x计算其平方并打印结果：\n\nx = 5\nsquare = x * x\nprint(square)\n\n25\n\n\n\n\n变量的重新赋值\n在程序中，我们可以多次为同一个变量赋值，新的赋值将覆盖之前的值。\n下面是一个例子，演示变量的重新赋值：\n\nx = 5\nprint(x)  # 输出：5\n\nx = 10\nprint(x)  # 输出：10\n\n题型一\n将字符串”Hello, Python!“赋值给变量message，然后打印出变量的值。\n\nmessage = \"Hello, Python!\"\nprint(message)\n\nHello, Python!\n\n\n题型二 将变量的值用于字符串拼接，使用input()函数接收输入值，然后使用f string，将这变量的值拼接到一句话中。最后，通过print()函数将句子打印输出。\nf string的用法是，在字符串中，需要引入变量值的位置写上一对大括号，将要引入的变量名放在打括号中，用法举例：\n\n# 用户输入姓名和年龄\nname = input(\"请输入您的姓名：\")\nage = input(\"请输入您的年龄：\")\n\n# 创建自我介绍的句子并打印输出\nintroduction = f\"我的名字是{name}，今年{age}岁。\"\nprint(introduction)\n\n我的名字是Jack，今年18岁。\n\n\n另外一种字符串的格式化方式\nf string 和 .format是两种不同的格式化字符串的方法\n.format的用法是在字符串中使用大括号占位，然后使用.format给出要填进去的变量，默认按照顺序填入，如果需要乱序或者一个变量使用多次，需要在大括号中给出后面format变量的序号，举例：\n\nname1 = \"apple\"\nname2 = \"orange\"\nprint(\"I hava a {} and {}.\".format(name1,name2))\n\nprint(\"I hava a {}, {} and {}.\".format(name1,name1,name2))\n\nI hava a apple and orange.\nI hava a apple, apple and orange."
  },
  {
    "objectID": "周一基础语法.html#注释",
    "href": "周一基础语法.html#注释",
    "title": "2  Python基础语法",
    "section": "注释",
    "text": "注释\n在Python中，注释用于对代码进行解释和说明，对于其他人（包括自己）来理解代码的作用和意图非常有帮助。注释是在代码中添加的文本，Python解释器会忽略它们。\n\n单行注释\n在Python中，使用#符号开始的文本被视为单行注释。在#后面的所有内容都被视为注释，不会被执行。\n下面是一个例子，演示如何使用单行注释：\n\n# 这是一个单行注释\nprint(\"Hello, World!\")  # 打印输出文本\n\nHello, World!\n\n\n上述代码中，第一行是一个注释，用于对代码的目的进行解释。第二行是打印输出语句，不受注释的影响。\n\n\n多行注释\n在Python中，使用三个引号（双引号或单引号都可以）包围的文本被视为多行注释。多行注释可以跨越多行，并且可以包含多个段落。\n下面是一个例子，演示如何使用多行注释：\n\n\"\"\"\n这是一个多行注释的示例。\n它可以跨越多行，并且可以包含多个段落。\n\n以下是代码的主要功能：\n- 输入用户的姓名\n- 打印欢迎消息和姓名\n\"\"\"\n\nname = input(\"请输入您的姓名：\")\nprint(\"欢迎，\" + name + \"!\")\n\n欢迎，jack!\n\n\n\n\n\n\n\n\nNote\n\n\n\n如果想一次性注释多行的话，鼠标选取后，按ctl+/进行注释"
  },
  {
    "objectID": "周一基础语法.html#行和缩进",
    "href": "周一基础语法.html#行和缩进",
    "title": "2  Python基础语法",
    "section": "行和缩进",
    "text": "行和缩进\n在Python中，行用于分隔不同的代码语句，而缩进用于表示代码块（例如条件语句、循环等）的范围。\n\n行\n每一行都包含一个完整的代码语句或表达式。下面是一个例子：\n\nprint(\"Hello, world!\")\n\nHello, world!\n\n\n上述代码中，print(“Hello, world!”)是一行代码，用于输出字符串”Hello, world!“。\n\n\n缩进\n在Python中，缩进通过空格或制表符来实现，用于表示代码块的开始和结束。通常使用4个空格作为标准缩进。\n\n\n\n\n\n\nWarning\n\n\n\n缩进造成的错误，应该名列 Python 错误榜第一\n\n\n下面是一个例子，演示如何在代码块中使用缩进：\n\n if x&gt;0:\n    print(\"x是正数\")\n    print(\"干得漂亮！\")\nelse:\n    print (\"x是负数\")\n    print (\"可惜哇嗷！\") \n\nx是正数\n干得漂亮！\n\n\n上述代码中，if语句和else语句是两个代码块，它们的范围由缩进表示。在if代码块中，两个print语句都会在条件满足时执行。在else代码块中，同样有两个print语句。（大家可以自己修改下x范围）\n\n\n\n\n\n\nNote\n\n\n\n养成良好编码习惯：\n\n保持一致的缩进：使用相同数量的空格或制表符进行缩进，并在整个代码中保持一致。这有助于提高代码的可读性；\n使用合适的缩进级别：根据代码逻辑嵌套关系，选择适当的缩进级别。通常建议每个缩进级别使用4个空格；\n使用注释：在关键地方添加注释，解释代码的目的和功能。注释可以提高代码的可读性和可维护性；\n注意行的长度：尽量将每行代码控制在适当的长度范围内，通常推荐不超过80个字符。可以使用换行符（）或括号来换行。\n\n\n\n\n\n多行语句\n\n使用反斜杠\n使用反斜杠（\\）将一行代码分成多行。下面是一个例子：\n\ntotal = 1 + \\\n        2 * \\\n        3\nprint(total)\n\n7\n\n\n上述代码中，total变量的值是1+2*3，通过使用反斜杠在多行中编写，使代码更易读。\n\n\n使用括号\n另一种方式是使用括号（圆括号、方括号、花括号）来隔行编写多行语句。下面是一个例子：\n\ntotal = (1 +\n         2 *\n         3)\nprint(total)\n\n7"
  },
  {
    "objectID": "周二数据类型.html#数据类型",
    "href": "周二数据类型.html#数据类型",
    "title": "3  Python数据类型",
    "section": "数据类型",
    "text": "数据类型\n在Python中，有多种内置的数据类型，每种类型都用于存储不同类型的数据。了解和正确使用这些数据类型对于编写有效的Python代码非常重要。\nPython有以下基本数据类型：\n\n整数（int）：如 1, 2, 3\n浮点数（float）：如 1.5, 3.14\n字符串（str）：如 “hello” 或者 ‘world !’\n布尔值（bool）：True, False\n\n\n\n\n\n\n\nNote\n\n\n\n使用 type() 函数来查看数据结构的类型\n\n\n\n数字类型\n数字类型用于表示数值数据，包括整数（int）和浮点数（float）。\n下面是一个例子，演示如何使用数字类型：\n\n# 整数类型（没有小数点的数字）\nnum1 = 10\nprint(num1) \n\n10\n\n\n\ntype(num1)\n\nint\n\n\n\n# 浮点数类型（带小数点的数字）\nnum2 = 3.14\nprint(num2)  \n\n3.14\n\n\n\n\n字符串类型\n字符串类型用于表示文本数据，使用引号（单引号或双引号）括起来。\n下面是一个例子，演示如何使用字符串类型：\n\nintro = \"你好，我叫 Jack !\"\nprint(intro)  \n\n你好，我叫 Jack !\n\n\n\n\n布尔类型\n布尔类型用于表示真（True）和假（False）的值。\n下面是一个例子，演示如何使用布尔类型：\n\nis_active = True\nprint(is_active)  \n\nTrue\n\n\n\nis_student = False\nprint(is_student) \n\nFalse"
  },
  {
    "objectID": "周二数据类型.html#运算符",
    "href": "周二数据类型.html#运算符",
    "title": "3  Python数据类型",
    "section": "运算符",
    "text": "运算符\n当提到Python的运算符，可以包括算术运算符、赋值运算符、比较运算符、逻辑运算符和位运算符等。下面是一些常见的运算符示例及其解析：\n\n算术运算符\n比较常见的算术运算符，也就是加减乘除这些。\n\n\n\n运算符\n描述\n举例\n\n\n\n\nx+y\n加\n1+2=3\n\n\nx-y\n减\n6-5=1\n\n\nx*y\n乘\n2*3=6\n\n\nx/y\n除\n2/4=0.5\n\n\nx//y\n整除，取整数部分\n2//4=0\n\n\nx%y\n取余\n15%4=3\n\n\n**\n幂运算\n2**3=8 二的三次方\n\n\n\n\na = 10\nb = 3\n\n# 加法\nresult = a + b * (a // b) \nprint(result)  \n\n19\n\n\n\n\n赋值运算符\n在加减乘除的基础上直接进行赋值计算，不需要新的变量\n\n\n\n运算符\n描述\n举例\n\n\n\n\n=\n赋值\nx = 5\n\n\n+=\n加等\nx += 3\n\n\n-=\n减等\nx -= 3\n\n\n*=\n乘等\nx *= 3\n\n\n%=\n余等\nx %= 3\n\n\n/=\n除等\nx /= 3\n\n\n//=\n取整等\nx //= 3\n\n\n**=\n幂等\nx **= 3\n\n\n\n\na = 10\nb = 3\n\n# 加法赋值\na += b \nprint(a)  \n\n13\n\n\n\n\n比较运算符（控制结构判断）\n输出为布尔值\n\n\n\n运算符\n描述\n\n\n\n\n&lt;\n小于\n\n\n&lt;=\n小于等于\n\n\n&gt;\n大于\n\n\n&gt;=\n大于等于\n\n\n==\n等于\n\n\n!=\n不等于\n\n\n\n\na = 10\nb = 3\n\n# 相等比较\nresult = a == b\nprint(result)  \n\nFalse\n\n\n\n\n标识运算符\n标识运算符用于比较对象，不是比较它们是否相等，而是比较它们是否实际上是相同的对象，具有相同的内存位置：\n\n\n\n运算符\n描述\n举例\n\n\n\n\nis\n判断两个标识符是不是引用自一个对象\nx is y\n\n\nis not\n判断两个标识符是不是引用自不同对象\nx is not y\n\n\n\n\n\n逻辑运算符\n逻辑运算符用于在布尔表达式中组合和比较逻辑条件。Python中的逻辑运算符包括以下三种：and（与）、or（或）和not（非）。\n\n\n\n\n\n\n\n\n运算符\n描述\n备注\n\n\n\n\nx and y\n如果两个声明都是真的，则返回True\nxy都为True,结果为True；否则为False\n\n\nx or y\n如果其中一个语句为真，则返回真\nxy都为False,结果为False；否则为True\n\n\nnot x\n反转结果，如果结果为真，则返回False\nx为True时，值为False；x为False时，值为True\n\n\n\n\n逻辑 与（and）运算符：\n逻辑与运算符返回两个操作数都为True时的结果为True，否则返回False。\n\nx = True\ny = False\n\n# 与运算\nresult = x and y\nprint(result)\n\nFalse\n\n\n这里可能比较难理解，在上面的示例中，x的值为True，y的值为False。当使用逻辑与运算符（and）将x和y进行运算时，由于y为False，所以结果为False。如果x和y都为True，则结果为True。\n\n\n逻辑或（or）运算符\n逻辑或运算符返回两个操作数中至少一个为True时的结果为True，只有当两个操作数都为False时结果才为False。\n\na = True\nb = False\n\nresult = a or b\nprint(result)  \n\nTrue\n\n\n\n\n逻辑非（not）运算符\n逻辑非运算符将操作数的值取反，如果操作数为True，则结果为False；如果操作数为False，则结果为True。\n\na = True\n\nresult = not a\nprint(result) \n\nFalse"
  },
  {
    "objectID": "周二数据类型.html#数据结构",
    "href": "周二数据类型.html#数据结构",
    "title": "3  Python数据类型",
    "section": "数据结构",
    "text": "数据结构\nPython中有多种常用的数据结构，包括列表（List）、元组（Tuple）和字典（Dictionary）\n\n列表是一个有序且可变的集合。允许重复的值。\n元组是一个有序且不可更改的集合。允许重复的值。\n字典是一个有序的、可变的集合。不允许重复的值。\n\n\n列表(List)\nlist是Python中最常用的数据结构之一，用于存储一组有序的元素。列表中的元素可以是不同类型的对象，可以进行增删改查等操作。\n\n\n创建列表\n列表可以使用方括号[]来创建，其中每个元素用逗号分隔。例如：\n\n水果 = ['苹果', '菠萝', '榴莲']\nprint(水果)\n\n['苹果', '菠萝', '榴莲']\n\n\n\n\n访问列表元素\n列表中的元素可以通过索引访问，索引从0开始。例如，要访问列表中的第一个元素，可以使用fruits[0]。可以使用负数索引从列表末尾开始访问元素。例如，fruits[-1]表示访问最后一个元素。\n\n# python中顺序需要向前递减一位，所以索引 0 代表第一个， -1 代表最后一个\nprint(水果[0]) \nprint(水果[-1])\n\n苹果\n榴莲\n\n\n\n\n修改列表元素\n列表中的元素可以通过索引进行修改。可以使用赋值语句将新的值赋给列表中的特定位置。\n\n# 修改列表中第二个\n水果[1] = '香蕉'\nprint(水果)\n\n['苹果', '香蕉', '榴莲']\n\n\n\n\n添加和删除元素\n添加元素：可以使用append()方法将元素添加到列表的末尾。\n\n水果.append('我爱香蕉')\nprint(水果)\n\n['苹果', '香蕉', '榴莲', '我爱香蕉']\n\n\n删除元素：可以使用remove()方法删除列表中的特定元素。\n\n水果.remove('香蕉')\nprint(水果) \n\n['苹果', '榴莲', '我爱香蕉']\n\n\n\n\n对列表进行排序\n列表的排序是指将列表中的元素按照一定的顺序进行排列。Python 提供了多种方法来对列表进行排序，其中最常用的是使用 sort() 方法。下面是一个实际案例和答案解析。\n\n\n\n\n\n\nNote\n\n\n\nsort()函数可以对列表进行就地排序，即直接修改原始列表的顺序。使用 sorted() 函数对列表进行临时排序，不改变原始列表的顺序。\n\n\n\n# 按数字对列表进行升序排序：\nlist_asc = [100, 50, 65, 82, 23]\nlist_asc.sort()\nprint(list_asc)\n\n[23, 50, 65, 82, 100]\n\n\n\n# 降序排序\nlist_des = [100, 50, 65, 82, 23]\nlist_des.sort(reverse=True)\nprint(\"降序排序后的列表：\", list_des)\n\n降序排序后的列表： [100, 82, 65, 50, 23]\n\n\n\n\n\n元组(Tuple)\n元组与列表类似，也是用于存储一组有序的元素。但是，元组一旦创建，其元素不可更改，即元组是不可变的。\n\n\n# 创建一个元组\nperson = ('Jack', 25, 'China')\n\n# 访问元组元素\nprint(person[0])  \n\nJack\n\n\n\n# 尝试修改元组元素（会抛出异常）\nperson[1] = 30\n\nTypeError: 'tuple' object does not support item assignment\n\n\n在上面的示例中，我们创建了一个包含个人信息的元组。通过索引访问元组中的元素，但是尝试修改元组元素会引发TypeError异常，因为元组是不可变的。\n\n元组的应用场景\n\n用于存储不可变的数据集合，如坐标点、日期等。\n作为字典（Dictionary）的键值，因为字典要求键是不可变的。\n用于函数返回多个值，函数可以返回元组，调用函数时可以解包元组并获得多个返回值。\n\n元组在需要存储不可变数据集合或对数据进行保护时非常有用。由于元组是不可变的，因此在某些情况下比列表更安全和高效。\n\n\n元组解包\n可以将元组的元素解包到多个变量中，从而快速访问元组的各个元素。\n\n# 上述的person元组中，有三个数值，所以必须设`x,y,z`\nx, y, z = person\nprint(x) \n\nJack\n\n\n\n\n\n\n\n\n\n字典(Dictionary)\n字典是Python中一种常用的数据结构，又称 哈希表，它以键-值（key-value）对的形式存储数据。以下是对字典的详细说明：\n\n\n创建字典\n字典使用花括号{}来创建，每个键-值对之间使用冒号:分隔，不同键-值对之间使用逗号,分隔。例如：\n\nstudent = {'姓名': '帅气的Jack', '年龄': 24, '成绩': 'A+'}\nstudent\n\n{'姓名': '帅气的Jack', '年龄': 24, '成绩': 'A+'}\n\n\n\n\n访问字典元素\n可以通过键来访问字典中的值。使用键来提取相应的值，使用方括号[]操作符，将键作为索引传递给字典。例如：\n\nprint(student['姓名'])\n\n帅气的Jack\n\n\n\n\n修改字典元素\n字典中的值是可以修改的。可以通过指定键来更新字典中的值。例如：\n\n#要修改元素，无论中英文都要加上引号''\nstudent['成绩'] = '刚好及格'\nprint(student)\n\n{'姓名': '帅气的Jack', '年龄': 24, '成绩': '刚好及格'}\n\n\n\n\n\n\n\n\nNote\n\n\n\n设置变量的时候，不要使用类似list, tuple等，如果出现'list' object is not callable，使用del list删除变量\n\n\n\ndict1 = {'key': ['value', 'value2'], 'key2': 'value2'}\ndict2 = {'key': ('physics', 'chemistry', 1997, 2000), 'key2': 'value2'}\n\n\n\n关于字典的相关操作\n要确定字典有多少项，可以使用len()函数\n\nprint(len(student))\n\n3\n\n\n\ndel student['姓名']  # 删除键是'姓名'的条目\nstudent.clear()      # 清空字典所有条目\ndel student          # 删除字典\ndel list            # 删除变量\n\n字典Dict中键和值是一 一对应的，键是唯一的，如果重复最后的一个键【值】对会替换前面的。若一个键中需要存放多个值，可以考虑使用元组Tuple和列表List\n\n\n\n数据结构间的相互转换\n\n列表转换元组\n\n使用 list() 函数将元组转换为列表。\n使用 tuple() 函数将列表转换为元组。\n\n\n# 元组转列表\nmy_tuple = (1, 2, 3, 4, 5)\nmy_list = list(my_tuple)\nprint(my_list)\n\n[1, 2, 3, 4, 5]\n\n\n\n# 列表转元组\nmy_list = [1, 2, 3, 4, 5]\nmy_tuple = tuple(my_list)\nprint(my_tuple)\n\n(1, 2, 3, 4, 5)\n\n\n\n\n字典转换列表&元组\n字典无法直接转换为列表或者元组\nkeys() 方法返回一个包含字典中所有键的可迭代对象。\nitems() 方法获取字典的键值对\n\n# keys() 是一个字典(Dictionary)对象的方法，用于返回字典中所有的键\n\nmy_dict = {\"name\": \"John\", \"age\": 25, \"city\": \"New York\"}\nmy_list = list(my_dict.keys())\nprint(my_list)\n\nprint(type(my_list))\n\n['name', 'age', 'city']\n&lt;class 'list'&gt;\n\n\n\n# 使用 items() 方法获取字典的键值对，然后使用 tuple() 函数将键值对转换为元组。\n\nmy_dict = {\"name\": \"John\", \"age\": 25, \"city\": \"New York\"}\nmy_tuple = tuple(my_dict.items())\nprint(my_tuple)\n\nprint(type(my_tuple))\n\n(('name', 'John'), ('age', 25), ('city', 'New York'))\n&lt;class 'tuple'&gt;"
  },
  {
    "objectID": "NumPy数组概念.html#numpy的安装和导入",
    "href": "NumPy数组概念.html#numpy的安装和导入",
    "title": "4  NumPy数组概念",
    "section": "NumPy的安装和导入",
    "text": "NumPy的安装和导入\n要安装 NumPy，可以选择conda安装或pip安装，在终端(terminal)输入以下安装命令：\nconda install numpy 或者 pip install numpy。\n如果想直接在ipynb文件内的代码块进行安装，需要在终端命令前加一个感叹号，比如!pip install numpy。\n\n\n\n\n\n\nNote\n\n\n\n在ipynb文件内进行安装时，建议将安装的代码块和其他代码分开，运行安装命令后，新开一个代码块去导入或执行其他命令，可以避免重新执行安装指令。\n\n\n安装好后即可导入 NumPy ，通常导入库的方式都是import 库名的形式，但为了方便后续调用库中的一些函数，我们会采取import 库名 as 缩写的形式，如下：\n\nimport numpy as np\n\n使用 NumPy 缩短导入的名称np，可以提高代码的可读性。"
  },
  {
    "objectID": "NumPy数组概念.html#numpy中的核心对象ndarray",
    "href": "NumPy数组概念.html#numpy中的核心对象ndarray",
    "title": "4  NumPy数组概念",
    "section": "NumPy中的核心对象：ndarray",
    "text": "NumPy中的核心对象：ndarray\nndarray是NumPy中最重要的对象，它是N 维数组的简写，可以是一维数组、二维数组或更高维度的数组，由一对或多对中括号括起来。\n\nprint(\"这是一个一维数组，有三个元素:\")\nnp.array((1, 2, 3))\n\n这是一个一维数组，有三个元素:\n\n\narray([1, 2, 3])\n\n\n一维数组只有一行，这个数组一行有三个元素，也就是三列。\n下面这个二维数组，有两行三列。两个维度，在NumPy中维度也可以称为轴，如同坐标系中的x轴和y轴，我们也可以把二维数组看作有两个轴。轴的个数可以根据数组第一个元素前面的中括号个数来判断。\n\nprint(\"这是一个二行三列的二维数组:\")\nnp.array([(1, 2, 3),(4, 5, 6)])\n\n这是一个二行三列的二维数组:\n\n\narray([[1, 2, 3],\n       [4, 5, 6]])\n\n\n相对于一维数组，二维数组多了一个维度，一维数组所有的元素处于同一个维度。\n而上面示例代码中的二维数组包含两个维度，第一个维度有两个元素——两个一维子数组（也称为行）：[1,2,3]和[4,5,6]。而第二个维度中的元素就是里面的中括号括起来的一个个单个的数字元素——1，2，3，4，5，6。也就是一维子数组中的单个元素。\n第一维度的元素个数对应第一个轴的轴长，也就是2，而每个一维子数组都包含3个元素，所以第二个维度的轴长为3。通常我们用形状来形容一个数组各个轴的轴长，也就是这个二维数组的形状为：(2, 3)。两个轴长相乘就是这个数组的单个元素总数。我们可以用表格数据中的行数和列数来理解数组的两个轴的轴长。\nndarray中的单个元素可以是任意数据类型，包括整数、浮点数、复数等。数据类型由dtype（data type）对象来描述。"
  },
  {
    "objectID": "NumPy数组概念.html#创建numpy数组",
    "href": "NumPy数组概念.html#创建numpy数组",
    "title": "4  NumPy数组概念",
    "section": "创建NumPy数组",
    "text": "创建NumPy数组\n要创建 NumPy 数组，可以使用函数np.array()将Python 列表、元组或其他序列转换为NumPy数组。\n\n\n\n\n\n\nNote\n\n\n\nnp.array()的参数传递的对象只能是一个整体，例如((),(),...)或[(),(),...]，不能是多个对象：(),(),...。\n\n\n\na = np.array(((1, 2, 3), (4, 5, 6)))\na\n\narray([[1, 2, 3],\n       [4, 5, 6]])\n\n\n创建一个元素都为0的数组，第一个参数指定各个轴长，并用括号括起来，也就是数组的形状：\n\nnp.zeros((2, 2))\n\narray([[0., 0.],\n       [0., 0.]])\n\n\n用np.zeros()创建的全零元素的数组元素默认为浮点型，如果需要改变元素类型，修改dtype参数即可。\n创建一个元素全为1的3x3的二维矩阵，数值类型为整型：\n\nnp.ones((3, 3), dtype=np.int_)\n\narray([[1, 1, 1],\n       [1, 1, 1],\n       [1, 1, 1]])\n\n\n\n\n\n\n\n\nNote\n\n\n\n二维数组通常也被称作二维矩阵。3x3的矩阵表示有三行三列。\n\n\n创建一个3x3单位矩阵（主对角线元素为1）：\n\nnp.eye(3, 3, dtype=np.int_)\n\narray([[1, 0, 0],\n       [0, 1, 0],\n       [0, 0, 1]])\n\n\n创建一个空数组，空数组不是指数组是空的，数组元素的初始内容会随机生成，同样的，np.empty()可以设置dtype参数：\n\nnp.empty((2, 3), dtype=np.float_)\n\narray([[1.01582801e+094, 3.54586565e+068, 1.57001898e+155],\n       [3.71754479e+177, 3.97949006e-315, 0.00000000e+000]])\n\n\n创建一个等差数列型的一维数组：\nnp.arange()第一个参数start代表起始值，默认从0开始，第二个参数stop代表结束值，但默认取不到结束值，所以结束值不包含在数组中。而第三个参数step为步长，即相邻元素的差值，一般默认步长为1。结束值没有默认值，所以只有结束值参数是不可省略的。\n\nprint(\"创建一个从1到8,步长为2的数组:\")\nnp.arange(1, 9, 2)\n\n创建一个从1到8,步长为2的数组:\n\n\narray([1, 3, 5, 7])\n\n\n\n\n\n\n\n\nNote\n\n\n\n这里取不到8，因为步长为2，元素依次为1，3，5，7，只能取到7。\n\n\n\nprint(\"只含一个参数时,默认从0开始,步长为1:\")\nnp.arange(4)\n\n只含一个参数时,默认从0开始,步长为1:\n\n\narray([0, 1, 2, 3])\n\n\nnp.linspace()也可以用来创建一个等差数列型的数组，和np.arange()不同的是，它可以取到结束值：\n\nprint(\"创建一个包含6个元素,值域从0到10的整型数组:\") \nnp.linspace(0, 10, num=6, dtype=np.int_) \n\n创建一个包含6个元素,值域从0到10的整型数组:\n\n\narray([ 0,  2,  4,  6,  8, 10])\n\n\n创建随机数组：\n\nprint(\"2行2列的随机数组:\")\nnp.random.random((2, 2))\n\n2行2列的随机数组:\n\n\narray([[0.43863291, 0.96991626],\n       [0.3334159 , 0.52684637]])\n\n\n创建随机整数型数组：\n\nnp.random.randint(5, size=(2, 3))\n\narray([[0, 0, 1],\n       [0, 1, 2]])\n\n\n基于已有数组复制得到同样内容的新数组：\n\na = np.arange(4)\nc = a.copy()\nc\n\narray([0, 1, 2, 3])"
  },
  {
    "objectID": "NumPy数组概念.html#numpy支持的数据类型",
    "href": "NumPy数组概念.html#numpy支持的数据类型",
    "title": "4  NumPy数组概念",
    "section": "NumPy支持的数据类型",
    "text": "NumPy支持的数据类型\n\n布尔类型（bool）：表示True或False的布尔值，设置dtype = np.bool_即可。\n整数类型（int）：包括有符号和无符号的整数，如int_、int8、int16、int32、int64、uint8、uint16、uint32、uint64等，u意为unsigned，无符号，表示只能为正数。\n浮点数类型（float）：表示浮点数，包括float16、float32、float64(简略写法dtype=float_)等。\n复数类型（complex）：表示复数，包括complex64、complex128(dtype=complex_)等。\n字符串类型（string）：表示固定长度的字符串，如S10表示长度为10的字符串。\nUnicode类型（unicode）：表示固定长度的Unicode字符串，如U10表示长度为10的Unicode字符串。\n日期和时间类型（datetime）：表示日期和时间，包括datetime64、timedelta64等。"
  },
  {
    "objectID": "NumPy数组概念.html#数组的属性",
    "href": "NumPy数组概念.html#数组的属性",
    "title": "4  NumPy数组概念",
    "section": "数组的属性",
    "text": "数组的属性\n前面已经提及，在 NumPy 中，维度称为轴。以下面这个二维数组为例，它的第一个轴的长度为2（行数），第二个轴长度为3（列数），它的形状为(2, 3)，一共包含6个元素，用两个轴长相乘得到元素总数。\n\na = np.array([[1, 2, 3], [4, 5, 6]])\n\nprint(f\"以此数组为例:\\n{a}\")\n\nprint(f\"数组的维度是:{a.ndim}\")\n\nprint(f\"数组的形状是:{a.shape}\")\n\nprint(f\"数组一共包含{a.size}个元素\")\n\n以此数组为例:\n[[1 2 3]\n [4 5 6]]\n数组的维度是:2\n数组的形状是:(2, 3)\n数组一共包含6个元素"
  },
  {
    "objectID": "NumPy数组概念.html#数组的形状操作",
    "href": "NumPy数组概念.html#数组的形状操作",
    "title": "4  NumPy数组概念",
    "section": "数组的形状操作",
    "text": "数组的形状操作\n\n\n\n\n\n\nNote\n\n\n\n重塑数组的形状或添加新轴不会改变元素，只会改变数组的形状。\n\n\n\na = np.arange(6)\nprint(f\"原数组:{a}\")\n\nprint(f\"重塑形状:\\n{a.reshape(2, 3)}\")\n\n原数组:[0 1 2 3 4 5]\n重塑形状:\n[[0 1 2]\n [3 4 5]]\n\n\n如果元素过多，我们不能确定所有轴的个数，可以指定部分轴长，指定某一个轴为-1，-1表示根据已知的其余轴长自动计算。\n下列示例表示重塑为3行的二维数组，列数自动计算。\n\nprint(f\"转换为3行n列:\\n{a.reshape(3, -1)}\")\n\n转换为3行n列:\n[[0 1]\n [2 3]\n [4 5]]\n\n\n\n添加新轴\nnp.newaxis是一个特殊的常量，用于扩展数组的维度。np.expand_dims()也能添加新轴，并且默认新轴的默认轴长为1，数组其他维度的元素个数会随之自动调整。\n对于二维数组的两个轴，可以看作是行轴（第0轴）和列轴（第1轴），行轴代表第一维度，列轴代表第二维度。\n添加行轴也就是在第0轴处添加新的维度，且行轴的轴长为1，说明第一维度只有一个元素，也就是只有一行。\n添加列轴，则默认添加的列轴轴长为1，每个一维子数组中的单个元素个数为1，也就是只有一列，元素总数不变，行数随之自动调整。\n\nrow_vector = a[np.newaxis, :]\nprint(f\"添加新的行轴:\\n{row_vector}\")\n\nprint(f\"相当于在第0轴处添加轴:\\n{np.expand_dims(a, axis=0)}\")\n\ncol_vector = a[:, np.newaxis]\nprint(f\"添加新的列轴:\\n{col_vector}\")\n\nprint(f\"相当于在索引位置1处添加轴:\\n{np.expand_dims(a, axis=1)}\")\n\n添加新轴,从一维转为二维:\n[[0 1 2 3 4 5]]\n相当于在索引位置0处添加轴:\n[[0 1 2 3 4 5]]\n添加新轴,转换为列向量:\n[[0]\n [1]\n [2]\n [3]\n [4]\n [5]]\n相当于在索引位置1处添加轴:\n[[0]\n [1]\n [2]\n [3]\n [4]\n [5]]\n\n\n除了重塑矩阵和添加新轴，还有一种方法叫转置矩阵。\n矩阵的转置是一种基本的线性代数运算，它是指将原始矩阵的行与列进行互换，从而得到一个新的矩阵。原来的第i行变成新矩阵的第i列，第j列则变成新矩阵的第j行，当m≠n时，形状会由(m, n)变为(n, m)。\n\narr = np.arange(1, 7).reshape(2, 3)\nprint(f\"原矩阵:\\n{arr}\")\n\nprint(f\"转置后:\\n{arr.transpose()}\")\n\nprint(f\"也可以用.T:\\n{arr.T}\")\n\n原矩阵:\n[[1 2 3]\n [4 5 6]]\n转置后:\n[[1 4]\n [2 5]\n [3 6]]\n也可以用.T:\n[[1 4]\n [2 5]\n [3 6]]"
  },
  {
    "objectID": "NumPy数组概念.html#numpy的通用函数",
    "href": "NumPy数组概念.html#numpy的通用函数",
    "title": "4  NumPy数组概念",
    "section": "NumPy的通用函数",
    "text": "NumPy的通用函数\n上面讲述了NumPy数组的一些基本概念和形状变换，现在我们介绍一些能够对NumPy数组进行元素操作的通用函数（Universal Functions，通常简称为 ufuncs），它能够对 NumPy 数组中的每个元素执行相同的操作，并返回一个新的数组作为结果。这种批量计算使得 NumPy 在数值计算和科学计算中非常高效和方便。\n通用函数可以执行各种数学运算，例如加法、减法、乘法、除法、取整、取余等。此外，通用函数也支持各种数学函数，例如三角函数、指数函数、对数函数、平方根等。\n\n1. 算术运算函数：\nnp.add(x1, x2): 两个数组对应元素相加。\nnp.subtract(x1, x2): 两个数组对应元素相减。\nnp.multiply(x1, x2): 两个数组对应元素相乘。\nnp.divide(x1, x2): 两个数组对应元素相除。\nnp.power(x1, x2): 以第二个数组为指数，计算第一个数组元素的幂次方，x2也可以为单个数字。\n\n\n2. 数学函数：\nnp.sin(x), np.cos(x), np.tan(x): 计算三角函数。\nnp.exp(x): 计算指数函数。\nnp.log(x), np.log10(x), np.log2(x): 计算对数函数。\nnp.sqrt(x): 计算平方根。\n\n\n3. 聚合运算：\nnp.sum(x): 对数组所有元素求和。\nnp.mean(x): 计算数组平均值。\nnp.min(x), np.max(x): 计算数组的最小值和最大值。\nnp.argmin(x), np.argmax(x): 找到数组最小值和最大值的索引。\n\n\n4. 舍入函数：\nnp.round(x): 对数组元素小数位进行四舍五入。\nnp.floor(x): 对数组元素向下取整。\nnp.ceil(x): 对数组元素向上取整。\n\n\n特殊值\n在数据处理和科学计算中，还有一些常见的特殊值，比如缺失值，无穷小，无穷大等等。如同Python中的None对象，表示缺少值或空值。\nnp.nan表示缺失或未定义的数据，可以在定义数组或数据框数据时用于赋值：arr = np.array([1, 2, np.nan, 4, 5])"
  },
  {
    "objectID": "NumPy数组的基本操作.html#数组的基本运算",
    "href": "NumPy数组的基本操作.html#数组的基本运算",
    "title": "5  NumPy数组的基本操作和变换",
    "section": "数组的基本运算",
    "text": "数组的基本运算\n数组上的算术运算符按元素应用。\n\nimport numpy as np\na = np.array([(20, 30),(40, 50)])\nb = np.arange(2, 6).reshape(2, 2)\n\nprint(f\"数组a:\\n{a}\")\nprint(f\"数组b:\\n{b}\")\n\nprint(f\"加法运算:\\n{np.add(a, b)}\")   # 等价于a + b\n\nprint(f\"减法运算:\\n{np.subtract(a, b)}\")   # 等价于a - b\n\nprint(f\"乘法运算:\\n{np.multiply(a, b)}\")   # 等价于a * b\n\nprint(f\"除法运算:\\n{np.divide(a, b)}\")   # 等价于a / b\n\nprint(f\"平方运算:\\n{np.square(b)}\")   # 等价于b ** 2\n\n数组a:\n[[20 30]\n [40 50]]\n数组b:\n[[2 3]\n [4 5]]\n加法运算:\n[[22 33]\n [44 55]]\n减法运算:\n[[18 27]\n [36 45]]\n乘法运算:\n[[ 40  90]\n [160 250]]\n除法运算:\n[[10. 10.]\n [10. 10.]]\n平方运算:\n[[ 4  9]\n [16 25]]\n\n\n矩阵（二维数组）乘积运算用@或.dot()：\n\n\n\n\n\n\nNote\n\n\n\n计算矩阵A和B的乘积时，新矩阵第i行第j列的元素为矩阵A第i行元素和矩阵B第j列元素的乘积之和。\n\n\n下列示例中，矩阵A的第一行乘以矩阵B的第一列的元素并加和：1 x 3 + 2 x 1 = 5，得到新矩阵第1行第1列的元素。\n\nA = np.array([(1, 2),(3, 4)])\nB = np.array([(3, 2, 1),(1, 1, 1)])\n\nprint(f\"数组A:\\n{A}\")\nprint(f\"数组B:\\n{B}\")\n\nprint(f\"矩阵的乘积:\\n{A@B}\")\n# 等价于A.dot(B)\n\n数组A:\n[[1 2]\n [3 4]]\n数组B:\n[[3 2 1]\n [1 1 1]]\n矩阵的乘积:\n[[ 5  4  3]\n [13 10  7]]"
  },
  {
    "objectID": "NumPy数组的基本操作.html#聚合函数的运算",
    "href": "NumPy数组的基本操作.html#聚合函数的运算",
    "title": "5  NumPy数组的基本操作和变换",
    "section": "聚合函数的运算",
    "text": "聚合函数的运算\n\narr = np.array([(1, 2), (3, 4)])\nprint(f\"对数组进行聚合函数的运算:\\n{arr}\")\n\nprint(\"数组元素求和:\", arr.sum())\n\nprint(\"对每列求和:\", arr.sum(axis=0))  # 行求和: axis = 1\n\nprint(\"数组元素最小值:\", arr.min())\n\nprint(\"每列最小值:\", arr.min(axis=0)) \n\n对数组进行聚合函数的运算:\n[[1 2]\n [3 4]]\n数组元素求和: 10\n对每列求和: [4 6]\n数组元素最小值: 1\n每列最小值: [1 2]"
  },
  {
    "objectID": "NumPy数组的基本操作.html#数组的索引和切片",
    "href": "NumPy数组的基本操作.html#数组的索引和切片",
    "title": "5  NumPy数组的基本操作和变换",
    "section": "数组的索引和切片",
    "text": "数组的索引和切片\n数组包含的元素，每一个都有唯一的索引能够找到它，我们可以通过引用索引获取单个元素，如arr[n]，也能通过切片获取部分元素。\n一维数组切片的语法是 arr[start:stop:step]，其中 start 是切片开始的位置索引（包含在切片中），默认为0，stop 是切片结束的位置索引（不包含在切片中），step 是切片步长，默认为1。\n\n索引默认从0开始，步长为1，第一个元素索引为0，第二个元素索引为1，依此类推。\n且满足前闭后开规则，默认含首不含尾，结束索引指代的元素取不到。\n-n表示结束索引时，表示反方向（从后往前）第n个数；表示步长时指反方向取数且步长为n。\n修改切片元素时原数组的元素也会相应改变。\n\n\n一维数组\n\narr = np.arange(10)\nprint('以此数组为例:', arr)\n\nslice_one = arr[:5]    # 等价于arr[0:5:1]\nprint('索引从0到4的切片:', slice_one)\n\nslice_two = arr[4:7]\nprint('索引从4到6的切片:', slice_two)\n\nslice_three = arr[0:10:3]     # 范围取全部,起始/结束索引可省略,等价于arr[::3] \nprint('索引从0到9且步长为3的切片', slice_three)\n\nslice_four = arr[:-5]\nprint('索引从0到反向第5个数(不包含)的切片:', slice_four)\n\nslice_four[0] = 99\nprint('修改切片元素后原数组随之改变:', arr)\n\n以此数组为例: [0 1 2 3 4 5 6 7 8 9]\n索引从0到4的切片: [0 1 2 3 4]\n索引从4到6的切片: [4 5 6]\n索引从0到9且步长为3的切片 [0 3 6 9]\n索引从0到反向第5个数(不包含)的切片: [0 1 2 3 4]\n修改切片元素后原数组随之改变: [99  1  2  3  4  5  6  7  8  9]\n\n\n\n\n二维数组\n二维数组的切片语法是 arr[start:stop:step, start:stop:step]。逗号前是第一维度，逗号后是第二维度，同时对两个维度的位置索引进行定位，也就是同时定位行和列才能找到单个元素。\n\narr = np.arange(1, 10).reshape(3, 3)\nprint(f\"二维数组:\\n{arr}\")\n\nprint(f\"第2行第2列的元素5: {arr[1, 1]}\")\n\nprint(f\"第2行的元素: {arr[1, :]}\")\n\nprint(f\"第2行第1,3列的元素: {arr[1, ::2]}\")\n\n二维数组:\n[[1 2 3]\n [4 5 6]\n [7 8 9]]\n第2行第2列的元素5: 5\n第2行的元素: [4 5 6]\n第2行第1,3列的元素: [4 6]"
  },
  {
    "objectID": "NumPy数组的基本操作.html#条件过滤",
    "href": "NumPy数组的基本操作.html#条件过滤",
    "title": "5  NumPy数组的基本操作和变换",
    "section": "条件过滤",
    "text": "条件过滤\n除了用索引获取元素，还可以用逻辑条件来筛选满足条件的元素，提取数组部分元素用中括号，当用多个条件进行筛选过滤时，单个条件用圆括号括起来，条件之间用符号&连接。筛选后的数组会被展平为一维数组：\n\n\n\n\n\n\nNote\n\n\n\n条件过滤筛选数据时，条件之间要用符号&而不是and连接。\n\n\n\narr = np.arange(12).reshape((3, 4))\nprint(f\"以此数组为例:\\n{arr}\")\n\nprint(f\"大于6的元素:{arr[arr &gt; 6]}\")\n\nprint(f\"大于6且小于10的元素:{arr[(arr &gt; 6) & (arr &lt; 10)]}\")\n\n以此数组为例:\n[[ 0  1  2  3]\n [ 4  5  6  7]\n [ 8  9 10 11]]\n大于6的元素:[ 7  8  9 10 11]\n大于6且小于10的元素:[7 8 9]\n\n\n返回满足条件的元素索引：\n\narr = np.random.randint(4, size=(3, 3))\nprint(f\"以此二维数组为例:\\n{arr}\")\n\nprint(f\"所有非零元素的索引(分维度):\\n{np.nonzero(arr)}\")\n\nprint(f\"元素小于均值的索引:\\n{np.nonzero(arr &lt; np.mean(arr))}\")\n\n以此二维数组为例:\n[[0 1 1]\n [1 0 3]\n [3 3 3]]\n所有非零元素的索引(分维度):\n(array([0, 0, 1, 1, 2, 2, 2], dtype=int64), array([1, 2, 0, 2, 0, 1, 2], dtype=int64))\n元素小于均值的索引:\n(array([0, 0, 0, 1, 1], dtype=int64), array([0, 1, 2, 0, 1], dtype=int64))\n\n\n以坐标形式(打包成元组)返回元素索引：\n\nind = np.nonzero(arr &lt; 6)\n# ind[0]为第一维度索引数组，ind[1]为第二维度索引数组\nlist_of_coordinates = list(zip(ind[0], ind[1]))\nprint(list_of_coordinates)\n\n[(0, 0), (0, 1), (0, 2), (1, 0), (1, 1), (1, 2), (2, 0), (2, 1), (2, 2)]\n\n\n\n\n\n\n\n\nNote\n\n\n\n遇到不认识的函数或模块时，例如上述示例代码的zip()可以使用help(zip())查询函数或模块的详细参数信息以及示例代码。不习惯看英文解释可以复制以后进行中文翻译。\n如果想要了解某个特定模块的方法，例如numpy的array方法，可以使用numpy.info(numpy.array)，也可以使用缩写np.info(np.array)。\n此外，在学习过程中，除了会遇到一些不了解的代码，我们在执行代码时，也总会遇到各种各样的英文报错信息。大多数的报错在网络上都已经有大量的经验和讨论信息，学会去理解报错信息，借助网络找到解决办法也是学习编程的一项重要能力。我们可以通过翻译报错信息去思考报错的根源，也可以通过复制粘贴直接上网搜索，看看已有的一些解决问题的思路，在不断的尝试中累积经验和对代码的理解。\n学习编程是一个长期的过程，希望大家在学习的过程中能保持思考和独立解决问题的积极性。\n\n\n对数组的操作，不仅体现在计算和筛选，还可以对元素重新排序、去重复值、以及数组的拼接、堆叠、展平等各种操作，并且这些操作对于表格数据，在Pandas库中也有类似的方法能实现。"
  },
  {
    "objectID": "NumPy数组的基本操作.html#数组的排序反转和去重",
    "href": "NumPy数组的基本操作.html#数组的排序反转和去重",
    "title": "5  NumPy数组的基本操作和变换",
    "section": "数组的排序、反转和去重",
    "text": "数组的排序、反转和去重\n\n排序和反转\n对元素进行排序一般默认为按升序排列。\n\nx = np.array([7, 2, 5, 3, 6, 4, 9, 1, 8])\nprint(f\"一维数组:{x}\")\n\nprint(f\"排序:{np.sort(x)}\")\n\nprint(f\"反转:{np.flip(x)}\")\n\nprint(f\"利用切片方式反转,步长为-1:{x[::-1]}\")\n\n一维数组:[7 2 5 3 6 4 9 1 8]\n排序:[1 2 3 4 5 6 7 8 9]\n反转:[8 1 9 4 6 3 5 2 7]\n利用切片方式反转,步长为-1:[8 1 9 4 6 3 5 2 7]\n\n\n二维数组的排序在默认情况下，每一行按升序排列。当axis=0时，每一列按升序排序。\n\ny = np.array([[6, 5, 4], [3, 2, 1], [9, 8, 7]])\nprint(f\"二维数组:\\n{y}\")\n\nprint(f\"排序:\\n{np.sort(y, axis=0)}\")\n\nprint(f\"反转:\\n{np.flip(y)}\")\n\nprint(f\"仅反转子数组顺序:\\n{np.flip(y, axis=0)}\")\n\nprint(f\"切片反转数组顺序:\\n{y[::-1,::-1]}\")\n\n# 以上反转不改变原数组，下面的赋值才会使原数组改变\ny[:,1] = np.flip(y[:,1])\nprint(f\"仅反转第二列:\\n{y}\")\n\n二维数组:\n[[6 5 4]\n [3 2 1]\n [9 8 7]]\n排序:\n[[3 2 1]\n [6 5 4]\n [9 8 7]]\n反转:\n[[7 8 9]\n [1 2 3]\n [4 5 6]]\n仅反转子数组顺序:\n[[9 8 7]\n [3 2 1]\n [6 5 4]]\n切片反转数组顺序:\n[[7 8 9]\n [1 2 3]\n [4 5 6]]\n仅反转第二列:\n[[6 8 4]\n [3 2 1]\n [9 5 7]]\n\n\n\n\n去重复值\n设置return_index=True时，会同时返回去重后的数组和数组索引，可以分别赋值给两个变量同时得到数组和索引。\n\narr = np.array([1, 2, 2, 5, 7, 7, 8, 9, 9, 12, 14])\nprint(f\"原数组:{arr}\")\n\nprint(f\"去重后的数组:{np.unique(arr)}\")\n\nunique_arr, indices_list = np.unique(arr, return_index=True)\nprint(f\"去重数组的索引:{indices_list}\")\n\n原数组:[ 1  2  2  5  7  7  8  9  9 12 14]\n去重后的数组:[ 1  2  5  7  8  9 12 14]\n去重数组的索引:[ 0  1  3  4  6  7  9 10]"
  },
  {
    "objectID": "NumPy数组的基本操作.html#数组的展平合并堆叠拆分",
    "href": "NumPy数组的基本操作.html#数组的展平合并堆叠拆分",
    "title": "5  NumPy数组的基本操作和变换",
    "section": "数组的展平、合并、堆叠、拆分",
    "text": "数组的展平、合并、堆叠、拆分\n\n展平数组\n展平数组可用flatten()或ravel()。\n\n\n\n\n\n\nNote\n\n\n\n使用flatten时，对展平数组的更改不会影响原数组，使用ravel时，数组的更改会影响原数组。\n\n\n\narr = np.arange(6).reshape(2, 3)\nprint(f\"展平前:\\n{arr}\")\n\narr_one = arr.flatten()\nprint(f\"使用flatten展平后:\\n{arr_one}\")\n\narr_one[0] = 99\nprint(f\"修改元素:\\n{arr_one}\")\n\nprint(f\"原数组不变:\\n{arr}\")\n\n展平前:\n[[0 1 2]\n [3 4 5]]\n使用flatten展平后:\n[0 1 2 3 4 5]\n修改元素:\n[99  1  2  3  4  5]\n原数组不变:\n[[0 1 2]\n [3 4 5]]\n\n\n\narr_two = arr.ravel()\nprint(f\"使用ravel展平后:\\n{arr_two}\")\n\narr_two[0] = 99\nprint(f\"修改元素:\\n{arr_two}\")\n\nprint(f\"原数组改变:\\n{arr}\")\n\n使用ravel展平后:\n[0 1 2 3 4 5]\n修改元素:\n[99  1  2  3  4  5]\n原数组改变:\n[[99  1  2]\n [ 3  4  5]]\n\n\n\n\n拼接和堆叠数组\n\n\n\n\n\n\nNote\n\n\n\n二维数组的垂直堆叠需要列数相同，水平堆叠需要行数相同。\n用np.concatenate()合并数组时，默认axis=0，即沿着行方向进行合并，设置axis=1，即沿着列方向进行合并。\n\n\n\na = np.array([(1, 2),(3, 4)])\nb = np.array([(1, 2),(3, 4)])\nc = np.zeros((1, 2), dtype=np.int_)\n\nprint(f\"数组a:\\n{a}\")\nprint(f\"数组b:\\n{b}\")\nprint(f\"数组c:\\n{c}\")\n\nprint(f\"合并数组:\\n{np.concatenate((a, b))}\")\n\nprint(f\"垂直堆叠三个数组:\\n{np.vstack((a, b, c))}\")\n\nprint(f\"水平堆叠数组:\\n{np.hstack((a, a))}\")\n\n数组a:\n[[1 2]\n [3 4]]\n数组b:\n[[1 2]\n [3 4]]\n数组c:\n[[0 0]]\n合并数组:\n[[1 2]\n [3 4]\n [1 2]\n [3 4]]\n垂直堆叠三个数组:\n[[1 2]\n [3 4]\n [1 2]\n [3 4]\n [0 0]]\n水平堆叠数组:\n[[1 2 1 2]\n [3 4 3 4]]\n\n\n\n\n拆分数组\n\narr = np.arange(1, 21).reshape(2, 10)\nprint(f\"以此数组为例:\\n{arr}\")\n\nprint(f\"拆分为2个形状相同的数组(相当于从第5列开始拆分):\\n{np.hsplit(arr, 2)}\")\n\nprint(f\"从第3列,第7列之后开始拆分:\\n{np.hsplit(arr, (3, 7))}\")\n\n以此数组为例:\n[[ 1  2  3  4  5  6  7  8  9 10]\n [11 12 13 14 15 16 17 18 19 20]]\n拆分为2个形状相同的数组(相当于从第5列开始拆分):\n[array([[ 1,  2,  3,  4,  5],\n       [11, 12, 13, 14, 15]]), array([[ 6,  7,  8,  9, 10],\n       [16, 17, 18, 19, 20]])]\n从第3列,第7列之后开始拆分:\n[array([[ 1,  2,  3],\n       [11, 12, 13]]), array([[ 4,  5,  6,  7],\n       [14, 15, 16, 17]]), array([[ 8,  9, 10],\n       [18, 19, 20]])]\n\n\n以上,我们了解了NumPy作为数值计算的核心库，不仅提供了高性能的多维数组对象（ndarray）和对这些数组执行操作的函数，还能够高效地处理大规模数据。但对于数据处理和分析来说，往往还需要更高级的工具。例如Pandas，是Python中另一个强大的数据处理库，和NumPy的数组操作有许多相似之处，例如索引切片，Pandas库也是接下来我们要重点学习的内容。Pandas构建在NumPy之上，提供了丰富的功能，包括数据导入和导出、缺失数据处理、数据重塑、合并、分组和聚合、时间序列处理等。能让日常的数据处理更加简洁、高效。\nNumPy和Pandas是Python数据科学和数值计算领域的两个重要库。NumPy提供了多维数组和高性能数值计算功能，是数据处理的基础。而Pandas提供了更高级的数据结构和数据处理功能，使得数据分析更加方便。两者共同组成了Python数据科学生态系统的重要组成部分，为数据科学家和工程师提供了强大的工具来探索、处理和分析数据。"
  },
  {
    "objectID": "安装.html",
    "href": "安装.html",
    "title": "6  Pandas安装",
    "section": "",
    "text": "使用Anaconda安装\n对于没有经验的小白来说，直接上手用代码来安装各种包可能有点困难，而Anaconda作为一个发行平台，可以非常轻松的安装除了Pandas之外的各种Python包（IPython、NumPy、 Matplotlib等）\n可以直接在jupyter代码块中安装\n\n# 在jupyter代码块中使用\nconda install pandas\n\n\n\n\n\n使用PyPI中的 pip 安装\n\n# 在命令行（终端）中使用\npip install pandas\n\n\n使用pip show pandas检验是否安装成功\n\n\n\n\n\n\nTip\n\n\n\n一般来说这是python自带的安装方式，但有时候你的虚拟环境没有或者服务器里的需要更新，可以参考文档\n\n\n\n安装pip的步骤\n\n首先，确保您已经安装了Python。Pip是Python的包管理工具，它通常随着Python的安装一起提供。\n打开终端（命令提示符）。\n输入以下命令来检查是否已安装pip：\n\n\n# 命令行中输入\npip --version\n\n# 在jupyter中输入 \n%pip --version\n\n如果已经安装了pip，您将看到版本号信息。否则，将显示错误信息或没有任何输出。\n如果未安装pip，可以使用以下方法进行安装：\n\n\n\nLinux&MacOSWindows\n\n\n打开终端，运行以下命令来安装pip\n$ curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py\npython get-pip.py\n\n\n使用Python自带的ensurepip模块来安装或升级pip。\nC:&gt; py -m ensurepip --upgrade"
  },
  {
    "objectID": "pandas处理什么样的数据.html#表格数据",
    "href": "pandas处理什么样的数据.html#表格数据",
    "title": "7  pandas处理什么样的数据",
    "section": "表格数据",
    "text": "表格数据\nPandas最常用于处理表格数据，例如CSV文件、Excel文件、数据库查询结果等。你可以使用Pandas读取这些数据，并对其进行各种操作，如过滤、排序、合并、聚合、计算统计指标等。\n当使用Pandas处理表格数据时，你可以使用DataFrame这个主要的数据结构。DataFrame是一个二维的标记数组，类似于电子表格或SQL表。\n\n# 1. 导入pandas包\nimport pandas as pd\n\n# 2. 假设data数据\ndata = {\n  \"calories\": [420, 380, 390],\n  \"duration\": [50, 40, 45]\n}\n\n# 3. 假设df，然后调用pd(pandas包)，将数据转换为DataFrame格式\ndf = pd.DataFrame(data)\n\n# 4. 打印df\ndf\n\n\n\n\n\n\n\n\ncalories\nduration\n\n\n\n\n0\n420\n50\n\n\n1\n380\n40\n\n\n2\n390\n45"
  },
  {
    "objectID": "pandas处理什么样的数据.html#时间序列数据",
    "href": "pandas处理什么样的数据.html#时间序列数据",
    "title": "7  pandas处理什么样的数据",
    "section": "时间序列数据",
    "text": "时间序列数据\nPandas提供了强大的时间序列功能，可以处理日期和时间相关的数据。你可以使用Pandas对时间序列数据进行重采样、滚动计算、时间窗口分析、时间序列绘图等操作。\n\nimport pandas as pd\n\ndate = pd.to_datetime(\"13th of June, 2023\")\n\ndate\n\nTimestamp('2023-06-13 00:00:00')\n\n\n可以使用DateTimeIndex和TimedeltaIndex来表示时间索引和时间间隔。\n\nimport pandas as pd\n# 创建一个包含日期范围的时间索引\ndate_range = pd.date_range(start='2023-01-01', end='2023-01-10', freq='D')\n\n# 创建一个DataFrame，并使用时间索引\ndata = pd.DataFrame({'Value': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]}, index=date_range)\n\n# 查看数据的前几行\ndata.head()\n\n\n\n\n\n\n\n\nValue\n\n\n\n\n2023-01-01\n10\n\n\n2023-01-02\n20\n\n\n2023-01-03\n30\n\n\n2023-01-04\n40\n\n\n2023-01-05\n50\n\n\n\n\n\n\n\n选取所需的时间序列数据，并进行计算\n\n# 通过日期索引获取某一天的数据\nday_data = data.loc['2023-01-05']\n\n# 通过日期范围索引获取一段时间内的数据\nrange_data = data.loc['2023-01-03':'2023-01-07']\n\n# 使用日期的年、月、日等属性进行切片\nyear_data = data[data.index.year == 2023]\nmonth_data = data[data.index.month == 1]\nday_data = data[data.index.day == 5]\n\n# 将数据按周进行重采样，计算每周的平均值\nweekly_data = data.resample('W').mean()\n\n# 将数据按月进行重采样，计算每月的总和\nmonthly_data = data.resample('M').sum()"
  },
  {
    "objectID": "pandas处理什么样的数据.html#缺失数据处理",
    "href": "pandas处理什么样的数据.html#缺失数据处理",
    "title": "7  pandas处理什么样的数据",
    "section": "缺失数据处理",
    "text": "缺失数据处理\nPandas提供了灵活的方法来处理缺失数据。你可以使用Pandas来检测和处理缺失值，填充缺失数据，或者根据缺失值进行数据筛选和计算。\n\n# 创建带有缺失数据的DataFrame\ndata = pd.DataFrame({'A': [1, 2, None, 4, 5],\n                     'B': [None, 2, 3, None, 6],\n\n                     'C': [1, 2, 3, 4, 5]})\n\n检查并统计缺失值\n\n# 检测每个单元格是否为缺失值\nmissing_values = data.isnull()\n\n# 统计每列的缺失值数量\nmissing_counts = data.isnull().sum()\n\n# 统计整个DataFrame的缺失值数量\ntotal_missing_count = data.isnull().sum().sum()\n\n对缺失值进行操作\n\n# 删除包含缺失值的行\ndata_dropna = data.dropna()\n\n# 删除全部为缺失值的列\ndata_dropna_cols = data.dropna(axis=1, how='all')\n\n# 填充缺失值为指定的常数\ndata_fillna = data.fillna(0)\n\n# 使用缺失值前面的值进行前向填充\ndata_ffill = data.fillna(method='ffill')\n\n# 使用缺失值后面的值进行后向填充\ndata_bfill = data.fillna(method='bfill')"
  },
  {
    "objectID": "pandas处理什么样的数据.html#数据清洗和转换",
    "href": "pandas处理什么样的数据.html#数据清洗和转换",
    "title": "7  pandas处理什么样的数据",
    "section": "数据清洗和转换",
    "text": "数据清洗和转换\nPandas可以用于数据清洗和转换的各种操作。你可以使用Pandas对数据进行重塑、合并、分组、变形等，以满足特定的分析需求。\n\n# 创建原始数据\ndata = pd.DataFrame({'Name': ['John', 'Emily', 'Michael', 'Emma'],\n                     'Age': [25, 30, 35, 28],\n                     'Gender': ['M', 'F', 'M', 'F'],\n                     'Salary': ['$5000', '$6000', '$4500', '$7000']})\n\n\n数据清洗\n清洗重复或者多余数据\n\n# 去除重复的行\ndata_cleaned = data.drop_duplicates()\n\n# 去除列中的空格\ndata_cleaned['Name'] = data_cleaned['Name'].str.strip()\n\n# 删除缺失值所在的行\ndata_cleaned = data_cleaned.dropna()\n\n\n\n数据转换\n将列表转换为序列（Series）\nseries = pd.Series(list)\n\nimport pandas as pd\n\n# 将列表转换为序列\nmy_list = [1, 2, 3, 4, 5]\nseries = pd.Series(my_list)\nseries\n\n0    1\n1    2\n2    3\n3    4\n4    5\ndtype: int64\n\n\n将序列（Series）转换为数据框（DataFrame）\ndataframe = series.to_frame()\n\n# 将序列转换为数据框\nseries = pd.Series([1, 2, 3, 4, 5])\ndataframe = series.to_frame()\ndataframe\n\n\n\n\n\n\n\n\n0\n\n\n\n\n0\n1\n\n\n1\n2\n\n\n2\n3\n\n\n3\n4\n\n\n4\n5\n\n\n\n\n\n\n\n将数据框（DataFrame）转换为列表（list）\nmy_list = df.values.tolist()\n\n# 将数据框转换为列表\ndf = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\nmy_list = df.values.tolist()\nmy_list\n\n[[1, 4], [2, 5], [3, 6]]\n\n\n\n\n\n\n\n\nTip\n\n\n\n数据的清洗和转换是pandas最常使用的功能，之后我们会逐步拆解，进行详细说明"
  },
  {
    "objectID": "pandas处理什么样的数据.html#数据可视化",
    "href": "pandas处理什么样的数据.html#数据可视化",
    "title": "7  pandas处理什么样的数据",
    "section": "数据可视化",
    "text": "数据可视化\nPandas集成了Matplotlib库，可以通过简单的接口生成各种统计图表和可视化图形，以便更好地理解和呈现数据。\n\n# 创建数据\ndata = pd.DataFrame({'Month': ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun'],\n                     'Sales': [100, 150, 120, 200, 180, 250],\n                     'Expenses': [80, 90, 100, 85, 95, 110]})\n\n# 折线图\ndata.plot(x='Month', y='Sales', kind='line')\n\n&lt;Axes: xlabel='Month'&gt;\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n虽然pandas也可以画图，但是还是静态图形，之后我们会详细说明更加简洁和酷炫的可视化库 Plotly库"
  },
  {
    "objectID": "pandas处理什么样的数据.html#数据建模和分析",
    "href": "pandas处理什么样的数据.html#数据建模和分析",
    "title": "7  pandas处理什么样的数据",
    "section": "数据建模和分析",
    "text": "数据建模和分析\nPandas还支持数据建模和分析的操作。你可以使用Pandas进行数据建模、特征工程、数据预处理等，然后将数据传递给机器学习库（如Scikit-learn）进行模型训练和预测。网上看到不错的数据预测案例"
  },
  {
    "objectID": "导入_导出数据.html#导入数据",
    "href": "导入_导出数据.html#导入数据",
    "title": "8  导入&导出数据",
    "section": "导入数据",
    "text": "导入数据\n\n导入本地数据\n\n读取CSV文件, 官方文档参数介绍\n\n第一步先点击data.csv下载文件\n\n获取数据data.csv下载地址，将csv文件下载到本地。建议大家创建一个夏令营文件夹，方便对新文件统一管理\n\n导入pandas包进行调用，import是导入包体，as是重命名为pd，尽量为缩写，方便使用\n设置变量df，方便后续调用（也可以不设置变量直接使用）；pd是pandas包的缩写，使用read_csv()函数；单引号内为本地CSV文件路径\ndf 执行变量\n\nTips：如果已经来到了文件所在路径，则可以直接使用pd.read_csv('data.csv')读取csv文件\n\n# 导入pandas包\nimport pandas as pd\n\n# 注意csv文件路径，读取CSV文件，默认分隔符为逗号\ndf = pd.read_csv('./example_data/data.csv') \n\n# 调用变量df\ndf\n\n\n\n\n\n\n\n\nDuration\nPulse\nMaxpulse\nCalories\n\n\n\n\n0\n60\n110\n130\n409.1\n\n\n1\n60\n117\n145\n479.0\n\n\n2\n60\n103\n135\n340.0\n\n\n3\n45\n109\n175\n282.4\n\n\n4\n45\n117\n148\n406.0\n\n\n...\n...\n...\n...\n...\n\n\n164\n60\n105\n140\n290.8\n\n\n165\n60\n110\n145\n300.0\n\n\n166\n60\n115\n145\n310.2\n\n\n167\n75\n120\n150\n320.4\n\n\n168\n75\n125\n150\n330.4\n\n\n\n\n169 rows × 4 columns\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n此处直接使用df打印结果，是因为在pandas中默认使用DataFrame格式，相较于print()会更加清晰。\nDataFrame是Pandas中最常用的数据结构之一，它提供了一种二维表格的数据结构，类似于电子表格或关系型数据库中的数据表。DataFrame由行和列组成，每列可以包含不同的数据类型（例如整数、浮点数、字符串等）。\n\n\n遇到不熟悉的函数或者python库的时候，可以使用help()来查找相应文档，并且一般最下面会给一个例子\n\nhelp(pd.read_table)\n\n\n\n读取Excel文件, 官方文档参数介绍\n\n步骤同上，第一步先点击Financial_Sample.xlsx下载文件\n\n获取数据Financial_Sample.xlsx下载地址，将Excel文件下载到本地。\n\n导入pandas包进行调用；\n使用read_excel()函数；单引号内为本地Excel文件路径\ndf 执行变量\n\nTips：如果出现编码问题无法导入，可尝试将Excel文件，另存为为Utf-8格式，然后重新导入\n\n# 导入pandas包\nimport pandas as pd\n\n# 注意csv文件路径\ndf = pd.read_excel('./example_data/Financial Sample.xlsx') \n\n# 调用变量df，表格前五行\ndf.head()\n\n\n\n\n\n\n\n\nSegment\nCountry\nProduct\nDiscount Band\nUnits Sold\nManufacturing Price\nSale Price\nGross Sales\nDiscounts\nSales\nCOGS\nProfit\nDate\nMonth Number\nMonth Name\nYear\n\n\n\n\n0\nGovernment\nCanada\nCarretera\nNone\n1618.5\n3\n20\n32370.0\n0.0\n32370.0\n16185.0\n16185.0\n2014-01-01\n1\nJanuary\n2014\n\n\n1\nGovernment\nGermany\nCarretera\nNone\n1321.0\n3\n20\n26420.0\n0.0\n26420.0\n13210.0\n13210.0\n2014-01-01\n1\nJanuary\n2014\n\n\n2\nMidmarket\nFrance\nCarretera\nNone\n2178.0\n3\n15\n32670.0\n0.0\n32670.0\n21780.0\n10890.0\n2014-06-01\n6\nJune\n2014\n\n\n3\nMidmarket\nGermany\nCarretera\nNone\n888.0\n3\n15\n13320.0\n0.0\n13320.0\n8880.0\n4440.0\n2014-06-01\n6\nJune\n2014\n\n\n4\nMidmarket\nMexico\nCarretera\nNone\n2470.0\n3\n15\n37050.0\n0.0\n37050.0\n24700.0\n12350.0\n2014-06-01\n6\nJune\n2014\n\n\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\n如果使用Jupyter，必须确保文件与当前工作目录在同一目录下，或者指定文件的绝对路径。绝对路径 vs 相对路径区别\n\n\n\n\n\n导入线上数据\n线上数据地址 https://www.w3schools.com/python/pandas/data.csv.txt\n\ndf = pd.read_csv('https://www.w3schools.com/python/pandas/data.csv.txt')\n\n# 打印前五个\ndf.head()\n\n\n\n\n\n\n\n\nDuration\nPulse\nMaxpulse\nCalories\n\n\n\n\n0\n60\n110\n130\n409.1\n\n\n1\n60\n117\n145\n479.0\n\n\n2\n60\n103\n135\n340.0\n\n\n3\n45\n109\n175\n282.4\n\n\n4\n45\n117\n148\n406.0\n\n\n\n\n\n\n\n\n# 获取案例数据\nimport pandas as pd\ndf = pd.read_csv('https://raw.githubusercontent.com/pandas-dev/pandas/main/doc/data/titanic.csv') \ndf.head()\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nName\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\n\n\n\n\n0\n1\n0\n3\nBraund, Mr. Owen Harris\nmale\n22.0\n1\n0\nA/5 21171\n7.2500\nNaN\nS\n\n\n1\n2\n1\n1\nCumings, Mrs. John Bradley (Florence Briggs Th...\nfemale\n38.0\n1\n0\nPC 17599\n71.2833\nC85\nC\n\n\n2\n3\n1\n3\nHeikkinen, Miss. Laina\nfemale\n26.0\n0\n0\nSTON/O2. 3101282\n7.9250\nNaN\nS\n\n\n3\n4\n1\n1\nFutrelle, Mrs. Jacques Heath (Lily May Peel)\nfemale\n35.0\n1\n0\n113803\n53.1000\nC123\nS\n\n\n4\n5\n0\n3\nAllen, Mr. William Henry\nmale\n35.0\n0\n0\n373450\n8.0500\nNaN\nS\n\n\n\n\n\n\n\n\n\n参数介绍\n以下参数也适用于大部分pandas导入方式，也就是read_函数。\n\nfilepath_or_buffer：要读取的文件路径或文件对象。\nsep：字段分隔符，默认为逗号（,），可以使用其他字符或字符串作为分隔符。\nheader：指定作为列名的行号，默认为’infer’，表示使用文件中的第一行作为列名，可以设为None来表示没有列名。\nindex_col：指定作为索引列的列号或列名。\nusecols：要读取的列的列号或列名列表。\nnrows：读取制定行数\ndtype：指定列的数据类型。\nparse_dates：指定要解析为日期的列。\nskiprows：跳过指定的行数。\nna_values：指定用于表示缺失值的字符串列表。\nencoding：指定文件的编码方式。\n\n\nimport pandas as pd\n\n# 默认情况下\ndf1 = pd.read_csv('./example_data/data.csv')\ndf1.head()\n\n\n\n\n\n\n\n\nDuration\nPulse\nMaxpulse\nCalories\n\n\n\n\n0\n60\n110\n130\n409.1\n\n\n1\n60\n117\n145\n479.0\n\n\n2\n60\n103\n135\n340.0\n\n\n3\n45\n109\n175\n282.4\n\n\n4\n45\n117\n148\n406.0\n\n\n\n\n\n\n\nheader：指定作为列名的行号，默认为’infer’，表示使用文件中的第一行作为列名，可以设为None来表示没有列名。\n\n# 指定第二行为列名\n\ndf1 = pd.read_csv('./example_data/data.csv', header = 1)\ndf1.head()\n\n\n\n\n\n\n\n\n60\n110\n130\n409.1\n\n\n\n\n0\n60\n117\n145\n479.0\n\n\n1\n60\n103\n135\n340.0\n\n\n2\n45\n109\n175\n282.4\n\n\n3\n45\n117\n148\n406.0\n\n\n4\n60\n102\n127\n300.0\n\n\n\n\n\n\n\nindex_col：指定作为索引列的列号或列名。比如index_col=\"Duration\"，或者第一列index_col=0\n\ndf2 = pd.read_csv('./example_data/data.csv', index_col=\"Duration\")\ndf2.head()\n\n\n\n\n\n\n\n\nPulse\nMaxpulse\nCalories\n\n\nDuration\n\n\n\n\n\n\n\n60\n110\n130\n409.1\n\n\n60\n117\n145\n479.0\n\n\n60\n103\n135\n340.0\n\n\n45\n109\n175\n282.4\n\n\n45\n117\n148\n406.0\n\n\n\n\n\n\n\nusecols：只读取指定的列数据\n\ndf3 = pd.read_csv('./example_data/data.csv', usecols=[\"Pulse\", \"Calories\"])\ndf3.head() \n\n\n\n\n\n\n\n\nPulse\nCalories\n\n\n\n\n0\n110\n409.1\n\n\n1\n117\n479.0\n\n\n2\n103\n340.0\n\n\n3\n109\n282.4\n\n\n4\n117\n406.0\n\n\n\n\n\n\n\nnrows：只读取指定行数的数据\n\ndf4 = pd.read_csv('./example_data/data.csv', nrows=10)\ndf4\n\n\n\n\n\n\n\n\nDuration\nPulse\nMaxpulse\nCalories\n\n\n\n\n0\n60\n110\n130\n409.1\n\n\n1\n60\n117\n145\n479.0\n\n\n2\n60\n103\n135\n340.0\n\n\n3\n45\n109\n175\n282.4\n\n\n4\n45\n117\n148\n406.0\n\n\n5\n60\n102\n127\n300.0\n\n\n6\n60\n110\n136\n374.0\n\n\n7\n45\n104\n134\n253.3\n\n\n8\n30\n109\n133\n195.1\n\n\n9\n60\n98\n124\n269.0\n\n\n\n\n\n\n\nencoding：指定文件的编码方式。使用utf-8编码是因为它是一种广泛支持的字符编码，能够处理几乎所有的文本数据。出现编码问题用这个大概率就对了～\n\ndf5 = pd.read_csv('./example_data/data.csv', encoding='utf-8',index_col=0)\ndf5.head()\n\n\n\n\n\n\n\n\nPulse\nMaxpulse\nCalories\n\n\nDuration\n\n\n\n\n\n\n\n60\n110\n130\n409.1\n\n\n60\n117\n145\n479.0\n\n\n60\n103\n135\n340.0\n\n\n45\n109\n175\n282.4\n\n\n45\n117\n148\n406.0\n\n\n\n\n\n\n\n\n\n常见错误\n\n错误：FileNotFoundError: [Errno 2] No such file or directory: ‘data.csv’\n解决方法：检查文件路径和文件名是否正确，并确保文件存在于指定位置。\n错误：ParserError: Error tokenizing data. C error: Expected N fields in line M, saw K\n解决方法：确保文件中的数据与指定的分隔符一致，并且每行数据的字段数目相同。\n错误：UnicodeDecodeError: ‘utf-8’ codec can’t decode byte 0xff in position 0: invalid start byte\n解决方法：尝试指定正确的文件编码，如encoding=’utf-8-sig’来处理带有BOM（字节顺序标记）的文件。"
  },
  {
    "objectID": "导入_导出数据.html#导出数据",
    "href": "导入_导出数据.html#导出数据",
    "title": "8  导入&导出数据",
    "section": "导出数据",
    "text": "导出数据\n\n导出CSV文件\n在 pandas 中，可以使用 to_csv()方法将数据导出为文本格式（如 CSV 文件）。to_csv() 方法接受一个参数，即导出的文件路径，可以是相对路径或绝对路径\n一般我们的导出对象是 DataFrame 数据框和 Series 序列，将这些数据结构中的数据保存到一个 CSV 文件中。就算是字典或者Numpy的数据结构，也可以转换为DataFrame后进行导出。\n\n创建名为data的字典，作为示例数据；\n调用pandas，将字典转换为DataFrame格式；\n使用to_csv，导出并保存为csv文件，同时命名文件为 output.csv\nindex=False 参数表示不包含行索引。\n\n\nimport pandas as pd\n\n# 创建 DataFrame 示例数据\ndata = {'Name': ['Jack', 'Luxue', 'Wenxi'],\n        'Age': [25, 30, 35],\n        'City': ['New York', 'London', 'Paris']}\n\ndf = pd.DataFrame(data)\n\n# 导出为 CSV 文件，默认为当前路径\ndf.to_csv('output.csv', index=False)\n\nSeries 导出：Series 序列 是 pandas 中的另一个常见数据结构，它是一维标记数组。可以使用 to_csv()、to_excel() 等方法将 Series 导出为 CSV、Excel 等格式。\n\n# 创建 Series 示例数据\ndata = pd.Series([1, 2, 3, 4, 5])\n\n# 导出为 CSV 文件\ndata.to_csv('output.csv', index=False)\n\n# 导出为 Excel 文件\ndata.to_excel('output.xlsx', index=False)\n\n\n\n导出Excel文件\n当涉及到导出为 Excel 文件时，让我们考虑一个简单的案例。假设我们有一个包含学生考试成绩的 DataFrame，我们希望将其导出为一个名为 grades.xlsx 的 Excel 文件。\n\n\n\n\n\n\nWarning\n\n\n\n使用to_excel()时可能会出现报错ModuleNotFoundError: No module named 'openpyxl'，这意味着你的系统中没有安装 openpyxl 模块。\n\n\nopenpyxl 是一个用于处理Excel文件的第三方库，它在Pandas中用于导出Excel文件。为了解决这个错误，你需要安装 openpyxl 模块。\n你可以使用以下命令使用 pip 安装 openpyxl 模块：\n\n%pip install openpyxl\n\n\nimport pandas as pd\n\n# 创建一个示例的 DataFrame\ndata = {'Name': ['Alice', 'Bob', 'Charlie'],\n        'Math': [85, 92, 78],\n        'English': [90, 88, 95],\n        'Science': [80, 85, 92]}\n\ndf = pd.DataFrame(data)\n\n# 使用 to_excel() 方法将 DataFrame 导出为 Excel 文件\ndf.to_excel('grades.xlsx', index=False)\n\n\n\n参数介绍\n\nsheet_name：指定要导出到的工作表名称，默认为 ‘Sheet1’。\nna_rep：指定缺失值的表示，默认为空字符串。\ncolumns：指定要导出的列名。可以传入一个列表来指定特定的列，或者使用布尔索引来选择要导出的列。\nheader：指定是否将列名包含在导出的文件中，默认为 True。\nindex：指定是否将行索引包含在导出的文件中，默认为 True。\nindex_label：指定行索引的标签名称，默认为 None。\nstartrow 和 startcol：指定数据在工作表中的起始行和起始列，默认从第一行第一列开始。\n\nsheet_name如果我们想将数据保存在特定的工作表中，可以使用 sheet_name 参数指定工作表的名称\n\ndf.to_excel('grades.xlsx', sheet_name='Exam Scores', index=False)\n\ncolumns 如果我们只想导出特定的列，可以使用 columns 参数来指定要导出的列名，比如只导出 “Name”、“Math” 和 “English” 列的数据。\n\ndf.to_excel('grades.xlsx', columns=['Name', 'Math', 'English'], index=False)\n\n\n\n\n\n连接MySQL数据库导入导出数据（拓展）\n\n步骤1：安装必要的库\n在开始之前，确保已经安装了以下库：\nPandas：用于数据处理和操作。\nSQLAlchemy：用于数据库连接和交互\n可以使用以下命令通过pip安装它们：\n\npip install pandas sqlalchemy\n\n\n\n步骤2：链接数据库\n首先，我们需要使用SQLAlchemy来建立与数据库的连接。根据使用的数据库类型（如MySQL、SQLite、PostgreSQL等），使用适当的连接字符串和数据库驱动程序。\n以下是使用SQLite数据库的示例代码：\n\nimport sqlalchemy\n\n# 建立与数据库的连接\nengine = sqlalchemy.create_engine('sqlite:///path/to/database.db')\n\n\n\n\n\n\n\nTip\n\n\n\n将path/to/database.db替换为实际的数据库文件路径或连接字符串\n\n\n\n\n步骤3：导入数据\n有几种方法可以使用Pandas从数据库中导入数据。最简单的方法是使用read_sql()函数，该函数接受一个SQL查询语句并将结果读取为DataFrame对象。\n以下是使用read_sql()函数导入数据的示例代码：\n\nimport pandas as pd\n\n# 执行SQL查询并将结果读取为DataFrame\nquery = 'SELECT * FROM table_name'\ndf = pd.read_sql(query, engine)\n\n# 打印DataFrame\nprint(df)\n\n\n\n\n\n\n\nTip\n\n\n\n将table_name替换为要查询的实际表名。\n\n\n\n\n步骤4：导出数据\n同样，使用Pandas可以将DataFrame中的数据导出到数据库中。可以使用to_sql()函数将DataFrame写入数据库表。\n以下是使用to_sql()函数导出数据的示例代码\n\n# 将DataFrame写入数据库表\ndf.to_sql('table_name', engine, if_exists='replace', index=False)\n\n\n\n\n\n\n\nTip\n\n\n\n将table_name替换为要写入的实际表名。if_exists=’replace’表示如果表已经存在，则替换它。index=False表示不将DataFrame的索引写入数据库。"
  },
  {
    "objectID": "选取数据.html#筛选行数据",
    "href": "选取数据.html#筛选行数据",
    "title": "9  选取数据",
    "section": "筛选行数据",
    "text": "筛选行数据\n第一种：通过行索引获取行数据，冒号指定范围，一般的模式是，起始索引:结束索引，结束索引不含在内，开始索引为0或结束索引为行数时可省略数字。\n\n# 选取前3行数据，行索引取0、1、2，结束索引3是取不到的。\ndf[:3]  # 等价于df[0:3]\n# 选取第5行(索引4)到第8行(索引7)\ndf[4:8] \n\n\n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nName\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\n\n\n\n\n4\n5\n0\n3\nAllen, Mr. William Henry\nmale\n35.0\n0\n0\n373450\n8.0500\nNaN\nS\n\n\n5\n6\n0\n3\nMoran, Mr. James\nmale\nNaN\n0\n0\n330877\n8.4583\nNaN\nQ\n\n\n6\n7\n0\n1\nMcCarthy, Mr. Timothy J\nmale\n54.0\n0\n0\n17463\n51.8625\nE46\nS\n\n\n7\n8\n0\n3\nPalsson, Master. Gosta Leonard\nmale\n2.0\n3\n1\n349909\n21.0750\nNaN\nS\n\n\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\n注意在dataframe中第0行才是第一行，所以切片的索引比行数小一个数。\n\n\n\niloc方法基于行索引筛选行\niloc方法是按行索引位置选取数据，索引就是表格最左边的数字。\n\ndf.iloc[[1, 4]]\n# 等价于df.iloc[[1, 4], :]，选取行数据时可以不提取列。\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nName\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\n\n\n\n\n1\n2\n1\n1\nCumings, Mrs. John Bradley (Florence Briggs Th...\nfemale\n38.0\n1\n0\nPC 17599\n71.2833\nC85\nC\n\n\n4\n5\n0\n3\nAllen, Mr. William Henry\nmale\n35.0\n0\n0\n373450\n8.0500\nNaN\nS\n\n\n\n\n\n\n\n\n\nloc方法基于行标签筛选行\nloc方法是按行标签选取数据，因为这里没有设置行标签，所以这里行标签默认等于行索引。\n\ndf.loc[[1, 4]]\n# 等价于df.loc[[1, 4], :]\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nName\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\n\n\n\n\n1\n2\n1\n1\nCumings, Mrs. John Bradley (Florence Briggs Th...\nfemale\n38.0\n1\n0\nPC 17599\n71.2833\nC85\nC\n\n\n4\n5\n0\n3\nAllen, Mr. William Henry\nmale\n35.0\n0\n0\n373450\n8.0500\nNaN\nS\n\n\n\n\n\n\n\n\n除了列表形式，还可以用区间形式如a:b，引用连续的行标签。\n\ndf_summary = df.describe()\ndf_summary.loc[\"count\":\"mean\"]\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nAge\nSibSp\nParch\nFare\n\n\n\n\ncount\n891.0\n891.000000\n891.000000\n714.000000\n891.000000\n891.000000\n891.000000\n\n\nmean\n446.0\n0.383838\n2.308642\n29.699118\n0.523008\n0.381594\n32.204208"
  },
  {
    "objectID": "选取数据.html#选取列数据",
    "href": "选取数据.html#选取列数据",
    "title": "9  选取数据",
    "section": "选取列数据",
    "text": "选取列数据\n通过列索引或列名可以获取DataFrame的单列数据或多列数据。\n假如我想知道每位乘客的姓名（选取单列），df为数据表格，Name为列名。\n\n引用列名提取单列\n\ndf['Name']\ndf.Name\n\n0                                Braund, Mr. Owen Harris\n1      Cumings, Mrs. John Bradley (Florence Briggs Th...\n2                                 Heikkinen, Miss. Laina\n3           Futrelle, Mrs. Jacques Heath (Lily May Peel)\n4                               Allen, Mr. William Henry\n                             ...                        \n886                                Montvila, Rev. Juozas\n887                         Graham, Miss. Margaret Edith\n888             Johnston, Miss. Catherine Helen \"Carrie\"\n889                                Behr, Mr. Karl Howell\n890                                  Dooley, Mr. Patrick\nName: Name, Length: 891, dtype: object\n\n\n\n\nloc和iloc方法提取单列\n\n# 使用.loc或.iloc取列: 逗号前筛选行,逗号后面筛选列\n# 行数取全部时只用一个冒号就可以，列取Name列：\ndf.loc[:, 'Name']\n# # 使用.iloc根据列索引来提取第4列(索引3)\ndf.iloc[:, 3]\n\n0                                Braund, Mr. Owen Harris\n1      Cumings, Mrs. John Bradley (Florence Briggs Th...\n2                                 Heikkinen, Miss. Laina\n3           Futrelle, Mrs. Jacques Heath (Lily May Peel)\n4                               Allen, Mr. William Henry\n                             ...                        \n886                                Montvila, Rev. Juozas\n887                         Graham, Miss. Margaret Edith\n888             Johnston, Miss. Catherine Helen \"Carrie\"\n889                                Behr, Mr. Karl Howell\n890                                  Dooley, Mr. Patrick\nName: Name, Length: 891, dtype: object\n\n\n\n\n提取多列数据\n如果需要获取多列，比如所有乘客的幸存情况（Name、Survived），我们再添加一对中括号把所有的列括起来以获取多个列的数据，数据子集依旧为数据框dataframe。\n下面的代码示例用.head()显示前5行。\n\n# 方法一：\ndf[['Name','Survived']]\n\n# 方法二：\n# df.loc[:, ['column_name1', 'column_name2', ...]]\ndf.loc[:, ['Name','Survived']]\n\n# df.iloc[:, [column_index1, column_index2]]\ndf.iloc[:, [3, 1]].head()\n\n\n\n\n\n\n\n\nName\nSurvived\n\n\n\n\n0\nBraund, Mr. Owen Harris\n0\n\n\n1\nCumings, Mrs. John Bradley (Florence Briggs Th...\n1\n\n\n2\nHeikkinen, Miss. Laina\n1\n\n\n3\nFutrelle, Mrs. Jacques Heath (Lily May Peel)\n1\n\n\n4\nAllen, Mr. William Henry\n0\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n内部方括号定义了一个带有列名或列索引的Python列表，而外部方括号用于从 dataframe 中筛选数据。\n筛选行的时候可以不提取列，但取列的时候必须用”:, “来选取行，单个冒号表示取全部行。\n\n\n\n除了列表形式，还可以用列标签区间提取连续的列，比如提取乘客的基本信息(Name、Sex、Age)：\n\n# 用区间提取连续的多个列\ndf.loc[:, \"Name\":\"Age\"].head() \n\n\n\n\n\n\n\n\nName\nSex\nAge\n\n\n\n\n0\nBraund, Mr. Owen Harris\nmale\n22.0\n\n\n1\nCumings, Mrs. John Bradley (Florence Briggs Th...\nfemale\n38.0\n\n\n2\nHeikkinen, Miss. Laina\nfemale\n26.0\n\n\n3\nFutrelle, Mrs. Jacques Heath (Lily May Peel)\nfemale\n35.0\n\n\n4\nAllen, Mr. William Henry\nmale\n35.0\n\n\n\n\n\n\n\n\n\n\n根据条件筛选行数据\n提取十八岁以下的乘客信息:\n\ndf[df[\"Age\"] &lt; 18].head()\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nName\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\n\n\n\n\n7\n8\n0\n3\nPalsson, Master. Gosta Leonard\nmale\n2.0\n3\n1\n349909\n21.0750\nNaN\nS\n\n\n9\n10\n1\n2\nNasser, Mrs. Nicholas (Adele Achem)\nfemale\n14.0\n1\n0\n237736\n30.0708\nNaN\nC\n\n\n10\n11\n1\n3\nSandstrom, Miss. Marguerite Rut\nfemale\n4.0\n1\n1\nPP 9549\n16.7000\nG6\nS\n\n\n14\n15\n0\n3\nVestrom, Miss. Hulda Amanda Adolfina\nfemale\n14.0\n0\n0\n350406\n7.8542\nNaN\nS\n\n\n16\n17\n0\n3\nRice, Master. Eugene\nmale\n2.0\n4\n1\n382652\n29.1250\nNaN\nQ\n\n\n\n\n\n\n\n\n\n根据多个条件筛选行数据\n多个条件之间用&相连：df[(条件1) & (条件2)] 提取成年(age&gt;=18)男性乘客信息:\n\ndf[(df.Age &gt;= 18) & (df.Sex == \"male\")] # 等价于 df[(df[\"Age\"] &lt; 18) & (df[\"Sex\"] == \"male\")]\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nName\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\n\n\n\n\n0\n1\n0\n3\nBraund, Mr. Owen Harris\nmale\n22.0\n1\n0\nA/5 21171\n7.2500\nNaN\nS\n\n\n4\n5\n0\n3\nAllen, Mr. William Henry\nmale\n35.0\n0\n0\n373450\n8.0500\nNaN\nS\n\n\n6\n7\n0\n1\nMcCarthy, Mr. Timothy J\nmale\n54.0\n0\n0\n17463\n51.8625\nE46\nS\n\n\n12\n13\n0\n3\nSaundercock, Mr. William Henry\nmale\n20.0\n0\n0\nA/5. 2151\n8.0500\nNaN\nS\n\n\n13\n14\n0\n3\nAndersson, Mr. Anders Johan\nmale\n39.0\n1\n5\n347082\n31.2750\nNaN\nS\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n883\n884\n0\n2\nBanfield, Mr. Frederick James\nmale\n28.0\n0\n0\nC.A./SOTON 34068\n10.5000\nNaN\nS\n\n\n884\n885\n0\n3\nSutehall, Mr. Henry Jr\nmale\n25.0\n0\n0\nSOTON/OQ 392076\n7.0500\nNaN\nS\n\n\n886\n887\n0\n2\nMontvila, Rev. Juozas\nmale\n27.0\n0\n0\n211536\n13.0000\nNaN\nS\n\n\n889\n890\n1\n1\nBehr, Mr. Karl Howell\nmale\n26.0\n0\n0\n111369\n30.0000\nC148\nC\n\n\n890\n891\n0\n3\nDooley, Mr. Patrick\nmale\n32.0\n0\n0\n370376\n7.7500\nNaN\nQ\n\n\n\n\n395 rows × 12 columns\n\n\n\nDataFrames 可以通过多种方式进行过滤，其中最直观的是使用布尔索引。\n\n\n\n\n\n\nTip\n\n\n\n这些对原始数据进行筛选和提取的操作并不会改变原数据df，如果需要保存数据子集，需要赋值给新的变量。"
  },
  {
    "objectID": "添加新列.html#添加新列",
    "href": "添加新列.html#添加新列",
    "title": "10  数据的增加、删除、修改",
    "section": "添加新列",
    "text": "添加新列\n目前的案例数据是四行三列，添加新的一列，有两种方法：\n\n直接对数据框df添加列\n\ndf['薪资'] = [5000, 6000, 9000, 7000]  # 有缺失值用一对不包含任何内容的引号代替\ndf\n\n\n\n\n\n\n\n\n姓名\n年龄\n性别\n薪资\n\n\n\n\n0\n张三\n25\nM\n5000\n\n\n1\n李四\n30\nF\n6000\n\n\n2\n王五\n35\nM\n9000\n\n\n3\n赵六\n28\nF\n7000\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n[值]必须对应行数，这里有四个人就必须有四个值，没有则可以为空白'' 或者 'NA'；[]里面的值的顺序也需要和原数据框保持一样\n\n\n\n\n使用assign()添加列\nassign()不会直接改变原数据框df，需要用新数据框覆盖原数据框的数据。\n\ndf = df.assign(工龄=[1, 1, 3, 2])\ndf\n\n\n\n\n\n\n\n\n姓名\n年龄\n性别\n薪资\n工龄\n\n\n\n\n0\n张三\n25\nM\n5000\n1\n\n\n1\n李四\n30\nF\n6000\n1\n\n\n2\n王五\n35\nM\n9000\n3\n\n\n3\n赵六\n28\nF\n7000\n2\n\n\n\n\n\n\n\n\n\n基于已有数据添加列\n\n# 一个例子，假设薪资不变\ndf[\"年薪\"] = df[\"薪资\"]*12\ndf\n\n\n\n\n\n\n\n\n姓名\n年龄\n性别\n薪资\n工龄\n年薪\n\n\n\n\n0\n张三\n25\nM\n5000\n1\n60000\n\n\n1\n李四\n30\nF\n6000\n1\n72000\n\n\n2\n王五\n35\nM\n9000\n3\n108000\n\n\n3\n赵六\n28\nF\n7000\n2\n84000\n\n\n\n\n\n\n\n除了手动添加新列，也可以从其他数据源（如文件、数据库等）中导入数据，并将其作为新列添加到DataFrame中。"
  },
  {
    "objectID": "添加新列.html#添加新行",
    "href": "添加新列.html#添加新行",
    "title": "10  数据的增加、删除、修改",
    "section": "添加新行",
    "text": "添加新行\n\n使用append方法\ndf = df.append(new_row, ignore_index=True)\n其中，new_row是一个包含新行数据的字典或Series对象。\n\n# 重新选取数据\ndata = {'姓名': ['张三', '李四', '王五', '赵六'],\n        '年龄': [25, 30, 35, 28],\n        '性别': ['M', 'F', 'M', 'F']}\n\ndf = pd.DataFrame(data)\n\n\n#`ignore_index=True`是确保新行的索引在原始DataFrame的索引基础上继续增加，而不是使用原来的索引。\n\nnew_row = {'姓名': '熊大', '年龄': 35, '性别': 'M'}\n\ndf = df.append(new_row, ignore_index=True)\ndf\n\nC:\\Users\\nan\\AppData\\Local\\Temp\\ipykernel_15056\\518159157.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(new_row, ignore_index=True)\n\n\n\n\n\n\n\n\n\n姓名\n年龄\n性别\n\n\n\n\n0\n张三\n25\nM\n\n\n1\n李四\n30\nF\n\n\n2\n王五\n35\nM\n\n\n3\n赵六\n28\nF\n\n\n4\n熊大\n35\nM\n\n\n\n\n\n\n\n\n\n使用concat()合并数据框\n将新行转换为数据框，然后将其与原数据框df进行合并。\n\nnew_row = {'姓名': '熊二', '年龄': 30, '性别': 'M'}\nnew_df = pd.DataFrame([new_row])\n\n# df = pd.concat([df, new_df]) # 不设置ignore_index的话，新行索引沿用旧索引 0\ndf = pd.concat([df, new_df], ignore_index=True)\ndf\n\n\n\n\n\n\n\n\n姓名\n年龄\n性别\n\n\n\n\n0\n张三\n25\nM\n\n\n1\n李四\n30\nF\n\n\n2\n王五\n35\nM\n\n\n3\n赵六\n28\nF\n\n\n4\n熊大\n35\nM\n\n\n5\n熊二\n30\nM"
  },
  {
    "objectID": "添加新列.html#删除行列",
    "href": "添加新列.html#删除行列",
    "title": "10  数据的增加、删除、修改",
    "section": "删除行/列",
    "text": "删除行/列\n\n使用drop方法删除列\ndf = df.drop('column_name', axis=1)\n需要提供要删除的列名，然后指定axis=1表示按列轴进行操作。删除列后，DataFrame会自动调整列的顺序。\n\ndf = df.drop('性别', axis=1)\ndf\n\n\n\n\n\n\n\n\n姓名\n年龄\n\n\n\n\n0\n张三\n25\n\n\n1\n李四\n30\n\n\n2\n王五\n35\n\n\n3\n赵六\n28\n\n\n4\n熊大\n35\n\n\n5\n熊二\n30\n\n\n\n\n\n\n\n\n\n使用drop方法删除行\ndf = df.drop(row_index)\n使用drop方法根据行的索引来删除特定的行\n\n# 删除第六行数据\ndf = df.drop(5)\ndf\n\n\n\n\n\n\n\n\n姓名\n年龄\n\n\n\n\n0\n张三\n25\n\n\n1\n李四\n30\n\n\n2\n王五\n35\n\n\n3\n赵六\n28\n\n\n4\n熊大\n35"
  },
  {
    "objectID": "添加新列.html#修改数据值",
    "href": "添加新列.html#修改数据值",
    "title": "10  数据的增加、删除、修改",
    "section": "修改数据值",
    "text": "修改数据值\n\nat方法\n\n# 指定行列\ndf.at[4, '年龄'] = 32\ndf\n\n\n\n\n\n\n\n\n姓名\n年龄\n\n\n\n\n0\n张三\n25\n\n\n1\n李四\n30\n\n\n2\n王五\n35\n\n\n3\n赵六\n28\n\n\n4\n熊大\n32\n\n\n\n\n\n\n\n\n\n根据条件过滤修改数据\n\ndf.loc[df['姓名'] == '熊大', '年龄'] = 31\ndf\n\n\n\n\n\n\n\n\n姓名\n年龄\n\n\n\n\n0\n张三\n25\n\n\n1\n李四\n30\n\n\n2\n王五\n35\n\n\n3\n赵六\n28\n\n\n4\n熊大\n31"
  },
  {
    "objectID": "添加新列.html#重命名列",
    "href": "添加新列.html#重命名列",
    "title": "10  数据的增加、删除、修改",
    "section": "重命名列",
    "text": "重命名列\n\n使用rename\ndf = df.rename(columns={'old_column_name':'new_column_name'})\n其中，old_column_name是旧列名，new_column_name是新的列名。\ndf.rename(index={'old_label':'new_label'})也能用来修改行标签，但通常情况下我们不会对行标签进行修改。\n\ndf = df.rename(columns={'姓名': '职员姓名', '年龄':'职员年龄'})\ndf\n\n\n\n\n\n\n\n\n职员姓名\n职员年龄\n\n\n\n\n0\n张三\n25\n\n\n1\n李四\n30\n\n\n2\n王五\n35\n\n\n3\n赵六\n28\n\n\n4\n熊大\n31\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\ndrop()和rename()也可以通过设置inplace=True直接修改原数据框。"
  },
  {
    "objectID": "添加新列.html#按值排序",
    "href": "添加新列.html#按值排序",
    "title": "10  数据的增加、删除、修改",
    "section": "按值排序",
    "text": "按值排序\n\n使用sort_values方法\ndf = df.sort_values(by='column_name', ascending=True)\n其中，column_name是你想要按其值进行排序的列名。ascending=True表示按升序——从小到大排列，若要按降序——从大到小排列，将ascending设置为False即可。\n通过sort_values方法可以根据特定列的值对DataFrame进行排序。可以选择按单个列或多个列的值排序，只需在by参数中提供相应的列名列表即可。\n\ndf = df.sort_values(by='职员年龄', ascending=True)\ndf\n\n\n\n\n\n\n\n\n职员姓名\n职员年龄\n\n\n\n\n0\n张三\n25\n\n\n3\n赵六\n28\n\n\n1\n李四\n30\n\n\n4\n熊大\n31\n\n\n2\n王五\n35\n\n\n\n\n\n\n\n\ndf['薪资'] = [9000, 8000, 9000, 11000, 10000]\n# 先按薪资降序排列，薪资相同则按年龄升序排列\ndf = df.sort_values(by=['薪资', '职员年龄'], ascending=[False, True]) # 如果排序方式相同，只需要一个布尔值就好 \ndf\n\n\n\n\n\n\n\n\n职员姓名\n职员年龄\n薪资\n\n\n\n\n4\n熊大\n31\n11000\n\n\n2\n王五\n35\n10000\n\n\n0\n张三\n25\n9000\n\n\n1\n李四\n30\n9000\n\n\n3\n赵六\n28\n8000"
  },
  {
    "objectID": "Pandas计算重塑合并最终版本.html",
    "href": "Pandas计算重塑合并最终版本.html",
    "title": "11  如何计算汇总统计",
    "section": "",
    "text": "describe()的用法\ndescribe() 是 Pandas 中一个常用的基础操作，用于生成关于 DataFrame 列的统计摘要。\n使用 describe() 方法，你可以获得以下统计信息：\n计数（count）：非缺失值的数量。\n均值（mean）：平均值。\n标准差（std）：标准差衡量数据的离散程度。\n最小值（min）和最大值（max）：数据列的最小和最大值。\n四分位数（25%，50%，75%）：数据的四个百分位数，用于描述数据的分布。\n示例代码：\n\nimport pandas as pd\n\n# 创建DataFrame示例\ndata = {'Name': ['John', 'Emma', 'Alex', 'Sophia', 'James'],\n        'Age': [25, 28, 22, 30, 32],\n        'Height': [175, 162, 180, 158, 170],\n        'Weight': [70, 58, 75, 52, 68]}\ndf = pd.DataFrame(data)\n\n# 查看数值型列的汇总统计\nsummary_stats = df.describe()\nmean_age = df['Age'].mean()\nmedian_height = df['Height'].median()\nmax_weight = df['Weight'].max()\n\nprint(summary_stats)\nprint(\"Mean Age:\", mean_age)\nprint(\"Median Height:\", median_height)\nprint(\"Max Weight:\", max_weight)\n\n             Age      Height     Weight\ncount   5.000000    5.000000   5.000000\nmean   27.400000  169.000000  64.600000\nstd     3.974921    9.055385   9.370165\nmin    22.000000  158.000000  52.000000\n25%    25.000000  162.000000  58.000000\n50%    28.000000  170.000000  68.000000\n75%    30.000000  175.000000  70.000000\nmax    32.000000  180.000000  75.000000\nMean Age: 27.4\nMedian Height: 170.0\nMax Weight: 75\n\n\n常用的计算汇总统计的方法：\n\ndescribe()方法：计算数值型列的基本统计信息，包括计数、均值、标准差、最小值、25%、50%和75%分位数以及最大值。\nmean()方法：计算数值型列的平均值。\nmedian()方法：计算数值型列的中位数。\nmin()方法：计算数值型列的最小值。\nmax()方法：计算数值型列的最大值。\nsum()方法：计算数值型列的总和。\ncount()方法：计算非缺失值的数量。\nstd()方法：计算数值型列的标准差。\nvar()方法：计算数值型列的方差。\n\n通过查看数值型列的汇总统计，可以快速了解数据的整体分布和统计特征，有助于进行数据分析和洞察。\n\n\nsize和count\n在Pandas中，size和count是用于计算分组数据的两个方法，常常与groupby一起使用。它们可以提供关于每个分组的计数信息，但在计算方式和返回结果上有一些区别。\nsize方法：\n\nsize方法用于计算每个分组中的元素数量，包括缺失值。\n返回的结果是一个Series，其索引是分组键，值是每个分组中的元素数量。\nsize方法不考虑缺失值，即使某个分组中存在缺失值，它也会将其计算为有效元素。\n\ncount方法：\n\ncount方法用于计算每个分组中非缺失值的数量。\n返回的结果是一个Series，其索引是分组键，值是每个分组中的非缺失值的数量。\ncount方法排除了缺失值，只计算非缺失值的数量。\n\n示例，演示如何使用size和count方法结合groupby对数据进行计数：\n\nimport pandas as pd\n\n# 创建一个示例DataFrame\ndata = {'Group': ['A', 'A', 'B', 'B', 'B'],\n        'Value': [1, 2, 3, None, 5]}\ndf = pd.DataFrame(data)\n\n# 使用groupby和size计算每个分组的元素数量\nsize_result = df.groupby('Group').size()\n\n# 使用groupby和count计算每个分组的非缺失值数量\ncount_result = df.groupby('Group').count()\n\nprint(\"Size结果:\")\nprint(size_result)\nprint(\"\\nCount结果:\")\nprint(count_result)\n\nSize结果:\nGroup\nA    2\nB    3\ndtype: int64\n\nCount结果:\n       Value\nGroup       \nA          2\nB          2\n\n\n在上述示例中，我们创建了一个DataFrame，并使用Group列进行分组。然后，我们分别使用size和count方法对分组后的数据进行计数。可以看到，size方法返回了每个分组的元素数量，而count方法返回了每个分组的非缺失值数量。在分组B中，有一个缺失值，因此size方法返回3，而count方法返回2。\n这两个方法的使用可以根据具体需求来选择。如果需要考虑缺失值并计算所有元素的数量，可以使用size方法；如果只关心非缺失值的数量，可以使用count方法。\n\n\n如何重塑表格布局\n\nsort的用法\n在Pandas中，sort_values和sort_index是用于对DataFrame或Series进行排序的两个常用方法。\nsort_values方法：\n\nsort_values方法用于按照指定的列或多个列的值对DataFrame或Series进行排序。\n可以通过by参数指定要排序的列或多个列，以列表形式提供。\n可以使用ascending参数来控制排序的升序或降序，默认为True（升序）。\n可以使用inplace参数来指定是否原地修改DataFrame或Series，默认为False，即返回排序后的副本。\n示例：\n\n\nimport pandas as pd\n\ndf = pd.DataFrame({'A': [3, 2, 1], 'B': [1, 3, 2]})\nsorted_df = df.sort_values(by='A', ascending=True)\n\n\n上述代码将按照’A’列的值对DataFrame df 进行升序排序，并将结果存储在sorted_df中。\n\nsort_index方法：\n\nsort_index方法用于根据索引对DataFrame或Series进行排序。\n可以使用axis参数指定要排序的轴，axis=0表示按行索引排序，axis=1表示按列索引排序。\n可以使用ascending参数来控制排序的升序或降序，默认为True（升序）。\n可以使用inplace参数来指定是否原地修改DataFrame或Series，默认为False，即返回排序后的副本。\n示例：\n\n\nimport pandas as pd\n\ndf = pd.DataFrame({'A': [3, 2, 1], 'B': [1, 3, 2]}, index=[2, 1, 3])\nsorted_df = df.sort_index(axis=0, ascending=True)\n\n\n上述代码将按照行索引对DataFrame df 进行升序排序，并将结果存储在sorted_df中。\n\n排序操作可以根据具体需求来选择使用sort_values还是sort_index。如果希望根据列的值进行排序，使用sort_values方法；如果希望根据索引进行排序，使用sort_index方法。\n\n在Pandas中，可以使用不同的方法来重新塑造（reshape）表格布局，以满足特定的数据分析和处理需求。以下是一些常用的重塑表格布局的方法：\n\n\npivot()方法\npivot()方法：用于将长格式（long format）的数据转换为宽格式（wide format），根据指定的列创建新的列，并使用列值进行填充。\n示例，展示如何使用pivot()方法将数据从长格式转换为宽格式：\n\nimport pandas as pd\n\n# 创建示例DataFrame\ndata = {'Name': ['John', 'John', 'Emma', 'Emma', 'Alex', 'Alex'],\n        'Subject': ['Math', 'Science', 'Math', 'Science', 'Math', 'Science'],\n        'Score': [85, 92, 78, 88, 90, 85]}\ndf = pd.DataFrame(data)\n\n# 使用pivot方法重塑表格布局\npivot_df = df.pivot(index='Name', columns='Subject', values='Score')\npivot_df\n\n\n\n\n\n\n\nSubject\nMath\nScience\n\n\nName\n\n\n\n\n\n\nAlex\n90\n85\n\n\nEmma\n78\n88\n\n\nJohn\n85\n92\n\n\n\n\n\n\n\n\n\nmelt()方法\n在Pandas中，melt()是一个用于将宽格式（wide format）的数据转换为长格式（long format）的方法。它将数据从列中展开成为更长的格式，使得数据更适合进行分析和可视化。\nmelt()方法的语法如下：\nDataFrame.melt(id_vars=None, value_vars=None, var_name=None, value_name='value', col_level=None)\n参数说明：\n\nid_vars：可选参数，指定要保留的列名，不进行展开操作。\nvalue_vars：可选参数，指定要进行展开操作的列名。如果未指定，则默认展开所有未指定为id_vars的列。\nvar_name：可选参数，指定展开后的列名的名称。\nvalue_name：可选参数，指定展开后的值的列名的名称，默认为value。\ncol_level：可选参数，用于多层索引列的级别。\n\n下面是一个示例，演示如何使用melt()方法将宽格式的数据转换为长格式：\n\nimport pandas as pd\n\n# 创建一个示例DataFrame\ndata = {\n    'Name': ['Alice', 'Bob', 'Charlie'],\n    'Math': [90, 80, 70],\n    'Science': [95, 85, 75],\n    'History': [92, 82, 72]\n}\ndf = pd.DataFrame(data)\n\n# 使用melt()方法进行数据转换\nmelted_df = df.melt(id_vars='Name', value_vars=['Math', 'Science', 'History'], var_name='Subject', value_name='Score')\n\nprint(\"原始DataFrame:\")\nprint(df)\nprint(\"\\n转换后的DataFrame:\")\nmelted_df\n\n原始DataFrame:\n      Name  Math  Science  History\n0    Alice    90       95       92\n1      Bob    80       85       82\n2  Charlie    70       75       72\n\n转换后的DataFrame:\n\n\n\n\n\n\n\n\n\nName\nSubject\nScore\n\n\n\n\n0\nAlice\nMath\n90\n\n\n1\nBob\nMath\n80\n\n\n2\nCharlie\nMath\n70\n\n\n3\nAlice\nScience\n95\n\n\n4\nBob\nScience\n85\n\n\n5\nCharlie\nScience\n75\n\n\n6\nAlice\nHistory\n92\n\n\n7\nBob\nHistory\n82\n\n\n8\nCharlie\nHistory\n72\n\n\n\n\n\n\n\n\n\nstack()方法\nstack()方法：\n在Pandas中，stack()是一个用于对DataFrame进行堆叠操作的方法。它将列标签（Column labels）转换为行索引（Row index），将数据从宽格式转换为长格式，从而生成一个更紧凑的DataFrame。\nstack()方法的语法如下：\nDataFrame.stack(level=-1, dropna=True)\n参数说明：\n\nlevel：可选参数，用于多层索引列的级别。默认值为-1，表示堆叠所有列。\ndropna：可选参数，指定是否删除包含缺失值的行，默认为True。\n\n示例：\n\nimport pandas as pd\n\n# 创建一个示例DataFrame\ndata = {\n    'Name': ['Alice', 'Bob'],\n    'Math': [90, 80],\n    'Science': [95, 85],\n    'History': [92, 82]\n}\ndf = pd.DataFrame(data)\n\n# 使用stack()方法进行堆叠操作\nstacked_df = df.set_index('Name').stack().reset_index()\n\nprint(\"原始DataFrame:\")\nprint(df)\nprint(\"\\n堆叠后的DataFrame:\")\nstacked_df\n\n原始DataFrame:\n    Name  Math  Science  History\n0  Alice    90       95       92\n1    Bob    80       85       82\n\n堆叠后的DataFrame:\n\n\n\n\n\n\n\n\n\nName\nlevel_1\n0\n\n\n\n\n0\nAlice\nMath\n90\n\n\n1\nAlice\nScience\n95\n\n\n2\nAlice\nHistory\n92\n\n\n3\nBob\nMath\n80\n\n\n4\nBob\nScience\n85\n\n\n5\nBob\nHistory\n82\n\n\n\n\n\n\n\n\n\nunstack()方法\n在Pandas中，unstack()是用于将表格中的行索引转换为列索引，将数据从长格式转换为宽格式。\nunstack()方法的语法如下：\nDataFrame.unstack(level=-1, fill_value=None)\n参数说明：\n\nlevel：可选参数，用于指定要展开的层次化索引的级别。默认值为-1，表示展开最内层索引。\nfill_value：可选参数，用于指定填充缺失值的值。\n\n示例：\n\nimport pandas as pd\n\n# 创建一个示例DataFrame\ndata = {\n    'Name': ['Alice', 'Bob'],\n    'Subject': ['Math', 'Science'],\n    'Score': [90, 80]\n}\ndf = pd.DataFrame(data)\n\n# 将DataFrame进行设置层次化索引\nindexed_df = df.set_index(['Name', 'Subject'])\n\n# 使用unstack()方法进行展开操作\nunstacked_df = indexed_df.unstack()\n\nprint(\"原始DataFrame:\")\nprint(df)\nprint(\"\\n展开后的DataFrame:\")\nunstacked_df\n\n原始DataFrame:\n    Name  Subject  Score\n0  Alice     Math     90\n1    Bob  Science     80\n\n展开后的DataFrame:\n\n\n\n\n\n\n\n\n\nScore\n\n\nSubject\nMath\nScience\n\n\nName\n\n\n\n\n\n\nAlice\n90.0\nNaN\n\n\nBob\nNaN\n80.0\n\n\n\n\n\n\n\n在上述示例中，原始数据包含学生的姓名、科目和分数。通过使用pivot()方法，将姓名作为行索引，科目作为列索引，并将分数填充到相应的单元格中，得到了以学生姓名为行、科目为列的宽格式表格布局。\n\n\n\n如何合并多个表中的数据\n在Pandas中，可以使用不同的方法来合并（merge）多个表中的数据。以下是一些常用的合并数据的方法：\n\nconcat()方法\n在Pandas中，concat()是一个用于沿指定轴（行或列）将多个DataFrame对象进行合并的方法。它可以将多个DataFrame对象按照指定的方式进行连接，并返回一个合并后的DataFrame。以下是关于concat()方法的解释和示例说明：\nconcat()方法的语法如下：\npd.concat(objs, axis=0, join='outer', ignore_index=False)\n参数说明：\n\nobjs：要合并的DataFrame对象列表或字典。\naxis：可选参数，指定合并的轴。默认为0，表示按行合并；1表示按列合并。\njoin：可选参数，指定连接的方式。默认为'outer'，表示按照并集进行连接；'inner'表示按照交集进行连接。\nignore_index：可选参数，指定是否忽略合并后的索引。默认为False，表示保留原始索引。\n\n示例：\n\nimport pandas as pd\n\n# 创建示例DataFrame\ndf1 = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\ndf2 = pd.DataFrame({'A': [7, 8, 9], 'B': [10, 11, 12]})\n\n# 使用concat()方法进行合并操作\nmerged_df = pd.concat([df1, df2])\n\nprint(\"合并后的DataFrame:\")\nmerged_df\n\n合并后的DataFrame:\n\n\n\n\n\n\n\n\n\nA\nB\n\n\n\n\n0\n1\n4\n\n\n1\n2\n5\n\n\n2\n3\n6\n\n\n0\n7\n10\n\n\n1\n8\n11\n\n\n2\n9\n12\n\n\n\n\n\n\n\n\n\nmerge()方法\n在Pandas中，merge()是一个用于合并（或连接）多个DataFrame对象的方法。它基于指定的键（或多个键）将多个DataFrame按照指定的方式进行连接，并返回一个合并后的DataFrame。\nmerge()方法的语法如下：\npd.merge(left, right, how='inner', on=None, left_on=None, right_on=None, left_index=False, right_index=False, sort=True)\n参数说明：\n\nleft：左侧的DataFrame对象。\nright：右侧的DataFrame对象。\nhow：可选参数，指定连接方式。默认为'inner'，表示按照键的交集进行连接；'outer'表示按照键的并集进行连接；'left'表示按照左侧DataFrame的键进行连接；'right'表示按照右侧DataFrame的键进行连接。\non：可选参数，用于指定连接的键。可以是一个列名的字符串，或多个列名组成的列表。\nleft_on：可选参数，用于指定左侧DataFrame连接键的列名或列名列表。\nright_on：可选参数，用于指定右侧DataFrame连接键的列名或列名列表。\nleft_index：可选参数，指定是否使用左侧DataFrame的索引作为连接键。\nright_index：可选参数，指定是否使用右侧DataFrame的索引作为连接键。\nsort：可选参数，指定是否按照连接键进行排序。\n\n示例：\n\nimport pandas as pd\n\n# 创建示例DataFrame\ndf1 = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6], 'Key': ['K1', 'K2', 'K3']})\ndf2 = pd.DataFrame({'C': [7, 8, 9], 'D': [10, 11, 12], 'Key': ['K2', 'K3', 'K4']})\n\n# 使用merge()方法进行合并操作\nmerged_df = pd.merge(df1, df2, on='Key')\n\nprint(\"合并后的DataFrame:\")\nmerged_df\n\n合并后的DataFrame:\n\n\n\n\n\n\n\n\n\nA\nB\nKey\nC\nD\n\n\n\n\n0\n2\n5\nK2\n7\n10\n\n\n1\n3\n6\nK3\n8\n11\n\n\n\n\n\n\n\n\n\njoin()方法\n在Pandas中，join()是一个用于基于索引或列之间的关系将两个DataFrame对象进行连接的方法。它类似于SQL中的JOIN操作，可以根据指定的连接键将两个DataFrame进行合并，并返回一个合并后的DataFrame。\njoin()方法的语法如下：\nDataFrame.join(other, on=None, how='left', lsuffix='', rsuffix='', sort=False)\n参数说明：\n\nother：要连接的另一个DataFrame对象。\non：可选参数，用于指定连接键。可以是一个列名的字符串，或多个列名组成的列表。如果未指定，则根据索引进行连接。\nhow：可选参数，指定连接方式。默认为'left'，表示按照左侧DataFrame的索引或列进行连接；'right'表示按照右侧DataFrame的索引或列进行连接；'inner'表示按照两个DataFrame共有的索引或列进行连接；'outer'表示按照两个DataFrame的并集进行连接。\nlsuffix：可选参数，用于处理连接时重叠列名的后缀（左侧DataFrame）。\nrsuffix：可选参数，用于处理连接时重叠列名的后缀（右侧DataFrame）。\nsort：可选参数，指定是否按照连接键进行排序。\n\n示例：\n\nimport pandas as pd\n\n# 创建示例DataFrame\ndf1 = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]}, index=['K1', 'K2', 'K3'])\ndf2 = pd.DataFrame({'C': [7, 8, 9], 'D': [10, 11, 12]}, index=['K2', 'K3', 'K4'])\n\n# 使用join()方法进行连接操作\njoined_df = df1.join(df2)\n\nprint(\"连接后的DataFrame:\")\njoined_df\n\n连接后的DataFrame:\n\n\n\n\n\n\n\n\n\nA\nB\nC\nD\n\n\n\n\nK1\n1\n4\nNaN\nNaN\n\n\nK2\n2\n5\n7.0\n10.0\n\n\nK3\n3\n6\n8.0\n11.0\n\n\n\n\n\n\n\n\n\n补充：T（Transpose）转置\n在Pandas中，T（Transpose）是一个用于转置数据的方法。转置操作会将DataFrame或Series的行和列进行交换，从而生成一个新的转置后的数据结构。以下是关于Pandas中的T转置的一些知识点：\n\nDataFrame的转置： 转置DataFrame时，行索引将会变成转置前的列索引，列索引将会变成转置前的行索引。可以使用T方法来执行转置操作，例如：\n\n\nimport pandas as pd\n\ndf = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\ntransposed_df = df.T\n\n上述代码将创建一个DataFrame df，然后使用T方法将其转置，结果将会存储在transposed_df中。\n\nSeries的转置： 转置一个Series对象会生成一个具有单一列的DataFrame，行索引将会保持不变，而列索引将会变为转置前的索引值。可以使用T方法对Series进行转置，例如：\n\n\nimport pandas as pd\n\nseries = pd.Series([1, 2, 3, 4], index=['A', 'B', 'C', 'D'])\ntransposed_series = series.T\n\n上述代码将创建一个Series series，然后使用T方法将其转置，结果将会存储在transposed_series中。\n\n转置对数据结构的影响： 转置操作不会改变原始数据结构，而是生成一个新的转置后的数据结构。原始数据结构保持不变，只是行和列的排列顺序发生了变化。\n转置的应用： 转置操作常用于需要改变数据结构的情况，例如在数据分析和处理过程中，可以使用转置来更改数据的布局以满足特定的分析需求。\n\n需要注意的是，转置操作可能会导致数据结构的变化，因此在进行转置操作之后，索引和列名可能需要进行调整以适应新的结构。"
  },
  {
    "objectID": "时间序列数据.html#一日期和时间数据类型",
    "href": "时间序列数据.html#一日期和时间数据类型",
    "title": "12  Pandas处理时间序列数据",
    "section": "一、日期和时间数据类型",
    "text": "一、日期和时间数据类型\n\n1. Timestamp对象\nTimestamp对象是Pandas中用于表示日期和时间的单个时间点的数据类型，是Pandas处理时间序列数据的基本数据类型之一，其精度达到纳秒(0.000000001秒)级别。\n在Pandas中，通常使用pandas.Timestamp来表示Timestamp对象。\n\n(1) 创建Timestamp对象\n在Pandas中，Timestamp对象的值包括日期和时间信息，创建Timestamp对象的方法共有三种：\n\nimport pandas as pd\nimport datetime\n\n# 从字符串创建\npd.Timestamp('2023-07-20')\n\n# 从Python的datetime对象创建\npd.Timestamp(datetime.datetime(2023, 7, 21))\n\n# 从时间戳创建\npd.Timestamp(1612060800)    # 时间戳1612060800代表从UNIX纪元开始经过的秒数，具体日期和时间取决于该时间戳对应的具体时区和时刻。\n\n\n\n\n拓展：属性与方法\n\n\n\n属性（Attributes）是对象的特征或状态，用于描述对象的数据。在Python中，对象的属性可以是对象的实例变量（instance variable），也可以是类变量（class variable），用于存储对象的数据。\n\n\n方法（Methods）是对象可以执行的操作或行为，用于描述对象的功能和行为。在Python中，方法是定义在类中的函数，通过访问对象的方法，我们可以执行特定的操作或实现对象的功能。\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n注意，这部分是可选的，大家可以根据自己的需要阅读。\n\nTimestamp对象具有多个属性和方法，用于获取和操作日期时间信息。通过使用属性和方法可以对时间和日期进行提取或格式化等操作。对Timestamp对象常用的属性和方法有： ##### 属性：\n\nyear、month、day：返回Timestamp对象的年份、月份和日期。\nhour、minute、second：返回Timestamp对象的小时、分钟和秒。\nmicrosecond、nanosecond：获取Timestamp对象的微秒数和纳秒数。\ndayofweek：获取Timestamp对象所表示的星期几，返回一个整数（0代表星期一，6代表星期日）。\nweekday_name：返回星期几的名称。\nweek：获取Timestamp对象所在年份的周数。\ndayofyear：获取Timestamp对象在所在年份中的第几天。\n\n\n方法：\n\ndate()：获取Timestamp对象的日期部分，返回一个日期对象。\ntime()：获取Timestamp对象的时间部分，返回一个时间对象。\nstrftime(format)：将Timestamp对象格式化为指定的字符串格式。format参数是一个字符串，用于指定输出的日期时间格式，如”%Y-%m-%d %H:%M:%S”。\n\n\n\n\n\n\n(2) 比较和运算\nTimestamp对象在Pandas中支持比较运算符和算术运算符，可以用于进行日期和时间的比较和计算。\n\n比较运算符\n\n相等性比较：使用==运算符检查两个Timestamp对象是否相等。\n不等性比较：使用!=运算符检查两个Timestamp对象是否不相等。\n大小比较：使用&lt;、&lt;=、&gt;、&gt;=运算符进行Timestamp对象之间的大小比较。\n\n\n\n算术运算符\n\n加法和减法运算：可以使用+和-运算符对Timestamp对象进行加法和减法运算。加法运算可以用于将一个Timestamp对象与时间差（Timedelta对象）相加，得到一个新的Timestamp对象。减法运算可以用于计算两个Timestamp对象之间的时间差，得到一个Timedelta对象。\n时间偏移运算：可以使用+和-运算符对Timestamp对象进行时间偏移运算。通过给Timestamp对象加上或减去一个时间差（Timedelta对象），可以得到一个新的Timestamp对象。\n\n\n在Pandas中，datetime和timedelta是Python标准库中的对象，而不是Pandas特有的对象。Pandas使用这些对象来处理日期和时间序列数据。\n具体来说：\n\ndatetime是Python标准库中的模块，用于处理日期和时间相关的操作。Pandas通过使用datetime模块中的类，如datetime.datetime，来表示日期和时间点。在Pandas中，datetime对象通常用于创建时间戳（Timestamp）或时间序列的索引（DatetimeIndex）。\ntimedelta也是Python标准库中的模块，用于表示时间间隔。timedelta对象表示两个日期或时间点之间的差异。在Pandas中，timedelta对象通常用于执行时间偏移或计算时间差。\n\nPandas通过将这些Python标准库中的对象与其自己的数据结构和函数结合使用，提供了更高级和便捷的功能来处理时间序列数据。例如，Pandas的Timestamp对象是基于Python的datetime.datetime进行了封装和扩展，提供了更多的时间序列操作和处理方法。\n因此，虽然datetime和timedelta不是Pandas特有的对象，但它们在Pandas中被广泛使用，用于处理时间序列数据的表示、操作和计算。\n\n\n\n\n\n2. DatetimeIndex对象\nDatetimeIndex对象是由一组Timestamp对象构成的时间序列索引对象，用于对时间序列数据进行索引、切片和筛选操作。DatetimeIndex对象以时间点的形式对数据进行索引和标记，用于表示时间序列数据的时间维度。\n在Pandas中，DatetimeIndex对象可以作为DataFrame或Series的索引，或作为时间序列数据的标签。\n\n(1) 创建DatetimeIndex对象\n创建DatetimeIndex对象的方式一共有三种：\n\n# 从Python的datetime对象列表或数组创建\npd.DatetimeIndex([datetime1, datetime2, ...])\n\n# 通过日期字符串列表或数组创建\npd.DatetimeIndex(['2023-07-20', '2023-07-21', ...])\n\n# 通过日期范围创建\npd.date_range(start, end, freq) # start和end是起始和结束日期，freq是时间间隔。\n\n\n\n\n\n\n\nNote\n\n\n\n\n注意，这部分是可选的，大家可以根据自己的需要阅读。\n\nDatetimeIndex对象具有多个属性和方法，如下是对其常用的属性和方法。\n\n属性\n\nyear、month、day：返回DatetimeIndex对象中所有时间点的年份、月份和日期。\nhour、minute、second：返回DatetimeIndex对象中所有时间点的小时、分钟和秒。\nmicrosecond、nanosecond：获取DatetimeIndex对象中所有时间点的微秒数和纳秒数。\ndayofweek：获取DatetimeIndex对象中所有时间点所表示的星期几，返回一个整数（0代表星期一，6代表星期日）。\nweekday_name：返回DatetimeIndex对象中所有时间点所表示的星期几的名称。\ndate：返回DatetimeIndex对象中所有时间点的日期部分（日期对象）。\ntime：返回DatetimeIndex对象中所有时间点的时间部分（时间对象）。\n\n\n\n方法\n\nstrftime(format)：将DatetimeIndex对象中的时间点格式化为指定的字符串格式。\nresample(rule)：对DatetimeIndex对象进行重采样，将时间序列数据的频率转换为指定的频率规则。\n\nDatetimeIndex对象常用于对时间序列数据进行索引和切片操作，实现对时间序列数据的筛选、聚合和分析，还可以用于时间序列数据的重采样和频率转换操作，对时间序列数据进行降采样或升采样。另外，DatetimeIndex对象也可以用在时间序列数据的可视化中，将时间轴作为横坐标，方便观察和分析时间趋势。\n\n\n\n\n\n\n3. Period对象\n在Pandas中，Period对象用于表示时间段，表示在某个特定的时间单位内，如年、季度、月、周或天。它由一个起始时间点和一个结束时间点组成。\n\n(1) 创建Period对象\n在Pandas中，创建Period对象的方式有很多种，主要取决于时间段的起始点和频率\n\n# 使用日期字符串创建\npd.Period('2023-07', freq='M')  # 表示以2023年7月1日为起始点的一个月时间段，即从2023年7月1日到2023年7月31日\n\n# 使用整数值创建\npd.Period(2023, freq='A-DEC')   #表示以2023为起始点的一个年度的时间段，即从2023年1月1日开始，2023年12月31日结束，\n\n# 使用时间戳创建\npd.Period(pd.Timestamp('2023-07-21'), freq='D') #表示一个天的时间段，从2023年7月21日开始，为期1天的时间段\n\n\n起始点可以是日期字符串、整数或时间戳，而频率由频率字符串表示，如年度（‘A’）、季度（Q）、月度（M）、周度（W）或日（D）等。\n使用日期字符串和使用时间戳创建Period对象的区别\n\n使用日期字符串\n\n起始点使用的是日期字符串，表示了时间段的起始日期。\n在创建Period对象时，Pandas会根据传递的日期字符串进行解析和转换，将其转换为相应的时间点。\n\n使用时间戳\n\n起始点使用的是时间戳，表示了具体的时间点。\n时间戳是一个精确到纳秒级别的时间值，包含日期和时间信息。\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n注意，这部分是可选的，大家可以根据自己的需要阅读\n\n\n属性\n\nstart_time：返回时间段的起始时间点，表示为时间戳（Timestamp）对象。\nend_time：返回时间段的结束时间点，表示为时间戳（Timestamp）对象。\nfreq：返回时间段的频率，表示为频率字符串。\n\n\n\n方法\n\nto_timestamp(how='start')：将时间段转换为时间戳(Timestamp)对象，其中how为可选参数，可选的值包括start、end、nearest。\nto_period(freq)：将时间段转换为指定频率的时间段对象。\nstrftime(format)：将时间段格式化为指定的字符串表示形式。"
  },
  {
    "objectID": "时间序列数据.html#二创建时间序列数据",
    "href": "时间序列数据.html#二创建时间序列数据",
    "title": "12  Pandas处理时间序列数据",
    "section": "二、创建时间序列数据",
    "text": "二、创建时间序列数据\n在使用Pandas处理时间序列数据时，我们常常需要自己创建这些数据。下面，我们将采用示例的形式，向你展示Pandas中创建时间序列数据的方法。\n\n1. 从Python的datetime对象创建时间序列\n这种方法涉及在Python中使用datetime模块创建datetime对象，然后将其转换为Pandas的时间序列数据。需要预先定义和创建datetime对象，然后将其转换为时间序列。\n\n\"\"\"\n从Python的datetime对象创建时间序列\n1. 创建一个包含Python的datetime对象的列表或数组\n2. 使用pd.Series()函数将其转换为时间序列数据\n\"\"\"\n\nimport pandas as pd\nfrom datetime import datetime\n\ndates_1 = [datetime(2023, 7, 21), datetime(2023, 7, 22), datetime(2023, 7, 23)]\nts_1 = pd.Series(dates_1)\n\nprint(ts_1)\n\n\n\n2. 从字符串创建时间序列\n这种方法接受包含日期时间信息的字符串，并使用pd.to_datetime()函数将其转换为时间序列数据。它能够直接从日期时间字符串中解析和转换。\n\n\"\"\"\n从字符串创建时间序列\n1. 创建一个包含日期字符串的列表或数组\n2. 使用pd.to_datetime()函数将其转换为时间序列数据\n\"\"\"\n\nimport pandas as pd\n\ndates_2 = ['2023-07-24', '2023-07-25', '2023-07-26']\nts_2 = pd.to_datetime(dates_2)\n\nprint(ts_2)\n\n\n\n3. 使用日期范围创建\n这种方法使用pd.date_range()函数生成指定范围内的连续日期时间序列。需要指定起始日期、结束日期和频率等参数来定义范围和间隔。\n\n\"\"\"\n使用日期范围创建时间序列\n1. 使用start和end参数指定日期范围的其实和结束\n2. 使用freq参数指定日期的频率，例如天(D)、月(M)等\n\"\"\"\n\nimport pandas as pd\n\nts_3 = pd.date_range(start='2023-07-27', end='2023-07-29', freq='D')\n\nprint(ts_3)\n\n\n\n4. 从时间戳创建\n这种方法使用pd.Timestamp()函数从单个时间戳创建时间序列。需要提供一个日期时间的字符串或Python的datetime对象作为参数。\n\n\"\"\"\n从时间戳创建时间序列\n1. 使用pd.Timestamp函数，将单个时间戳转换为时间序列数据\n\"\"\"\n\nimport pandas as pd\n\nts_4 = pd.Timestamp('2022-07-30')\n\n\n\n5. 从时间偏移创建\n这种方法使用pd.date_range()函数结合相对时间偏移（DateOffset）对象，生成具有特定规则的时间序列。需要指定起始日期、时间序列长度和相对时间偏移对象等参数。\n\n\"\"\"\n从时间偏移创建时间序列\n1. 使用start和periods参数指定起始日期和时间序列的长度\n2. 使用freq参数指定日期的频率，并将相对时间偏移对象做为参数传递给freq参数\n\"\"\"\nimport pandas as pd\nfrom pandas.tseries.offsets import DateOffset\n\nts_5 = pd.date_range(start='2023-07-31', periods=10, freq=DateOffset(days=1))\n\n\nDateOffset是Pandas中的一个类，用于表示相对时间偏移量。它可以与日期时间对象一起使用，用于执行日期时间的偏移和调整。"
  },
  {
    "objectID": "时间序列数据.html#三时间序列的索引和切片",
    "href": "时间序列数据.html#三时间序列的索引和切片",
    "title": "12  Pandas处理时间序列数据",
    "section": "三、时间序列的索引和切片",
    "text": "三、时间序列的索引和切片\n\n1. 时间序列索引\n\n\n\n拓展：时间序列索引的特性和功能\n\n\n\n时间序列索引的特性\n\n\n\n时间序列索引具有排序的特性，它将时间点按照从早到晚的顺序进行排序。\n\n\n时间序列索引还可以具有重复的时间点，这意味着在同一个时间点上可能有多个数据点。\n\n\n\n时间序列索引的功能\n\n\n\n时间序列索引提供了一种灵活的方式来访问和处理时间序列数据。\n\n\n可以使用时间序列索引来选择特定日期或时间范围的数据点。\n\n\n时间序列索引支持基于标签的索引和切片操作，可以使用日期时间对象、日期时间字符串或日期时间范围来选择数据。\n\n\n时间序列索引还支持根据时间点进行数据的重采样、聚合和频率转换等操作。\n\n\n\n\nPandas提供了多种类型的时间序列索引，其中最常用的时DatetimeIndex，除了DatetimeIndex以外，还有其他的时间序列索引类型，如PeriodIndex用于表示时间段的索引、TimedeltaIndex用于表示时间间隔索引等。\n\nimport pandas as pd\n\n# 创建时间序列索引\nnew_dates = pd.to_datetime(['2023-07-21', '2023-07-22', '2023-07-23', '2023-07-24', '2023-07-25'])\nvalue_list = [\"新手\", \"程序员\", 3.14, 666, (5, 3, 4, 2, 8)]\n\nnew_ts_1 = pd.Series(value_list, index=new_dates)\n\nprint(new_ts_1['2023-07-21'])\n\n时间序列索引是由日期时间对象组成的，用于标识时间序列的各个数据点。时间序列索引可以是单个日期时间对象，也可以是包含多个日期对象的索引的对象。\n\n可以将时间序列索引分配给DataFrame或Series的索引，或者在创建DataFrame或Series时指定时间序列索引。\n\n使用单个日期时间对象作为时间序列索引\n\nimport pandas as pd\nimport datetime\n\n# 创建时间序列\ndt1 = datetime.datetime(2023, 7, 21)\ndt2 = datetime.datetime(2023, 7, 22)\ndt3 = datetime.datetime(2023, 7, 23)\n\nnew_ts_2 = pd.Series([\"name\", \"is\", \"新手程序员\"], index=[dt1, dt2, dt3])\n\n# 使用时间序列索引访问数据\nnum = new_ts_2[dt2]\nprint(num)\n\n使用日期时间对象列表作为时间序列索引\n\nimport pandas as pd\nimport datetime\n\n# 创建时间序列\nnew_dates_2 = [datetime.datetime(2023, 7, 21), datetime.datetime(2023, 7, 22), datetime.datetime(2023, 7, 23)]\nvalue_list_2 = [\"我想说\", \"Hello\", \"World\"]\n\nnew_ts_3 = pd.Series(value_list, index=new_dates_2)\n\n# 使用时间序列索引访问数据\nvalue = new_ts_3[datetime.datetime(2023, 8, 1)]\n\n\n\n2. 时间序列切片\nPandas中用于处理时间序列的主要数据结构是Timestamp、DatetimeIndex和Period。Timestamp表示一个具体的时间点，DatetimeIndex是由Timestamp组成的索引，用于索引时间序列数据，而Period表示一个时间段。在Pandas包中，可以使用时间序列切片来选择和处理时间序列数据。\n时间切片是指在时间序列数据中选择特定的时间范围或时间点的操作。时间切片允许我们根据时间来选择数据，以进行分析、可视化或其他处理。\n在时间序列数据中，时间切片可以根据日期、时间范围或时间段来选择数据。例如，可以选择某一天、某个时间段内的数据，或者选择特定的月份、季度或年份的数据。\n在Pandas中，有如下常用的时间序列切片操作：\n\n(1) 根据日期索引选择数据\n在Pandas中，我们可以使用日期索引来选择特定日期或日期范围的数据。\n\nimport pandas as pd\n\n# 创建一个示例时间序列数据，每日气温\ntemperatures = pd.Series([23, 25, 21, 19, 20, 22, 24], \n                        index=pd.date_range('2023-07-01', periods=7, freq='D'))\n\n# 选择7月3日的气温数据\nsliced_temperatures = temperatures['2023-07-03']\nprint(sliced_temperatures)\n\n\n\n(2) 根据时间范围选择数据\n除了根据日期索引选择数据外，我们还可以根据特定的时间范围来选择数据。\n\nimport pandas as pd\nfrom datetime import time\n\n# 创建一个示例时间序列数据，每小时交通流量\ntraffic = pd.Series([120, 160, 180, 200, 220, 210, 190, 150, 130, 110, 100, 90],\n                    index=pd.date_range('2023-07-01', periods=12, freq='H'))\n\n# 选择在早上8点到上午10点之间的交通流量数据\nsliced_traffic = traffic.between_time(time(8, 0), time(10, 0))\nprint(sliced_traffic)\n\n除了使用between_time()方法，我们还可以使用布尔索引来选择特定时间范围内的数据。我们可以创造一个布尔条件，指定时间范围，并应用于时间序列数据。\n\n# 创建一个布尔条件，选择早上8点到下午3点之间的数据\ncondition = (traffic.index.hour &gt;= 8) & (traffic.index.hour &lt;= 15)\n\n# 应用布尔条件进行筛选\nsliced_data = traffic[condition]\nprint(sliced_data)\n\n\n\n(3) 根据时间段选择数据\n在Pandas中，我们还可以使用时间段来选择数据。\n\nimport pandas as pd\n\n# 创建一个示例时间序列数据，每月销售额\nsales = pd.Series([1000, 1200, 900, 1100, 1300, 1400],\n                  index=pd.period_range('2023-01', periods=6, freq='M'))\n\n# 选择2023年第一季度的销售额数据\nsliced_sales = sales['2023Q1']\nprint(sliced_sales)"
  },
  {
    "objectID": "时间序列数据.html#四时间重采样和频率转换",
    "href": "时间序列数据.html#四时间重采样和频率转换",
    "title": "12  Pandas处理时间序列数据",
    "section": "四、时间重采样和频率转换",
    "text": "四、时间重采样和频率转换\n在Pandas中，时间重采样和频率转换是对时间序列数据进行重新采样和转换的操作。这些操作可以帮助我们更好地理解和分析时间序列数据，使其适应不同的时间尺度和分析需求。\n\n1. 时间重采样\n时间重采样是指将时间序列数据从一个时间频率转换为另一个时间频率的过程。它可以将高频率的数据降采样为低频率，或将低频率的数据升采样为高频率。\n\n降采样（Downsampling）：将数据从高频率转换为低频率，例如从每分钟数据转换为每小时数据。在降采样中，多个原始数据点被合并为一个单独的数据点，通常通过聚合函数进行汇总。\n\n\nimport pandas as pd\n\n# 创建一个示例时间序列数据，每秒钟的交易量数据\ntrade_volume = pd.Series([100, 150, 120, 80, 90, 110, 130, 140, 160, 120],\n                         index=pd.date_range('2023-07-01 09:30:00', periods=10, freq='S'))\n\n# 将数据降采样为每分钟，并计算每分钟的交易量\ndownsampled_trade_volume = trade_volume.resample('1min').sum()\nprint(downsampled_trade_volume)\n\n\n升采样（Upsampling）：将数据从低频率转换为高频率，例如从每天数据转换为每小时数据。在升采样中，单个原始数据点被扩展为一个或多个更细粒度的数据点，通常使用插值方法来填充新生成的数据点。\n\n\nimport pandas as pd\n\n# 创建一个示例时间序列数据，每月的销售额数据\nsales = pd.Series([1000, 1200, 900],\n                  index=pd.date_range('2023-01-01', periods=3, freq='M'))\n\n# 将数据升采样为每天，并使用线性插值方式填充新生成的数据点\nupsampled_sales = sales.resample('D').interpolate(method='linear')\nprint(upsampled_sales)\n\n在Pandas中，可以使用.resample()方法来执行时间重采样操作，并根据需要应用聚合函数（如求和、平均值等）来处理生成的时间段内的数据。\n\n\n2. 频率转换\n频率转换是指将时间序列数据从一个频率转换为另一个频率的过程。它可以根据需要将数据聚合到更高频率或更低频率，或者将数据按照自定义的频率进行转换。\n在Pandas中，可以使用.asfreq()方法来执行频率转换操作。它可以根据指定的频率将数据重新采样，填充缺失的数据点或者删除多余的数据点。\n\nimport pandas as pd\n\n# 创建一个示例时间序列数据，每天销售额\nsales = pd.Series([100, 200, 150, 300, 250, 180],\n                  index=pd.date_range('2023-01-01', periods=6, freq='D'))\n\n# 将数据转换为每周频率，填充缺失的数据点为0\nconverted_data = sales.asfreq('W', fill_value=0)\nprint(converted_data)\n\n\n时间重采样和频率转换都涉及将时间序列数据从一个时间频率或频率转换为另一个的操作。时间重采样更侧重于根据时间间隔进行数据汇总和处理，而频率转换更侧重于调整数据的频率，并可根据需求填充或删除缺失的数据点。尽管它们在某些方面有相似之处，但它们在Pandas中具有不同的方法和选项来执行这些操作。"
  },
  {
    "objectID": "时间序列数据.html#五对缺失值的处理",
    "href": "时间序列数据.html#五对缺失值的处理",
    "title": "12  Pandas处理时间序列数据",
    "section": "五、对缺失值的处理",
    "text": "五、对缺失值的处理\n在Pandas处理时间序列数据时，处理缺失值是一个重要的环节，因为时间序列数据中可能会存在一些缺失的观测值。缺失值可能会对数据分析和建模产生不良影响，因此需要选择合适的方法来处理它们。\n\n# 创建包含缺失值的DataFrame\n\ndata = {\n    'Date': pd.date_range(start='2023-01-01', periods=10),\n    'Value': [10, 20, np.nan, 40, np.nan, 60, np.nan, 80, 90, np.nan]\n}\ndf = pd.DataFrame(data)\n\n\n1. 删除缺失值\n删除缺失值是处理缺失值最简单直观的方法，其语法为.dropna()，调用该方法将直接删除包含缺失值的行和列。\n直接删除缺失值一般使用在缺失值较多，或者缺失值对数据整体影响较大的情况，且在删除缺失值后，仍然有足够的样本数据用于后续的分析和建模时。\n\n# 删除包含缺失值的行\ndf.dropna(axis=0, inplace=True)\n\n\n\n2. 填充缺失值\n填充缺失值时最常用的一种用于处理缺失值的方法，其语法为.fillna()。在调用该方法时，我们可以使用指定的值或其他有效的填充策略来替换缺失值。\n填充缺失值的方法通常适用于保留所有样本且不影响数据整体分布的情况，比如连续时间序列数据之中，相邻时间点的数据较为平滑。\n\n# 将缺失值填充为0\ndf.fillna(0, inplace=True)\n\n# 使用前向填充（使用前面的值填充）\ndf.fillna(method='ffill', inplace=True)\n\n# 使用后向填充（使用后面的值填充）\ndf.fillna(method='bfill', inplace=True)\n\n\n\n3. 使用统计值填充\n使用统计值填充通常与上面的方法结合使用。我们可以在获得已有数据的统计值(如均值、中位数)以后，使用列的统计值来填充该列的缺失值。\n使用统计值进行填充可以保持数据的整体分布特征。\n\n# 使用均值填充缺失值\nmean_value = df['Value'].mean()\ndf['Value'].fillna(mean_value, inplace=True)\n\n\n\n4. 使用插值方法进行填充\n对于连续的时间数据，我们可以尝试根据一致的数据点之间的关系来推断缺失数据点的值。这样的方法，就叫做插值填充。\n插值填充的方法适用于时间序列数据中缺失值相对较少且数据之间存在一定连续性的情况，比如在温度、股价等数据的处理中较为常用。\n\n# 使用插值方法对缺失值进行估算\ndf['Value'].interpolate(inplace=True)"
  },
  {
    "objectID": "时间序列数据.html#六时间序列的计算和操作",
    "href": "时间序列数据.html#六时间序列的计算和操作",
    "title": "12  Pandas处理时间序列数据",
    "section": "六、时间序列的计算和操作",
    "text": "六、时间序列的计算和操作\n\n1. 平移时间序列数据\n平移时间序列数据是指将时间序列沿时间轴前移或后移一定的时间单位。在Pandas中，可以使用.shift()方法来实现平移操作。通过指定正数表示向前平移，负数表示向后平移。\n\nimport pandas as pd\n\n# 创建一个示例时间序列数据\ntemperatures = pd.Series([23, 25, 24, 22, 20],\n                         index=pd.date_range('2023-07-01', periods=5, freq='D'))\n\n# 向前平移一天\nshifted_temperatures = temperatures.shift(1)\nprint(shifted_temperatures)\n\n\n\n2. 计算时间差\n计算时间差是指计算两个时间点之间的时间间隔。在Pandas中，可以使用时间戳索引之间的差异来计算时间差。计算结果可以是时间间隔（Timedelta）类型。\n\nimport pandas as pd\n\n# 创建示例时间戳索引\ntimestamps = pd.to_datetime(['2023-07-01', '2023-07-05', '2023-07-10'])\n\n# 计算时间差\ntime_diff = timestamps.diff()\nprint(time_diff)\n\n\n\n3. 统计和聚合操作\n时间序列数据常常需要进行统计和聚合操作，以了解数据的趋势、周期性和总体特征。在Pandas中，可以使用各种统计函数和聚合函数对时间序列进行操作，例如求和、平均值、最大值、最小值等。\n\nimport pandas as pd\n\n# 创建一个示例时间序列数据，表示每天的销售额\nsales = pd.Series([1000, 1200, 900, 1100, 1300],\n                  index=pd.date_range('2023-07-01', periods=5, freq='D'))\n\n# 计算销售额的总和、平均值和最大值\ntotal_sales = sales.sum()\naverage_sales = sales.mean()\nmax_sales = sales.max()\n\nprint(total_sales, average_sales, max_sales)"
  },
  {
    "objectID": "文本数据.html#一字符串处理函数",
    "href": "文本数据.html#一字符串处理函数",
    "title": "13  Pandas处理文本数据",
    "section": "一、字符串处理函数",
    "text": "一、字符串处理函数\n\n1. 字符串拆分和连接\nPandas可以通过如下函数处理字符串的拆分与连接：\n\n.split(): 将字符串拆分为多个子字符串，并返回一个包含拆分结果的列表。\n.join(): 将字符串列表或Series中的多个字符串连接成一个字符串。\n.str.split(): 在Series或DataFrame的字符串列上进行拆分操作，并返回一个包含拆分结果的Series或DataFrame。\n\n\nimport pandas as pd\n\n# 创建一个示例字符串列\nnames = pd.Series(['John Smith', 'Jane Doe', 'Mike Johnson'])\n\n# 将字符串拆分为姓和名两列\nsplit_names = names.str.split(' ')\nprint(split_names)\n\n# 将拆分后的姓和名连接为一个字符串\njoined_names = split_names.str.join('-')\nprint(joined_names)\n\n0      [John, Smith]\n1        [Jane, Doe]\n2    [Mike, Johnson]\ndtype: object\n0      John-Smith\n1        Jane-Doe\n2    Mike-Johnson\ndtype: object\n\n\n\n\n2. 字符串匹配和查找\nPandas可以通过如下函数处理字符串的匹配和查找：\n\n.contains(): 检查字符串是否包含指定的子字符串，并返回布尔值。\n.match(): 使用正则表达式对字符串进行匹配，返回匹配的结果。\n.find(): 查找字符串中第一个匹配子字符串的起始位置，并返回索引。\n.findall(): 查找字符串中所有匹配的子字符串，并返回一个列表。\n\n\nimport pandas as pd\n\n# 创建一个示例字符串列\nsentences = pd.Series(['Hello, world!', 'How are you?', 'Python is great'])\n\n# 检查字符串中是否包含指定子字符串\ncontains_world = sentences.str.contains('world')\nprint(contains_world)\n\n# 使用正则表达式匹配字符串\nmatches = sentences.str.match(r'[A-Z][a-z]+')\nprint(matches)\n\n# 查找字符串中第一个匹配子字符串的起始位置\nfirst_index = sentences.str.find('great')\nprint(first_index)\n\n# 查找字符串中所有匹配的子字符串\nall_matches = sentences.str.findall(r'\\b\\w+\\b')\nprint(all_matches)\n\n0     True\n1    False\n2    False\ndtype: bool\n0    True\n1    True\n2    True\ndtype: bool\n0    -1\n1    -1\n2    10\ndtype: int64\n0         [Hello, world]\n1        [How, are, you]\n2    [Python, is, great]\ndtype: object\n\n\n\n\n3. 字符串替换和删除\nPandas可以通过如下函数处理字符串的替换和删除：\n\n.replace(): 替换字符串中的指定子字符串为新的子字符串。\n.str.replace(): 在Series或DataFrame的字符串列上进行替换操作。\n.strip(): 去除字符串两端的空格或指定的字符。\n.str.strip(): 在Series或DataFrame的字符串列上进行去除操作。\n.str.replace(): 删除字符串中的指定子字符串。\n.str.strip(): 在Series或DataFrame的字符串列上进行删除操作。\n\n\nimport pandas as pd\n\n# 创建一个示例字符串列\ntext = pd.Series(['  Hello,  ', '  How are you?  ', '  Python is great  '])\n\n# 去除字符串两端的空格\ntrimmed_text = text.str.strip()\nprint(trimmed_text)\n\n# 替换字符串中的指定子字符串\nreplaced_text = text.str.replace('great', 'awesome')\nprint(replaced_text)\n\n# 删除字符串中的指定子字符串\nremoved_text = text.str.replace(' ', '')\nprint(removed_text)\n\n0             Hello,\n1       How are you?\n2    Python is great\ndtype: object\n0                 Hello,  \n1           How are you?  \n2      Python is awesome  \ndtype: object\n0           Hello,\n1       Howareyou?\n2    Pythonisgreat\ndtype: object"
  },
  {
    "objectID": "文本数据.html#二正则表达式操作",
    "href": "文本数据.html#二正则表达式操作",
    "title": "13  Pandas处理文本数据",
    "section": "二、正则表达式操作",
    "text": "二、正则表达式操作\n\n1. 正则表达式基础知识\n在Pandas中，正则表达式（Regular Expression）是一种强大的工具，用于处理和操作文本数据。Pandas提供了多个函数和方法，可以使用正则表达式对文本数据进行匹配、查找、替换等操作。\n正则表达式（Regular Expression）是一种用于描述字符模式的表达式。它是一种强大的工具，用于在文本中搜索、匹配和处理特定模式的字符串。正则表达式由一个或多个字符和特殊符号组成，它们形成了一种规则，用于描述所需的字符串模式。\n正则表达式的工作原理是通过与输入字符串逐字符匹配，尝试找到与模式匹配的字符串。它使用不同的元字符（Metacharacters）和字符类（Character classes）来表示不同的模式。以下是一些常用的元字符和字符类：\n\n(1) 元字符：\n\n.：匹配任意单个字符，除了换行符。\n*：匹配前面的字符零次或多次。\n+：匹配前面的字符一次或多次。\n?：匹配前面的字符零次或一次。\n|：用于分隔多个模式，表示或的关系。\n()：用于分组和捕获匹配的子字符串。\n\n\n\n(2) 字符类：\n\n[abc]：匹配字符a、b或c中的任意一个。\n[a-z]：匹配任意小写字母。\n[0-9]：匹配任意数字字符。\n[^abc]：匹配除了字符a、b和c之外的任意字符。\n\n正则表达式的匹配过程是从左到右逐字符进行的。它尝试在目标字符串中找到与模式完全匹配的子字符串。如果找到匹配，就可以执行相应的操作，如提取、替换、删除等。正则表达式还支持更复杂的模式匹配，如重复次数、边界限定、转义字符等。\n在Python中，正则表达式的使用通常使用re模块。该模块提供了许多函数和方法，用于对字符串进行正则表达式的匹配和处理。\n总而言之，正则表达式是一种强大的字符串匹配和处理工具，它通过使用特定的符号和语法规则，描述所需的字符串模式，并可以在文本中进行搜索、匹配和处理。\n\n\n\n2. Pandas中的正则表达式操作\n\n(1) .str.match() 方法：\n.str.match() 方法用于对字符串列应用正则表达式进行匹配操作，返回匹配结果。只返回第一个匹配项。\n\nimport pandas as pd\n\n# 创建一个示例字符串列\nnames = pd.Series(['John', 'Jane', 'Mike'])\n\n# 使用正则表达式匹配以J开头的名字\nmatches = names.str.match(r'J\\w+')\nprint(matches)\n\n0     True\n1     True\n2    False\ndtype: bool\n\n\n\n\n(2) .str.contains() 方法：\n.str.contains() 方法用于检查字符串列中是否包含匹配正则表达式的子字符串，并返回布尔值。\n\nimport pandas as pd\n\n# 创建一个示例字符串列\nsentences = pd.Series(['Hello, world!', 'How are you?', 'Python is great'])\n\n# 检查字符串列是否包含以w结尾的单词\ncontains_w = sentences.str.contains(r'\\b\\w+w\\b')\nprint(contains_w)\n\n0    False\n1     True\n2    False\ndtype: bool\n\n\n\n\n(3).str.extract() 方法：\n.str.extract() 方法用于从字符串列中提取满足指定正则表达式模式的子字符串，并返回一个新的列或DataFrame。\n\nimport pandas as pd\n\n# 创建一个示例字符串列\nsentences = pd.Series(['John is 25 years old', 'Jane is 30 years old'])\n\n# 提取字符串中的年龄\nages = sentences.str.extract(r'(\\d+) years')\nprint(ages)\n\n    0\n0  25\n1  30\n\n\n\n\n(4).str.replace() 方法：\n.str.replace() 方法用于替换字符串列中匹配正则表达式的子字符串为指定的字符串。\n\nimport pandas as pd\n\n# 创建一个示例字符串列\nsentences = pd.Series(['Hello, world!', 'How are you?', 'Python is great'])\n\n# 将字符串中的逗号替换为空格\nreplaced = sentences.str.replace(',', ' ')\nprint(replaced)\n\n0      Hello  world!\n1       How are you?\n2    Python is great\ndtype: object"
  },
  {
    "objectID": "文本数据.html#三文本数据的分组和聚合",
    "href": "文本数据.html#三文本数据的分组和聚合",
    "title": "13  Pandas处理文本数据",
    "section": "三、文本数据的分组和聚合",
    "text": "三、文本数据的分组和聚合\n\n1. 分组操作概述\n在Pandas中，分组（Grouping）是一种常用的数据操作，用于将数据根据某个标准分成多个组，并在每个组上进行进一步的操作。分组操作可以应用于各种数据类型，包括文本数据。\n首先，让我们概述一下分组操作的基本流程：\n\n分组依据：选择一个或多个列作为分组依据。这些列的值将用于对数据进行分组。\n分组创建：根据分组依据，将数据分成多个组。每个组由具有相同值的分组依据列形成。\n分组操作：对每个组进行操作，如聚合、计算统计量、过滤数据等。\n结果合并：将每个组的结果合并为一个新的数据结构，通常是一个新的DataFrame。\n\n\n\n2. 文本数据的分组和聚合操作\n在文本数据中，分组和聚合操作可以用于计算字符串的长度、计数特定单词的出现次数、找到具有最长或最短字符串的组等。下面介绍一些常见的文本数据的分组和聚合操作：\n\n(1).groupby() 方法：\n.groupby() 方法用于按照指定的列或多个列对数据进行分组。它返回一个GroupBy对象，表示按照指定列进行分组后的数据。\n\nimport pandas as pd\n\n# 创建一个示例DataFrame\ndf = pd.DataFrame({\n    'Name': ['John', 'Jane', 'Mike', 'Emily', 'John'],\n    'City': ['New York', 'Paris', 'London', 'Paris', 'London'],\n    'Age': [30, 25, 40, 35, 28]\n})\n\n# 按照City列进行分组\ngrouped = df.groupby('City')\nprint(grouped)\n\n&lt;pandas.core.groupby.generic.DataFrameGroupBy object at 0x000002ABE0A780D0&gt;\n\n\n\n\n(2) 分组聚合操作\n通过GroupBy对象，可以应用各种聚合函数来对每个组的数据进行汇总。一些常用的聚合函数包括：\n\n.count()：计算每个组中的元素个数。\n.sum()：计算每个组中数值列的总和。\n.mean()：计算每个组中数值列的平均值。\n.max()、.min()：计算每个组中数值列的最大值和最小值。\n.size()：计算每个组中的元素数量\n\n\nimport pandas as pd\n\n# 创建一个示例DataFrame\ndf = pd.DataFrame({\n    'Name': ['John', 'Jane', 'Mike', 'Emily', 'John'],\n    'City': ['New York', 'Paris', 'London', 'Paris', 'London'],\n    'Age': [30, 25, 40, 35, 28]\n})\n\n# 按照City列进行分组，并计算每个城市的平均年龄和人数\ngrouped = df.groupby('City')\naverage_age = grouped['Age'].mean()\ncount = grouped['Age'].count()\n\nprint(average_age)\nprint(count)\n\nCity\nLondon      34.0\nNew York    30.0\nParis       30.0\nName: Age, dtype: float64\nCity\nLondon      2\nNew York    1\nParis       2\nName: Age, dtype: int64\n\n\n\n\n(3)其他分组操作：\n\n.apply()：在每个组上应用自定义函数。\n.filter()：根据自定义条件过滤组。\n.transform()：对每个组应用函数，并将结果返回到原始数据的相应位置。"
  },
  {
    "objectID": "basic.html#plotly怎么安装",
    "href": "basic.html#plotly怎么安装",
    "title": "14  Plotly 图表绘制与可视化",
    "section": "Plotly怎么安装？",
    "text": "Plotly怎么安装？\n要安装 Plotly，你可以在jupyter中执行以下命令：\n\n# jupyter中安装\n!pip install plotly\n\n# 使用 pip 包管理器在命令行或终端中运行\npip install plotly"
  },
  {
    "objectID": "basic.html#kaleido包安装用于导出图片",
    "href": "basic.html#kaleido包安装用于导出图片",
    "title": "14  Plotly 图表绘制与可视化",
    "section": "Kaleido包安装（用于导出图片）",
    "text": "Kaleido包安装（用于导出图片）\nKaleido 是一个用于生成静态图片或动画的Python绘图工具，它与 Plotly 结合使用，可以帮助你在没有图形界面的服务器上生成图形，并且不需要依赖浏览器或显示器。\n在安装 Kaleido 之前，确保你已经安装了 Python 和 pip。然后按照以下步骤来安装 Kaleido：\n\n# jupyter中安装\n!pip install -U kaleido\n\n# 命令行中安装\npip install -U kaleido\n\n安装完成后，你就可以在 Python 脚本或 Jupyter Notebook 中导入 Plotly，并开始使用它来创建交互式和美观的可视化图表。例如，在 Python 脚本或 Jupyter Notebook 中导入 Plotly：\n\nimport plotly.express as px"
  },
  {
    "objectID": "basic.html#使用plotly可以绘制什么图表",
    "href": "basic.html#使用plotly可以绘制什么图表",
    "title": "14  Plotly 图表绘制与可视化",
    "section": "使用Plotly可以绘制什么图表？",
    "text": "使用Plotly可以绘制什么图表？\n\n散点图（Scatter plot）\n\n散点图的概念和用途：用于展示两个变量之间的关系，如相关性、分布等。\n创建散点图：px.scatter() 函数，设置 x 轴和 y 轴数据，以及通过颜色映射和大小映射展示额外信息。\n\n折线图（Line plot）\n\n折线图的作用：展示随时间或其他连续变量的变化趋势，如时间序列数据、趋势分析等。\n创建折线图： px.line() 函数，包括设置 x 轴和 y 轴数据，添加标记点、调整线条样式等。\n\n柱状图（Bar chart）\n\n解释柱状图的用途：用于比较不同类别或组之间的数值差异，比如销售额、人口统计等。\n创建柱状图： px.bar() 函数，包括设置 x 轴和 y 轴数据，添加堆叠柱状图、分组柱状图等。\n\n饼图（Pie chart）\n\n饼图的含义：展示数据在整体中的占比情况，适用于展示相对比例。\n绘制饼图：px.pie() 函数，设置数据和标签，调整颜色、标签位置等。\n\n直方图（Histogram）\n\n直方图的作用：用于展示数据的分布情况，特别适用于连续变量，帮助了解数据的分布范围和形态。\n绘制直方图： px.histogram() 函数，参数须了解，如 bin 大小、频数或频率显示等。\n\n箱线图（Box plot）\n\n箱线图的含义：用于显示数据的统计特征，如中位数、四分位数和异常值，帮助了解数据的分布和离群点。\n绘制箱线图：px.box() 函数，设置 x 轴和 y 轴数据，添加多个箱线图、调整样式等。"
  },
  {
    "objectID": "basic.html#绘制图表需要掌握的函数理解即可",
    "href": "basic.html#绘制图表需要掌握的函数理解即可",
    "title": "14  Plotly 图表绘制与可视化",
    "section": "绘制图表需要掌握的函数（理解即可）",
    "text": "绘制图表需要掌握的函数（理解即可）\n\npx.scatter() 函数绘制散点图\npx.scatter() 是 Plotly Express 中用于创建散点图的函数。散点图用于展示两个变量之间的关系，并通过点的位置和颜色来表示数据的特征。该函数简化了创建散点图的过程，只需提供数据和一些基本参数，即可生成可视化图形。\n以下是 px.scatter() 函数的简单案例：（复制代码测试下图表效果即可，理解其中参数）\n\n\n\n\n\n\nWarning\n\n\n\nplotly在本地运行无法显示图片的话，可以尝试直接使用fig.show(renderer=\"notebook\")，去掉renderer=\"notebook\"\n\n\n\nimport plotly.express as px\n\n# 准备数据\nx_data = [1, 2, 3, 4, 5]\ny_data = [10, 12, 8, 14, 9]\n\n# 使用px.scatter()创建散点图\nfig = px.scatter(x=x_data, y=y_data, title='散点图', labels={'x': 'X轴', 'y': 'Y轴'})\n\n# 显示图表，使用 fig.show() 即可\nfig.show(renderer=\"notebook\")\n\n\n                                                \n\n\n参数解释：\n\nx（必需参数）：这是一个列表、一维数组或DataFrame列，用于指定散点图中X轴的数据。\ny（必需参数）：这是一个列表、一维数组或DataFrame列，用于指定散点图中Y轴的数据。\ndata_frame（可选参数）：这是一个DataFrame，如果您有一个数据框，可以通过data_frame参数直接指定，而不需要分别指定x和y参数。\ntitle（可选参数）：用于设置散点图的标题，以字符串形式指定。\nlabels（可选参数）：一个字典，用于指定X轴和Y轴的标签。例如，labels={'x': '时间', 'y': '销量'}将X轴标签设置为”时间”，Y轴标签设置为”销量”。\ncolor（可选参数）：用于设置散点图的颜色。您可以通过指定颜色名称或HEX代码来自定义散点的颜色。还可以设置为列名或一维数组，根据其值自动给散点上色。\nsize（可选参数）：用于设置散点的大小。可以指定一个数值或列名，根据数据中的值调整散点的大小。\ntemplate（可选参数）：用于设置图表的样式模板，包括颜色、背景等。\ntrendline（可选参数）：是否显示散点图上的趋势线。\n\n通过 px.scatter() 函数，你可以轻松地创建各种散点图，将数据可视化，发现变量之间的关系，并更好地理解数据的特征和模式。\n\n\npx.line()绘制折线图\n当使用Plotly Express中的px.line()函数时，您可以绘制折线图（Line Plot），它是一种展示数据随连续变量变化而变化的图表。px.line()函数是Plotly库的高级封装，它简化了创建折线图的过程，使可视化变得更加简单和快捷。\n下面是px.line()函数的基本用法和常用参数解释：（复制代码测试下图表效果即可，理解其中参数）\n\nimport plotly.express as px\n\n# 准备数据\nx_data = [1, 2, 3, 4, 5]\ny_data = [10, 12, 8, 14, 9]\n\n# 使用px.line()创建折线图\nfig = px.line(x=x_data, y=y_data, title='折线图', labels={'x': 'X轴', 'y': 'Y轴'})\n\n# 显示图表\nfig.show(renderer=\"notebook\")\n\n\n                                                \n\n\n参数解释：\n\nx（必需参数）：这是一个列表或一维数组，用于指定折线图中X轴的数据点。\ny（必需参数）：这也是一个列表或一维数组，用于指定折线图中Y轴的数据点。\ndata_frame（可选参数）：这是一个DataFrame，如果您有一个数据框，可以通过data_frame参数直接指定，而不需要分别指定x和y参数。\ntitle（可选参数）：用于设置折线图的标题，以字符串形式指定。\nlabels（可选参数）：一个字典，用于指定X轴和Y轴的标签。例如，labels={'x': '时间', 'y': '销量'}将X轴标签设置为”时间”，Y轴标签设置为”销量”。\nline_group（可选参数）：用于绘制多个折线图并将它们分组。这个参数可以指定一个列名或一维数组，具有相同值的数据点将被视为同一组，并绘制在同一条折线上。\ncolor_discrete_sequence（可选参数）：用于指定折线的颜色序列。您可以通过指定颜色名称或HEX代码的列表来自定义折线的颜色。\ntemplate（可选参数）：用于设置图表的样式模板，包括颜色、背景等。\n\n\n\npx.bar()绘制条形图\npx.bar()函数是Plotly Express库中的一个函数，用于绘制条形图（Bar Chart）。条形图是一种常用的数据可视化方式，用于展示不同类别之间的数量或比较数据。\n以下是px.bar()函数的基本用法和常用参数解释：（复制代码测试下图表效果即可，理解其中参数）\n\nimport plotly.express as px\n\n# 准备数据\ncategories = ['A', 'B', 'C', 'D', 'E']\nvalues = [30, 15, 20, 25, 10]\n\n# 使用px.bar()创建条形图\nfig = px.bar(x=categories, y=values, title='条形图', labels={'x': '类别', 'y': '数量'})\n\n# 显示图表\nfig.show(renderer=\"notebook\")\n\n\n                                                \n\n\n参数解释：\n\nx（必需参数）：这是一个列表、一维数组或DataFrame列，用于指定条形图中各个条形的类别或X轴数据。\ny（必需参数）：这是一个列表、一维数组或DataFrame列，用于指定条形图中各个条形的高度或Y轴数据。\ndata_frame（可选参数）：这是一个DataFrame，如果您有一个数据框，可以通过data_frame参数直接指定，而不需要分别指定x和y参数。\ntitle（可选参数）：用于设置条形图的标题，以字符串形式指定。\nlabels（可选参数）：一个字典，用于指定X轴和Y轴的标签。例如，labels={'x': '产品', 'y': '销量'}将X轴标签设置为”产品”，Y轴标签设置为”销量”。\ncolor（可选参数）：用于设置条形图的颜色。您可以通过指定颜色名称或HEX代码来自定义条形的颜色。还可以设置为列名或一维数组，根据其值自动给条形上色。\nbarmode（可选参数）：用于指定多个数据系列的条形图显示模式。默认为”group”，表示每个类别的不同系列将并排显示。还可以设置为”stack”，表示将多个系列堆叠显示。\ntemplate（可选参数）：用于设置图表的样式模板，包括颜色、背景等。\n\n\n\npx.pie()函数绘制饼图\npx.pie()函数是Plotly Express库中的一个函数，用于绘制饼图（Pie Chart）。饼图是一种常见的数据可视化方式，用于展示不同类别的数据在整体中的比例关系。\n以下是px.pie()函数的基本用法和常用参数解释：（复制代码测试下图表效果即可，理解其中参数）\n\nimport plotly.express as px\n\n# 准备数据\nlabels = ['A', 'B', 'C', 'D', 'E']\nvalues = [30, 15, 20, 25, 10]\n\n# 使用px.pie()创建饼图\nfig = px.pie(values=values, names=labels, title='饼图')\n\n# 显示图表\nfig.show(renderer=\"notebook\")\n\n\n                                                \n\n\n参数解释：\n\nvalues（必需参数）：这是一个列表、一维数组或DataFrame列，用于指定各个类别的数据值，即饼图的扇区大小。\nnames（必需参数）：这是一个列表、一维数组或DataFrame列，用于指定各个类别的名称，即饼图的标签。\ndata_frame（可选参数）：这是一个DataFrame，如果您有一个数据框，可以通过data_frame参数直接指定，而不需要分别指定values和names参数。\ntitle（可选参数）：用于设置饼图的标题，以字符串形式指定。\ncolor（可选参数）：用于设置饼图扇区的颜色。您可以通过指定颜色名称或HEX代码来自定义扇区的颜色。还可以设置为列名或一维数组，根据其值自动给扇区上色。\ntemplate（可选参数）：用于设置图表的样式模板，包括颜色、背景等。\nhole（可选参数）：用于设置饼图的中心孔的大小。可以指定一个0到1之间的小数，值为0表示完整饼图，值为1表示一个圆环图。\nlabels（可选参数）：用于控制饼图标签的显示方式。默认为”percent”，表示显示百分比标签。也可以设置为”label”，表示显示类别名称标签。还可以设置为”name”，表示显示数据名称标签。\n\n\n\npx.histogram()函数绘制直方图\npx.histogram()函数是Plotly Express库中的一个函数，用于绘制直方图（Histogram）。直方图是一种常见的数据可视化方式，用于展示连续变量的分布情况。\n以下是px.histogram()函数的基本用法和常用参数解释：（复制代码测试下图表效果即可，理解其中参数）\n\nimport plotly.express as px\n\n# 准备数据\ndata = [2, 3, 1, 4, 5, 2, 3, 3, 4, 4, 4, 5, 5, 5]\n\n# 使用px.histogram()创建直方图\nfig = px.histogram(data, title='直方图', labels={'value': '数值', 'count': '频数'})\n\n# 显示图表\nfig.show(renderer=\"notebook\")\n\n\n                                                \n\n\n参数解释：\n\ndata_frame（必需参数）：这是一个DataFrame或一维数组，用于指定要绘制直方图的数据。\nx（可选参数）：这是一个字符串或一维数组，用于指定直方图中X轴的数据。如果不指定，x默认为数据列中的值。\nnbins（可选参数）：用于指定直方图的箱子数量，即直方图的条数。默认值为”auto”，会自动选择合适的箱子数量。\ntitle（可选参数）：用于设置直方图的标题，以字符串形式指定。\nlabels（可选参数）：一个字典，用于指定X轴和Y轴的标签。例如，labels={'value': '数值', 'count': '频数'}将X轴标签设置为”数值”，Y轴标签设置为”频数”。\ncolor（可选参数）：用于设置直方图的颜色。您可以通过指定颜色名称或HEX代码来自定义直方图的颜色。\ntemplate（可选参数）：用于设置图表的样式模板，包括颜色、背景等。\nmarginal（可选参数）：用于在直方图的边缘添加边缘直方图或箱线图。可以设置为”rug”、“box”、“violin”等。\n\n\n\npx.box()函数绘制箱线图（仅做了解）\npx.box()函数是Plotly Express库中的一个函数，用于绘制箱线图（Box Plot）。箱线图是一种常见的数据可视化方式，用于展示数据的分布情况和异常值。\n以下是px.box()函数的基本用法和常用参数解释：（复制代码测试下图表效果即可，理解其中参数）\n\nimport plotly.express as px\n\n# 准备数据\ndata_1 = [2, 3, 1, 4, 5, 2, 3, 3, 4, 4, 4, 5, 5, 5]\ndata_2 = [3, 4, 2, 5, 6, 1, 3, 4, 3, 5, 6]\n\n# 合并数据并添加标识列\ndf = []\nfor val in data_1:\n    df.append({'Value': val, 'Data': '数据集1'})\nfor val in data_2:\n    df.append({'Value': val, 'Data': '数据集2'})\n\n# 使用px.box()创建箱线图\nfig = px.box(df, y='Value', color='Data', title='箱线图', labels={'Value': '值', 'Data': '数据集'})\n\n# 显示图表\nfig.show(renderer=\"notebook\")\n\n\n                                                \n\n\n参数解释：\n\ndata_frame（必需参数）：这是一个DataFrame，用于指定要绘制箱线图的数据。在我们的例子中，我们使用了一个包含’Value’和’Data’列的DataFrame df，其中’Value’列包含箱线图的Y轴数据，’Data’列用于指定箱线图的不同数据集。\ny（必需参数）：这是一个字符串，用于指定箱线图中Y轴的数据。在我们的例子中，我们将’Value’列作为箱线图的Y轴数据。\ncolor（可选参数）：这是一个字符串，用于设置箱线图的颜色分类。在我们的例子中，我们使用’Data’列作为颜色分类，将两个数据集分别标记为’数据集1’和’数据集2’，这样就可以在箱线图中区分它们。\ntitle（可选参数）：用于设置箱线图的标题，以字符串形式指定。在我们的例子中，我们设置了标题为”箱线图”。\nlabels（可选参数）：一个字典，用于指定图表的标签。例如，labels={'Value': '值', 'Data': '数据集'}将Y轴标签设置为”值”，颜色分类标签设置为”数据集”。\ntemplate（可选参数）：用于设置图表的样式模板，包括颜色、背景等。"
  },
  {
    "objectID": "basic.html#plotly-express图表导出",
    "href": "basic.html#plotly-express图表导出",
    "title": "14  Plotly 图表绘制与可视化",
    "section": "Plotly Express图表导出",
    "text": "Plotly Express图表导出\nPlotly Express图表导出为静态图像文件或生成可分享的交互式图表链接，以下是两种方法的说明：\n\n导出为静态图像文件：\n\n使用plotly.io.write_image()函数可以将Plotly Express图表导出为静态图像文件，支持多种格式，如PNG、JPEG、SVG等。以下是一个示例：\n\nimport plotly.express as px\n\n\n# 准备数据\nx_data = [1, 2, 3, 4, 5]\ny_data = [10, 12, 8, 14, 9]\n\n# 使用px.line()创建折线图\nfig = px.line(x=x_data, y=y_data, title='折线图', labels={'x': 'X轴', 'y': 'Y轴'})\n\n# 导出为静态图像文件（PNG格式）\npio.write_image(fig, 'line_plot.png')\n\n运行上述代码后，将会在当前目录下生成名为”line_plot.png”的PNG格式图片文件，即将折线图保存为静态图像。（记得先选择当前文件夹）\n\n生成可分享的交互式图表链接：\n\n要生成可分享的交互式图表链接，您可以使用plotly.offline.plot()函数。这将创建一个HTML文件，其中包含交互式的Plotly Express图表，并且你可以将此HTML文件分享给其他人。以下是一个示例：\n\nimport plotly.express as px\nimport plotly.offline as pyo\n\n# 准备数据\nx_data = [1, 2, 3, 4, 5]\ny_data = [10, 12, 8, 14, 9]\n\n# 使用px.line()创建折线图\nfig = px.line(x=x_data, y=y_data, title='折线图', labels={'x': 'X轴', 'y': 'Y轴'})\n\n# 生成交互式图表链接并保存为HTML文件\npyo.plot(fig, filename='interactive_line_plot.html')\n\n'interactive_line_plot.html'\n\n\n运行上述代码后，将会在当前目录下生成名为”interactive_line_plot.html”的HTML文件，其中包含交互式的折线图。你可以将此HTML文件分享给其他人，他们可以通过浏览器查看和与图表进行交互。\n通过这两种方法，你可以方便地分享你的Plotly Express图表，无论是静态图像还是交互式图表。"
  },
  {
    "objectID": "basic.html#plotly.graph_objects高级绘图模块",
    "href": "basic.html#plotly.graph_objects高级绘图模块",
    "title": "14  Plotly 图表绘制与可视化",
    "section": "plotly.graph_objects高级绘图模块",
    "text": "plotly.graph_objects高级绘图模块\n当你导入plotly.graph_objects模块并使用别名go，你可以使用go来创建和定制Plotly图形对象。\n\n以下是plotly.graph_objects模块中go的主要内容和用法：\n\n1、创建图表对象：使用go.Figure()方法创建一个图表对象。这是创建几乎所有Plotly图表的起点。\n2、添加图表轨迹：使用go模块中的各种图表类型（例如Scatter、Bar、Pie等）创建图表轨迹（trace）。每个图表轨迹代表图表上的一组数据点或数据柱。\n3、图表布局和样式：使用update_layout()方法来设置图表的布局和样式，例如设置标题、轴标签、背景颜色等。\n4、图表交互性：Plotly允许你为图表添加交互性，例如鼠标悬停提示、缩放、平移等。可以使用update_traces()方法来设置图表轨迹的交互行为。\n5、绘制和显示图表：使用show()方法显示图表或使用write_image()方法将图表导出为图像文件。\n以下是融合了散点图和柱状图的示例代码：\n\nimport plotly.graph_objects as go\n\n\n\n# 创建一个图表对象\nfig = go.Figure()\n\n# 添加散点图轨迹\nfig.add_trace(go.Scatter(x=[1, 2, 3, 4], y=[10, 11, 12, 13], mode='markers', name='散点图'))\n\n# 添加柱状图轨迹\nfig.add_trace(go.Bar(x=[1, 2, 3, 4], y=[5, 6, 7, 8], name='柱状图'))\n\n# 设置图表布局和样式\nfig.update_layout(title='示例图表', xaxis_title='X轴', yaxis_title='Y轴')\n\n# 显示图表\nfig.show(renderer=\"notebook\")\n\n\n                                                \n\n\nplotly.graph_objects模块提供了丰富的图表类型和配置选项，让你能够灵活地创建和定制各种类型的图表，满足你的数据可视化需求。可以查阅Plotly官方文档获取更多关于go模块的详细信息和用法。\n\n.add_trace图表轨迹方法\n.add_trace是用于向Plotly图表对象中添加不同类型的图表轨迹（trace）的方法。每个图表轨迹代表图表上的一组数据点或数据柱。\n在Plotly中，你可以在同一个图表对象中添加多个图表轨迹，从而在同一个图表中展示多个不同类型的数据。这让你可以将多个数据集以不同的图表类型呈现在同一个图表中，方便进行数据比较和分析。\n.add_trace方法的基本语法如下：\nfig.add_trace(trace)\n其中，fig是go.Figure图表对象，trace是你要添加的图表轨迹。\n以下是.add_trace方法的具体用法和示例：\n添加散点图轨迹：\n\nimport plotly.graph_objects as go\n\n\n\n# 示例数据\nx = [1, 2, 3, 4]\ny = [10, 11, 12, 13]\n\n# 创建一个图表对象\nfig = go.Figure()\n\n# 添加散点图轨迹\nfig.add_trace(go.Scatter(x=x, y=y, mode='markers', name='散点图'))\n\n# 显示图表\nfig.show(renderer=\"notebook\")\n\n\n                                                \n\n\n添加折线图轨迹：\n\nimport plotly.graph_objects as go\n\n\n\n# 示例数据\nx = [1, 2, 3, 4]\ny = [10, 11, 12, 13]\n\n# 创建一个图表对象\nfig = go.Figure()\n\n# 添加折线图轨迹\nfig.add_trace(go.Scatter(x=x, y=y, mode='lines', name='折线图'))\n\n# 显示图表\nfig.show(renderer=\"notebook\")\n\n\n                                                \n\n\n\n#添加柱状图轨迹：\n\nimport plotly.graph_objects as go\n\n\n\n# 示例数据\nx = ['A', 'B', 'C', 'D']\ny = [10, 20, 15, 25]\n\n# 创建一个图表对象\nfig = go.Figure()\n\n# 添加柱状图轨迹\nfig.add_trace(go.Bar(x=x, y=y, name='柱状图'))\n\n# 显示图表\nfig.show(renderer=\"notebook\")\n\n\n                                                \n\n\n通过.add_trace方法，你可以在同一个图表对象中添加多个图表轨迹，实现数据的多重展示。这使得你可以更好地进行数据比较、分析和可视化。注意，每个图表轨迹可以有不同的样式和设置，使得图表的外观和表现更加灵活和丰富。\n\n\n表格可视化\n在Plotly中，使用go.Figure可以很方便地展示表格可视化。\n在这部分，我们使用go.Figure函数创建了一个图表对象table_figure，并将表格图形对象table_trace作为数据传入。\n准备数据并创建一个go.Table对象：\n\n# 示例数据\ndata = {\n    \"Name\": [\"John\", \"Emma\", \"Michael\", \"Sophia\"],\n    \"Age\": [28, 24, 22, 26],\n    \"City\": [\"New York\", \"San Francisco\", \"Los Angeles\", \"Chicago\"],\n}\n\n# 创建一个数据帧\ndf = pd.DataFrame(data)\n\n# 创建一个表格图形对象\ntable_trace = go.Table(\n    header=dict(values=list(df.columns)),  # 定义表头，将数据帧的列名作为表头的值\n    cells=dict(values=[df.Name, df.Age, df.City])  # 定义单元格内容，将数据帧的数据作为单元格的值\n)\n\n\n在这部分中，我们创建了一个示例数据字典data，其中包含了姓名（“Name”）、年龄（“Age”）和所在城市（“City”）的数据。接着，使用pandas的DataFrame函数将数据字典转换为数据帧df，这将创建一个表格结构，其中包含了姓名、年龄和所在城市这三列数据。然后，我们使用go.Table来创建一个表格图形对象。在go.Table中，我们传入了header和cells参数：\nheader用于定义表格的表头，我们将df.columns（即数据帧df的列名）作为表头的值。\ncells用于定义表格的单元格内容，我们将df.Name、df.Age和df.City作为单元格的值。这样，数据帧中的姓名、年龄和城市数据将分别显示在表格的三列中。\n创建go.Figure图表对象并添加表格轨迹：\n\n# 创建图表对象，并将表格轨迹添加到图表中\ntable_figure = go.Figure(data=[table_trace])\n\n在这部分，我们使用go.Figure函数创建了一个图表对象table_figure，并将表格图形对象table_trace作为数据传入。\n显示图表：\n\n# 显示图表\ntable_figure.show(renderer=\"notebook\")\n\n\n                                                \n\n\n\n更直接的把go.Table嵌套在go.Figure中的方法是：\n你可以直接将go.Table嵌套在go.Figure中来创建一个包含表格可视化的图表对象。这样的做法非常方便，特别是当你只需要展示一个简单的表格可视化时，直接在go.Figure中添加go.Table即可，无需另外创建一个图表轨迹。\n以下是直接将go.Table嵌套在go.Figure中的方法：\n\nimport plotly.graph_objects as go\nimport pandas as pd\n\n# 示例数据\ndata = {\n    \"Name\": [\"John\", \"Emma\", \"Michael\", \"Sophia\"],\n    \"Age\": [28, 24, 22, 26],\n    \"City\": [\"New York\", \"San Francisco\", \"Los Angeles\", \"Chicago\"],\n}\n\n# 创建一个数据帧\ndf = pd.DataFrame(data)\n\n# 创建一个表格图形对象\ntable_figure = go.Figure(data=[go.Table(\n    header=dict(values=list(df.columns)),  # 定义表头，将数据帧的列名作为表头的值\n    cells=dict(values=[df.Name, df.Age, df.City])   # 定义单元格内容，将数据帧的数据作为单元格的值\n)])\n\n# 显示图表\ntable_figure.show(renderer=\"notebook\")"
  },
  {
    "objectID": "动态图表.html#热力图",
    "href": "动态图表.html#热力图",
    "title": "15  高阶图表",
    "section": "热力图",
    "text": "热力图\n热力图是一种使用颜色来展示二维数据的图表，主要用于展示二维数据的分布和相关性，其中颜色的深浅表示数据的密度、数值的大小或相关性的强度。\n\n热力图可以帮助用户直观地观察数据的分布情况，从而快速识别数据的集中区域和稀疏区域。\n主要用于显示数据的分布、相关性和模式，例如地图上的人口密度。\n能够突出显示异常值：热力图可以突出显示数据中的异常值或异常模式，帮助用户识别潜在的问题或异常情况。\n\n\n一个简单的热力图示例\n\nimport plotly.express as px\nimport pandas as pd\n# 数据\nheat_map_data = {\n    'Day': ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday'],\n    'Temperature': [28, 30, 32, 29, 31], # 温度\n    'Humidity': [55, 58, 50, 61, 54]  # 湿度\n}\n\ndf = pd.DataFrame(heat_map_data)\n\n# 绘制热力图\nfig_heat_map = px.imshow(df[['Temperature', 'Humidity']], y=df['Day'], text_auto = True)\nfig_heat_map.show(renderer=\"notebook\")\n\n\n                                                \n\n\n\n参数介绍：\n\n绘制热力图函数px.imshow(img, x, y, ...)：\nimg : 二维数据矩阵，要绘制的数据。\nx : 用于指定列标签(每一列)。\ny : 用于指定行标签(每一行)。\ntext_auto=True 表示显示数值。"
  },
  {
    "objectID": "动态图表.html#旭日图",
    "href": "动态图表.html#旭日图",
    "title": "15  高阶图表",
    "section": "旭日图",
    "text": "旭日图\n旭日图，也叫做Sunburst Charts，主要用来展示具有层级结构的数据，其中每个数据点都有一个父级和一个或多个子级。\n\n旭日图可以理解为是表示分层数据的多级饼图，在一个圆环中嵌套多个圆环，每个圆环代表一个层级的分类数据，离中心越近的圆环层级越高。\n旭日图能够同时表现数据的局部和整体的占比情况，以及数据层级之间的关系。相较于饼图，旭日图更适合展示层级多的比例数据关系，更适合呈现复杂的数据结构。\n旭日图通过环形结构，使得用户可以清楚地看到数据从大类到子类的层级关系，以及不同类别之间的相对比例。\n\n\n一个简单的旭日图示例\n\nimport plotly.express as px\n\n# 旭日图数据（层次结构数据）\nsunburst_data = {\n    'Region': ['Asia', 'Asia', 'Europe', 'Africa', 'North America', 'South America', 'North America'],\n    'Country': ['China', 'Japan', 'Germany', 'Nigeria', 'USA', 'Brazil', 'Mexico'],\n    'Population': [1439323776, 124520000, 83783942, 214028302, 331002651, 212559417, 129040000]\n}\ndf = pd.DataFrame(sunburst_data)\n# 绘制旭日图\nfig_sunburst = px.sunburst(df, path=['Region', 'Country'], \n                           values='Population', color='Region',\n                           title='Sunburst Plot'\n                           )\nfig_sunburst.show(renderer=\"notebook\")\n\n\n                                                \n\n\n\n参数介绍：\n\n不论绘制任何图像，第一个参数基本上为传递给绘图参数的数据，这里是数据框df。\npath : 层次结构的路径：洲Region-&gt;国Country。一个列名列表，在前面的列为更靠近圆环中心的大类。 从中心向外的层层圆环，从前往后的列名列表，都表示从高层级向子层级展开。\nvalues : 决定圆环中各部分占比的变量，这里是人口数Population。\ncolor : 表示这个变量中的所有不同取值用不同颜色来区分，这里不同洲地区的板块显示为不同的颜色。\n\n通过鼠标点击旭日图中不同的环块，可以展开或折叠不同层级的数据。"
  },
  {
    "objectID": "动态图表.html#树状图",
    "href": "动态图表.html#树状图",
    "title": "15  高阶图表",
    "section": "树状图",
    "text": "树状图\n树状图是一种展现层次结构的可视化图表，通过矩形的嵌套和面积大小来展示数据的层级关系。\n\n树状图主要用于展示层次结构数据，例如文件夹大小、组织架构、经济分布等。\n树状图可以帮助用户快速了解数据的组织结构，同时直观地比较不同层级之间的数据大小。\n\n\n一个简单的树状图示例\n\n# 树状图数据（层次结构数据）\n# 各个领域的商品销量\ntree_map_data = {\n    'Category': ['Electronics', 'Fashion', 'Fashion', 'Beauty', 'Toys'],\n    'Product': ['Laptop', 'Shirt', 'Pants', 'Lipstick', 'Action Figure'],\n    'Sales': [1200, 800, 600, 600, 300]\n}\ndf = pd.DataFrame(tree_map_data)\n# 绘制树状图\n# 参数可以参照旭日图\n# path表示层次结构路径，values为决定矩形大小的变量，color决定用不同颜色区分哪个层级。\nfig_tree_map = px.treemap(df, path=[px.Constant('Sale'), 'Category', 'Product'], \n                          values='Sales', color='Category', title='TreeMap Plot')\nfig_tree_map.show(renderer=\"notebook\")\n\n\n                                                \n\n\n\n\ncolor参数\n当使用数值列来决定不同矩形的颜色时，可以设置color相关的参数：\n\ncolor_continuous_scale ：这个参数设置了颜色的渐变色标尺，’RdBu’表示红蓝双色渐变。\ncolor_continuous_midpoint ：这个参数用于设置颜色渐变的中点。将某个值作为颜色渐变的中点，可以使得图表的颜色更加平衡。\n\n\nimport numpy as np\nfig1_tree_map = px.treemap(df, path=[px.Constant('Sale'), 'Category', 'Product'], \n                           values='Sales', color='Sales', color_continuous_scale='RdBu',\n                           color_continuous_midpoint=np.average(df['Sales'])\n                           )\nfig1_tree_map.show(renderer=\"notebook\")\n\n\n                                                \n\n\n通过鼠标点击树状图中不同的矩形版块，可以展开或折叠不同层级的数据。"
  },
  {
    "objectID": "动态图表.html#动画效果",
    "href": "动态图表.html#动画效果",
    "title": "15  高阶图表",
    "section": "动画效果",
    "text": "动画效果\n通过图像连续变化来展示一系列动作或过程，就叫做动效，通常用来展示数据的可视化图表随时间变化的过程。\n\n绘图示例\n\nimport plotly.express as px\n# 内置数据集\ndf = px.data.gapminder()\n\n# 绘制加入动画效果的散点图，展示随时间变化的散点图走势\nfig = px.scatter(df, x=\"gdpPercap\", y=\"lifeExp\", \n                 animation_frame=\"year\", animation_group=\"country\",\n                 size=\"pop\", color=\"continent\", hover_name=\"country\",\n                 log_x=True, size_max=55, range_x=[100,100000], range_y=[25,90])\nfig.show(renderer=\"notebook\")\n\n\n                                                \n\n\n\nGapminder数据集变量介绍\n\n用于展示全球人口、经济和健康状况的变化情况。\ncountry：国家名称。\ncontinent：所属洲。\nyear：年份。\nlifeExp：平均预期寿命。\npop：人口数量。\ngdpPercap：人均GDP。\n\n\n\n参数介绍\n\nhover_name ：鼠标悬停在散点上时显示的标签。\nlog_x ：控制 x 轴是否使用对数刻度。将其设置为True，则 x 轴使用对数刻度。 在对数刻度中，刻度值是指数增长的，例如刻度值为100、101、102、103\nsize_max ：设置散点的最大大小以避免散点过大。\nrange_x ：x 轴的取值范围。\nrange_y ：y 轴的取值范围。\nanimation_frame ：设置动画效果的关键字，此处为year表示散点图将以动画形式展示数据随时间的变化\nanimation_group ：确定动画效果的关键字，此处为country表示将展示各个国家的变化数据趋势。"
  },
  {
    "objectID": "动态图表.html#交互式功能",
    "href": "动态图表.html#交互式功能",
    "title": "15  高阶图表",
    "section": "交互式功能",
    "text": "交互式功能\n\n鼠标交互：\n鼠标悬停提示：Plotly 默认会在图表上显示数据点的数值信息。鼠标悬停在数据点上时，会显示该点的具体数值，包括 x 轴和 y 轴的值。这个功能在 Plotly 中是默认开启的，无需设置。\n缩放和平移：通过鼠标拖拽可以实现图表的缩放和平移。当鼠标指针放在图表上方时，会出现缩放和平移的图标，通过拖动可以改变图表的视图范围。\n\n\n工具栏操作：\n工具栏按钮：Plotly 默认会在图表的右上角显示一个工具栏，其中包含一系列按钮，例如缩放、平移、自动缩放、重置轴范围等。这些按钮可以用于调整图表的外观和交互方式。\n\n\n图例控制：\n图例样式：可以通过设置图例的样式来调整图例的外观，例如字体大小、背景颜色等。通过在 legend 参数中设置相应的属性来实现。\n图例位置：可以通过设置图表布局中的 legend 参数来控制图例的位置。例如，layout=dict(legend=dict(x=0, y=1)) 表示将图例放在图表的左上角。默认情况下，Plotly 会自动根据图表的内容和大小来选择最佳的图例位置。\nlegend常用参数：\n\nx 和 y ：设置图例的水平和垂直位置，取值范围为0到1，0表示图表的最左边或最下边，1表示图表的最右边或最上边。\nxanchor 和 yanchor ：设置图例的水平和垂直锚点，用于确定图例相对于设置的 x 和 y 位置的对齐方式。\nbgcolor ：设置图例的背景颜色。\nbordercolor 和 borderwidth ：设置图例的边框颜色和宽度。\ntraceorder ：设置图例中数据系列的显示顺序，可选值为 ‘normal’（默认）或 ‘reversed’。\nitemsizing ：设置图例中每个数据系列的尺寸，可选值为 ‘trace’（默认）或 ‘constant’。‘trace’ 表示图例中每个数据系列的尺寸与其在图表中的尺寸成比例，‘constant’ 表示图例中每个数据系列的尺寸保持不变。\n\n\nimport plotly.express as px\n\n# 内置数据集\ndf = px.data.gapminder()\n\n# 绘制加入动画效果的散点图，展示随时间变化的散点图走势\nfig = px.scatter(df, x=\"gdpPercap\", y=\"lifeExp\", \n                 animation_frame=\"year\", animation_group=\"country\",\n                 size=\"pop\", color=\"continent\", hover_name=\"country\",\n                 log_x=True, size_max=55, range_x=[100,100000], range_y=[25,90])\n# update_layout定制图表布局\n# legend参数设置图表的图例位置和样式\nfig.update_layout(\n    # x=1表示右，y=1表示上，图例显示在右上角，背景色为白色，边框黑色且宽度为1\n    legend=dict(x=1, y=1, bgcolor='white', bordercolor='black', borderwidth=1)\n)\n\n# 显示图表\nfig.show(renderer=\"notebook\")"
  },
  {
    "objectID": "动态图表.html#滑块和dropdown选择器",
    "href": "动态图表.html#滑块和dropdown选择器",
    "title": "15  高阶图表",
    "section": "滑块和dropdown选择器",
    "text": "滑块和dropdown选择器\n\nslider滑块\n\nimport plotly.express as px\n\ndf = px.data.gapminder()\nfig = px.scatter(df, x=\"gdpPercap\", y=\"lifeExp\", animation_frame=\"year\", animation_group=\"country\",\n           size=\"pop\", color=\"continent\", hover_name=\"country\",\n           log_x=True, size_max=55, range_x=[100,100000], range_y=[25,90])\n\nfig[\"layout\"].pop(\"updatemenus\") # 省去动画的播放按钮\nfig.show(renderer=\"notebook\")\n\n\n                                                \n\n\n\n\nDropdown下拉菜单（仅作了解）\n\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\n# 示例数据\nyears = [2010, 2011, 2012, 2013, 2014]\nsales = [100, 150, 200, 180, 250]\nprice = [10, 12, 15, 18, 20]\n\n# 创建图表\nfig = go.Figure()\n\n# 添加销售额折线图，不可见\nfig.add_trace(go.Scatter(x=years, y=sales, mode='lines+markers', name='Sales', visible=True))\n\n# 添加价格折线图，默认可见\nfig.add_trace(go.Scatter(x=years, y=price, mode='lines+markers', name='Price', visible=False))\n\n# 设置布局\nfig.update_layout(title='Sales and Price over Time',\n                  xaxis_title='Year',\n                  yaxis_title='Value'\n                  )\n\n# 添加 Dropdown 组件\nfig.update_layout(\n    updatemenus=[\n        dict(\n            buttons=list([\n                dict(\n                    args=[{'visible': [True, False]}],\n                    label='Sales',\n                    method='update'\n                ),\n                dict(\n                    args=[{'visible': [False, True]}],\n                    label='Price',\n                    method='update'\n                )\n            ]),\n            direction='down',\n            showactive=True,\n            x=0.1,\n            xanchor='left',\n            y=1.1,\n            yanchor='top'\n        ),\n    ]\n)\n\n# 显示图表\nfig.show(renderer=\"notebook\")"
  },
  {
    "objectID": "动态图表.html#数据的分组聚合-groupby和agg",
    "href": "动态图表.html#数据的分组聚合-groupby和agg",
    "title": "15  高阶图表",
    "section": "数据的分组聚合: groupby()和agg()",
    "text": "数据的分组聚合: groupby()和agg()\n使用groupby()和agg()实现数据的分组聚合：\n\nimport plotly.express as px\nimport pandas as pd\n\n# 示例数据\ndata = {\n    'Category': ['A', 'B', 'A', 'B', 'A', 'B'],\n    'Value': [10, 15, 20, 25, 30, 35]\n}\ndf = pd.DataFrame(data)\n\n# 嵌套使用 groupby 和 agg 进行数据分组和聚合\ngrouped_data = df.groupby('Category').agg({'Value': 'mean'}).reset_index()\n\n# 使用 Plotly 绘制条形图\nfig = px.bar(grouped_data, x='Category', y='Value', title='Category Average')\nfig.show(renderer=\"notebook\")"
  },
  {
    "objectID": "动态图表.html#数据转换-filtergroupbyaggregate",
    "href": "动态图表.html#数据转换-filtergroupbyaggregate",
    "title": "15  高阶图表",
    "section": "数据转换: Filter/Groupby/Aggregate",
    "text": "数据转换: Filter/Groupby/Aggregate\nPlotly中有一种Transform可以对数据进行转换处理，通过transform可以实现对数据的筛选过滤filter、分组groupby、聚合aggregate操作。\n请查看下面的示例代码和图表。\n\nFilter\n\nimport plotly.io as pio\n\nstudent = ['Amy', 'Laura', 'Lisa', 'Amy', 'Laura', 'Lisa', 'Laura', 'Lisa', 'Amy']\nscore = [77, 88, 99, 87, 76, 65, 78, 89, 90]\n# 使用 dict() 定义一个散点图的数据字典列表 data。\n# data 中包含一个字典，其中定义了散点图的数据属性。\ndata = [dict(\n  type = 'scatter', \n  # 指定x轴和y轴\n  x = student, \n  y = score,\n  # mode 参数用于控制绘制散点图时标记的形状。\n  # markers:圆点。'lines':折线,'lines+markers':圆点+折线,'text'：显示文本标签。\n  mode = 'markers',\n  transforms = [dict(\n    type = 'filter',  # 'filter'表示筛选过滤，'groupby'表示分组，'aggregate'表示聚合\n    target = 'y',     # 数据转换filter的目标对象为y\n    operation = '&gt;',  # 过滤条件：&gt;\n    value = 80        # 过滤条件临界值：80\n  )]\n)]\n\nlayout = dict(\n    title = 'Scores &gt; 80'\n)\n\nfig_dict = dict(data=data, layout=layout)\n# validate=False表示无需验证数据，直接输出图像\npio.show(fig_dict, validate=False, renderer=\"notebook\")\n\n                                                \n\n\n\n\nGroupby\n\nimport plotly.io as pio\n\nstudent = ['Amy', 'Laura', 'Lisa', 'Amy', 'Laura', 'Lisa', 'Laura', 'Lisa', 'Amy']\nscore = [77, 88, 99, 87, 76, 65, 78, 89, 90]\n\ndata = [dict(\n  type = 'scatter', \n  x = student, \n  y = score,\n  mode = 'markers',\n  transforms = [dict(\n    type = 'groupby',  \n    groups = student,  # 以不同学生来分组\n    # styles: 样式列表，其中包含不同学生的样式设置，这里显示为特定的不同颜色\n    styles = [\n        dict(target = 'Amy', value = dict(marker = dict(color = 'blue'))),\n        dict(target = 'Laura', value = dict(marker = dict(color = 'red'))),\n        dict(target = 'Lisa', value = dict(marker = dict(color = 'black')))\n    ]\n  )]\n)]\n\nfig_dict = dict(data=data)\npio.show(fig_dict, validate=False, renderer=\"notebook\")\n\n                                                \n\n\n\n\nAggregate\n\ncount: 数量。\nsum: 总和。\navg: 平均值。\nmedian: 中位数。\nmode: 众数。\nrms: 均方根。\nstddev: 标准差。\nmin: 最小值。\nmax: 最大值。\nfirst: 第一个值。\nlast: 最后一个值。\n\n\nimport plotly.io as pio\n\nstudent = ['Amy', 'Laura', 'Lisa', 'Amy', 'Laura', 'Lisa', 'Laura', 'Lisa', 'Amy']\nscore = [77, 88, 99, 87, 76, 65, 78, 89, 90]\n\ndata = [dict(\n  type = 'scatter', \n  x = student, \n  y = score,\n  mode = 'markers',\n  transforms = [dict(\n    type = 'aggregate',\n    groups = student,\n    aggregations = [dict(\n        # 聚合的目标对象:y, 聚合结果：返回平均值。\n        target = 'y', func = 'avg', enabled = True),\n    ]\n  )]\n)]\n\nlayout = dict(\n    title = 'Average Score'\n)\nfig_dict = dict(data=data, layout=layout)\npio.show(fig_dict, validate=False, renderer=\"notebook\")"
  },
  {
    "objectID": "地图可视化.html#地图可视化概念",
    "href": "地图可视化.html#地图可视化概念",
    "title": "16  Plotly地图可视化",
    "section": "地图可视化概念",
    "text": "地图可视化概念\n地图可视化是数据可视化的一种重要形式，它将数据以地理位置为基础进行可视化展示。通过地图可视化，我们可以直观地看到数据在地理空间上的分布、趋势和关联关系，帮助我们更好地理解数据所在的空间背景和地理特征。\n使用 Plotly Express 和地图可视化，我们可以：\n\n绘制各种类型的地图图表，包括气泡图、散点地图、连线地图、热力图、区域地图等，展示不同类型的地理数据。\n添加交互功能，如鼠标悬停显示数据信息、缩放、拖动和动画效果，使图表更具交互性和可操作性。\n自定义图表样式和主题，使图表更符合项目需求和品牌风格。\n结合其他 Python 数据处理库，如 Pandas，进行数据准备和处理，从而更方便地生成可视化图表。\n\n更高阶的地图可视化，还能和其他图表一起组合成为数据大屏，搭配Dash做到类似以下的效果"
  },
  {
    "objectID": "地图可视化.html#地图数据结构",
    "href": "地图可视化.html#地图数据结构",
    "title": "16  Plotly地图可视化",
    "section": "地图数据结构",
    "text": "地图数据结构\n相较于其他数据，地理位置的数据结构略微有些不同，地图可视化通常需要使用经纬度坐标或地理编码来表示地理位置，以及其他与地理位置相关的属性数据。通常数据文件格式为.SHP或者.GeoJSON这类的矢量GIS文件格式。详细请看地理数据格式介绍\n常见的地图数据结构可以是以下两种：\n\n点数据结构：这种数据结构用于表示地图上的散点数据，每个数据点都有一个经纬度坐标和其他属性数据。每个数据点在地图上呈现为一个点，可以用来标记地理位置或展示某个属性值在地图上的分布。\n区域数据结构：这种数据结构用于表示地图上的区域数据，如国家、城市、行政区等，每个区域有一个地理边界和其他属性数据。区域数据可以用来绘制地图上的色块或边界，表示不同地区的属性值。\n\n\n# 创建点数据结构\n点数据结构 = {\n    'City': ['New York', 'Paris', 'Tokyo', 'Beijing', 'London'],\n    'Lat': [40.7128, 48.8566, 35.6895, 39.9042, 51.5074],\n    'Lon': [-74.0060, 2.3522, 139.6917, 116.4074, -0.1278],\n    'Population': [8398748, 2140526, 37393129, 21705000, 8982000]\n}\n\n\n# 创建区域数据结构\n区域数据结构 = {\n    'Country': ['United States', 'Canada', 'France', 'Japan', 'China'],\n    'Coordinates': [\n        [[-125, 50], [-65, 50], [-65, 25], [-125, 25]],     # 美国边界坐标\n        [[-140, 72], [-55, 72], [-55, 40], [-140, 40]],     # 加拿大边界坐标\n        [[-5, 52], [9, 52], [9, 42], [-5, 42]],             # 法国边界坐标\n        [[129, 45], [149, 45], [149, 25], [129, 25]],       # 日本边界坐标\n        [[73, 53], [135, 53], [135, 18], [73, 18]]          # 中国边界坐标\n    ]\n}"
  },
  {
    "objectID": "地图可视化.html#使用-plotly-express-绘制散点地图",
    "href": "地图可视化.html#使用-plotly-express-绘制散点地图",
    "title": "16  Plotly地图可视化",
    "section": "使用 Plotly Express 绘制散点地图",
    "text": "使用 Plotly Express 绘制散点地图\nPlotly Express 中，可以使用 px.scatter_geo 来绘制散点地图。px.scatter_geo()参数介绍 以及官方案例\n下面为官方给出的数据案例：所有官方数据集\n\n从plotly官方提供的示例数据集中提取gapminder，包含了世界各国在不同年份的一些经济指标，如国家/地区、年份、人口数量、GDP、预期寿命等信息。\n\n\n# 导入plotly.express库\nimport plotly.express as px\n\ndf = px.data.gapminder()\ndf \n\n\n\n\n\n\n\n\ncountry\ncontinent\nyear\nlifeExp\npop\ngdpPercap\niso_alpha\niso_num\n\n\n\n\n0\nAfghanistan\nAsia\n1952\n28.801\n8425333\n779.445314\nAFG\n4\n\n\n1\nAfghanistan\nAsia\n1957\n30.332\n9240934\n820.853030\nAFG\n4\n\n\n2\nAfghanistan\nAsia\n1962\n31.997\n10267083\n853.100710\nAFG\n4\n\n\n3\nAfghanistan\nAsia\n1967\n34.020\n11537966\n836.197138\nAFG\n4\n\n\n4\nAfghanistan\nAsia\n1972\n36.088\n13079460\n739.981106\nAFG\n4\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n1699\nZimbabwe\nAfrica\n1987\n62.351\n9216418\n706.157306\nZWE\n716\n\n\n1700\nZimbabwe\nAfrica\n1992\n60.377\n10704340\n693.420786\nZWE\n716\n\n\n1701\nZimbabwe\nAfrica\n1997\n46.809\n11404948\n792.449960\nZWE\n716\n\n\n1702\nZimbabwe\nAfrica\n2002\n39.989\n11926563\n672.038623\nZWE\n716\n\n\n1703\nZimbabwe\nAfrica\n2007\n43.487\n12311143\n469.709298\nZWE\n716\n\n\n\n\n1704 rows × 8 columns\n\n\n\n\n因为散点图不适合制作时间序列相关数据，所以需要筛选年份为某一年，这里筛选为2007年的数据。\n\n\n# 筛选出年份等于2007年的数据。 df = px.data.gapminder().query(\"year == 2007\")\ndf = df[df[\"year\"] == 2007].head()\ndf\n\n\n\n\n\n\n\n\ncountry\ncontinent\nyear\nlifeExp\npop\ngdpPercap\niso_alpha\niso_num\n\n\n\n\n11\nAfghanistan\nAsia\n2007\n43.828\n31889923\n974.580338\nAFG\n4\n\n\n23\nAlbania\nEurope\n2007\n76.423\n3600523\n5937.029526\nALB\n8\n\n\n35\nAlgeria\nAfrica\n2007\n72.301\n33333216\n6223.367465\nDZA\n12\n\n\n47\nAngola\nAfrica\n2007\n42.731\n12420476\n4797.231267\nAGO\n24\n\n\n59\nArgentina\nAmericas\n2007\n75.320\n40301927\n12779.379640\nARG\n32\n\n\n\n\n\n\n\n\n数据准备好后，使用px.scatter_geo绘图。通常设置变量为fig。\n\n主要参数介绍：\n\ndata_frame：要绘制的数据的DataFrame，也就是变量df，其中必须包含地理信息，如经度（lon）和纬度（lat）。\nlocations 表示地图上要标记的位置，可以是国家、城市或其他地理位置的标识。\nsize：指定散点的大小。可以是一个具体的大小值，也可以是与数据列关联的列名，用于根据数据的值自动调整散点大小。\n\n\n\n\n\n\n\nNote\n\n\n\nISO 2字母代码通常被称为 ISO Alpha-2 代码。它是一个国家/地区的两个大写字母的缩写，能够快速标识和表示该国家/地区。例如，中国的 ISO Alpha-2 代码是 “CN”，美国的代码是 “US”，英国的代码是 “GB” 等。\n\n\n\nfig = px.scatter_geo(data_frame=df, \n                     locations=\"iso_alpha\", # 指定地理位置的ISO 2字母国家/地区代码所在的列名，定位散点在地图上的位置。\n                     size=\"pop\", # 指定散点的大小所在的列名，根据人口数量调整散点的大小。\n                     )\nfig.show(renderer=\"notebook\") # 显示绘制的地理散点图。\n\n\n                                                \n\n\n\n绘制气泡地图\n气泡图是散点图的升级版，通常会在原有基础上增加了另一个数据维度，通常用散点的大小或颜色来表示该维度的数据。每个数据点仍用一个散点来表示其地理位置，但通过调整散点的大小或颜色，可以同时显示第二个数据维度的信息。例如地理位置与人口数量或销售额之间的关系。\n同样使用上面筛选过后的2007年的世界经济数据，展示各个国家的地理位置，并用不同颜色表示它们所属的大洲，通过数据点的大小表示国家的人口数量。官方案例\n主要参数介绍：\n\ncolor: 字符串或列名，用于给散点图的数据点着色。\nhover_name: 字符串或列名，表示当鼠标悬停在数据点上时，显示在悬停提示框中的文本。\nprojection: 字符串，表示地图投影的类型。\n\n\n\n\n\n\n\nNote\n\n\n\n通过设置 projection 参数，可以选择合适的地图投影方式，以满足不同地理数据可视化需求。可以尝试下不同方式。默认为equirectangular经纬度投影，其他projection请参考官方文档\n\n\n\nfig = px.scatter_geo(data_frame=df, \n                     locations=\"iso_alpha\", \n                     size=\"pop\", \n                     color=\"continent\", # \"continent\"表示每个国家所在的大洲，将用于给数据点按照所属大洲进行着色。\n                     hover_name=\"country\", # \"country\"表示每个数据点所对应的国家名称，将显示在悬停提示框中。\n                     projection=\"natural earth\") # \"natural earth\"表示使用自然地球投影，即将地球投影到二维平面上。可以进行上下左右拖拽\nfig.show(renderer=\"notebook\")"
  },
  {
    "objectID": "地图可视化.html#使用-plotly-express-绘制着色地图",
    "href": "地图可视化.html#使用-plotly-express-绘制着色地图",
    "title": "16  Plotly地图可视化",
    "section": "使用 Plotly Express 绘制着色地图",
    "text": "使用 Plotly Express 绘制着色地图\n着色地图(Choropleth map)是一种用颜色来表示不同地理区域数据值的地图类型。在 Choropleth map 中，地图的每个区域（例如国家、州、县等）都被着色，颜色的深浅表示该区域的数据值大小或密度。这种地图可以帮助我们直观地看出不同地区之间的数据差异或分布情况，从而更好地理解地理数据的特征。详情请看官方案例\n着色地图的主要数据结构\n需要两种主要输入方式：\n\n几何信息： 可以是一个提供的 GeoJSON 文件，其中每个特征都有一个 id 字段或属性中的一些识别值；或 plotly 内置的几何图形之一：美国各州和世界各国（见下文）\n按特征标识符索引的值列表： GeoJSON 数据会传入 geojson 参数，数据会传入 px.choropleth 的颜色参数，顺序与传入 location 参数的 ID 相同。\n\n\n\n\n\n\n\nNote\n\n\n\n请注意，geojson 属性也可以是 GeoJSON 文件的 URL，这在某些情况下可以加快地图渲染速度。\n\n\n\n读取地理数据\n这里我们加载一个 GeoJSON 文件，其中包含美国各县的几何信息，其中feature.id是FIPS 代码。\n\nfrom urllib.request import urlopen\nimport json\nwith urlopen('https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json') as response:\n    counties = json.load(response)\n\ncounties[\"features\"][0]\n\n{'type': 'Feature',\n 'properties': {'GEO_ID': '0500000US01001',\n  'STATE': '01',\n  'COUNTY': '001',\n  'NAME': 'Autauga',\n  'LSAD': 'County',\n  'CENSUSAREA': 594.436},\n 'geometry': {'type': 'Polygon',\n  'coordinates': [[[-86.496774, 32.344437],\n    [-86.717897, 32.402814],\n    [-86.814912, 32.340803],\n    [-86.890581, 32.502974],\n    [-86.917595, 32.664169],\n    [-86.71339, 32.661732],\n    [-86.714219, 32.705694],\n    [-86.413116, 32.707386],\n    [-86.411172, 32.409937],\n    [-86.496774, 32.344437]]]},\n 'id': '01001'}\n\n\n这里我们按县 和 FIPS 代码索引，加载失业数据，注意上面的是json文件，这个是csv文件\n\nimport pandas as pd\ndf = pd.read_csv(\"https://raw.githubusercontent.com/plotly/datasets/master/fips-unemp-16.csv\",\n                   dtype={\"fips\": str})\ndf.head()\n\n\n\n\n\n\n\n\nfips\nunemp\n\n\n\n\n0\n01001\n5.3\n\n\n1\n01003\n5.4\n\n\n2\n01005\n8.6\n\n\n3\n01007\n6.6\n\n\n4\n01009\n5.5\n\n\n\n\n\n\n\n\n\n使用 GeoJSON 绘制着色地图\n注意 在本例中，我们将 layout.geo.scope 设置为 USA，以便自动配置地图，以适当的投影显示以美国为中心的数据。有关范围的更多信息，请参阅 Geo 地图配置文档。\n\n主要参数介绍\n\ngeojson: 这是一个包含地理区域边界信息的 GeoJSON 数据，用于在地图上绘制各个区域的形状。如果不指定该参数，Plotly Express 会自动下载所需的 GeoJSON 数据。\nlocations: 这是一个字符串，表示 DataFrame 中的列名，它与 geojson 中的区域标识符（例如 FIPS 码）进行匹配，以正确地将数据绘制到地图上的各个区域。\ncolor: 这是一个字符串，表示 DataFrame 中的列名，用于表示每个地理区域的颜色深浅。通常，它是一个连续数值型列，例如失业率或人口数量。\ncolor_continuous_scale: 这是一个字符串，表示用于表示颜色深浅的连续色标尺。你可以选择内置的颜色映射，例如 \"Viridis\"、\"Cividis\"、\"Plasma\" 等，也可以指定自定义的颜色映射。\nrange_color: 这是一个元组，表示颜色映射的取值范围。它用于将数据值映射为颜色深浅的范围。（可作颜色渐变地图）\nscope: 这是一个字符串，表示绘制的地理范围。常用的值包括 “world”（绘制全球地图）、“usa”（绘制美国地图）等。\nlabels: 这是一个字典，用于设置图例的标签。\ntitle: 这是一个字符串，表示图表的标题。\n\n\nimport plotly.express as px\n\nfig = px.choropleth(df, geojson=counties, # 包含各县边界信息的 GeoJSON 文件，用于绘制地图区域\n                        locations='fips', # 表示地图区域的唯一标识符，这里使用数据中的 'fips' 列\n                        color='unemp',    # 表示用于颜色填充的数值，这里使用数据中的 'unemp' 列\n                        color_continuous_scale=\"Viridis\", # 设置颜色范围\n                        range_color=(0, 12),              # 设置颜色范围\n                        scope=\"usa\",                      # 设置地图范围\n                        labels={'unemp':'失业率'},         # 设置标签\n                        title=\"美国失业率\"                  # 设置标题\n                          )\nfig.update_layout(margin={\"r\":50,\"t\":50,\"l\":50,\"b\":50})     # 修改整体布局，通过设置各个边缘的边距值为 0，将图表与绘图区域的边缘对齐，使图表填充整个绘图区域。\nfig.show(renderer='notebook')\n\n\n                                                \n\n\n\n\n\n绘制美国城市人口地图\nPlotly 支持两种不同类型的地图：\n地理地图: 是基于轮廓的地图。如果您的图层是使用px.scatter_geo,px.line_geo或px.choropleth函数创建的，或者以其他方式包含一个或多个类型go.Scattergeo或的trace_go.Choropleth，则layout.geo图层中的对象包含地图本身的配置信息。\nMapbox: 地图是基于图块的地图。如果您的图层是使用px.scatter_mapbox, px.line_mapbox,px.choropleth_mapbox或px.density_mapbox函数创建的，或者以其他方式包含一个或多个类型go.Scattermapbox, 或的trace_go.Choroplethmapbox，则图层中的go.Densitymapbox对象layout.mapbox包含地图本身的配置信息。Mapbox图层文档，使用Mapbox可以获得更加精细化的地图样式。 详情请看，Mapbox散点图\n\n# 读取美国城市人口数据\nimport pandas as pd\nus_cities = pd.read_csv(\"https://raw.githubusercontent.com/plotly/datasets/master/us-cities-top-1k.csv\")\nus_cities.head()\n\n\n\n\n\n\n\n\nCity\nState\nPopulation\nlat\nlon\n\n\n\n\n0\nMarysville\nWashington\n63269\n48.051764\n-122.177082\n\n\n1\nPerris\nCalifornia\n72326\n33.782519\n-117.228648\n\n\n2\nCleveland\nOhio\n390113\n41.499320\n-81.694361\n\n\n3\nWorcester\nMassachusetts\n182544\n42.262593\n-71.802293\n\n\n4\nColumbia\nSouth Carolina\n133358\n34.000710\n-81.034814\n\n\n\n\n\n\n\n\nfig = px.scatter_mapbox(us_cities, lat=\"lat\", lon=\"lon\", hover_name=\"City\", hover_data=[\"State\", \"Population\"],\n                        color_discrete_sequence=[\"fuchsia\"], zoom=3, height=300)\nfig.update_layout(\n    mapbox_style=\"white-bg\",\n    mapbox_layers=[\n        {\n            \"below\": 'traces',\n            \"sourcetype\": \"raster\",\n            \"sourceattribution\": \"United States Geological Survey\",\n            \"source\": [\n                \"https://basemap.nationalmap.gov/arcgis/rest/services/USGSImageryOnly/MapServer/tile/{z}/{y}/{x}\"\n            ]\n        }\n      ])\nfig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\nfig.show(renderer='notebook')"
  },
  {
    "objectID": "地图可视化.html#使用-plotly-express-绘制热力地图",
    "href": "地图可视化.html#使用-plotly-express-绘制热力地图",
    "title": "16  Plotly地图可视化",
    "section": "使用 Plotly Express 绘制热力地图",
    "text": "使用 Plotly Express 绘制热力地图\n热力图（Heatmap）又称密度图，是一种二维数据可视化技术，通过使用颜色编码来展示数据矩阵中每个数据点的大小，从而直观地呈现数据的分布和模式。例如温度分布，可以展示不同地理位置的温度分布情况，通过色彩的变化直观显示不同地区的温度高低。或者城市规划，可以用于显示人流、交通流等信息，帮助优化城市交通和设施布局。亦或者金融分析，用于分析股票和证券市场的相关性，揭示不同股票之间的关联程度。\n给定一个带坐标的数据帧，并为每个点赋值，就可以用 plotly 在 Python 中创建动态空间热图。为此，可以使用 plotly express 中的 density_mapbox 函数。这种图表对于可视化不同类型的数据（如人口数据、电话信号数据、道路拥堵情况等）\n以下为地震热力地图，可以更直观地了解地震的发生地点和震级情况，帮助我们分析地震的分布和规律。\n\n读取地震数据\n\n\n# 读取地震数据\nimport pandas as pd\ndf = pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/earthquakes-23k.csv')\ndf.head()\n\n\n\n\n\n\n\n\nDate\nLatitude\nLongitude\nMagnitude\n\n\n\n\n0\n01/02/1965\n19.246\n145.616\n6.0\n\n\n1\n01/04/1965\n1.863\n127.352\n5.8\n\n\n2\n01/05/1965\n-20.579\n-173.972\n6.2\n\n\n3\n01/08/1965\n-59.076\n-23.557\n5.8\n\n\n4\n01/09/1965\n11.938\n126.427\n5.8\n\n\n\n\n\n\n\n\n主要参数介绍\n详细Mapbox style地图参数设置\n\nlat和lon：分别指定数据框中代表纬度和经度的列名。这些列将决定数据点在地图上的位置。\nz：代表颜色强度的数值列。密度地图将使用该列的数值来表示数据点的密度。\nradius：设置聚合的半径大小。较小的半径将显示更细致的细节，而较大的半径将显示更广泛的数据趋势。\ncenter：用于设置地图的中心位置，是一个字典，包含lat和lon两个键，分别对应中心点的纬度和经度。\nzoom：设置地图的缩放级别，用于调整地图的显示范围。\nmapbox_style：设置地图的样式，可以选择不同的预定义地图样式，如”open-street-map”、“carto-positron”等。\n\n\nimport plotly.express as px\nfig = px.density_mapbox(df, # 地震数据集（必需参数）\n                        lat='Latitude',  # 维度列（必需参数）\n                        lon='Longitude', # 经度列（必需参数）\n                        z='Magnitude',   # 地震值（必需参数）其颜色会根据数据值的大小而变化。\n                        radius=10,       # 调整地图上数据点的大小\n                        center=dict(lat=0, lon=90), # 表示地图的中心坐标。默认为dict(lat=0, lon=180)，表示地图的中心位于纬度0，经度18的位置。\n                        zoom=1, # 表示地图的缩放级别。默认为0，表示地图显示全球范围。\n                        mapbox_style=\"stamen-terrain\") # 表示地图的样式。默认为\"open-street-map\"，还可以选择\"stamen-terrain\"、\"carto-positron\"等不同的样式。\n                        \nfig.show(renderer='notebook')"
  },
  {
    "objectID": "地图可视化.html#下拉菜单仅作了解",
    "href": "地图可视化.html#下拉菜单仅作了解",
    "title": "16  Plotly地图可视化",
    "section": "下拉菜单（仅作了解）",
    "text": "下拉菜单（仅作了解）\n通过创建一个下拉菜单来更改不同变量之间的绘制值（例如，预期寿命、GDP、人口） 详细可见官方文档以及下述代码块中的注释\n\n读取数据 是哟哦那个gapminder数据，并指定为2007年。\n\n最后创建了一个字符串列表cols_dd，其中包含了三个绘制值的名称：Population、GDP per Capita和Life Expectancy。\n\nimport pandas as pd\nimport numpy as np\nimport plotly.graph_objs as go\nimport plotly.express as px\n\n# 读取数据\ndf = px.data.gapminder().query(\"year==2007\")\ndf = df.rename(columns=dict(pop=\"Population\",\n                            gdpPercap=\"GDP per Capita\",\n                            lifeExp=\"Life Expectancy\"))\ncols_dd = [\"Population\", \"GDP per Capita\", \"Life Expectancy\"]\n\n\n绘制地图和下拉菜单\n\n通过遍历cols_dd中的绘制值名称，分别创建钻取地图的绘制值对象和按钮对象，然后将按钮对象放入updatemenus列表中。最后，使用这些对象来创建go.Figure，实现在钻取地图中切换不同绘制值的功能。\n\n\n\n# 定义了一个visible数组，用于指示哪个绘制值在初始情况下可见。\nvisible = np.array(cols_dd)\n\n# 分别创建一个空列表traces和buttons，用于存储后续创建的绘制值对象和按钮对象。\ntraces = []\nbuttons = []\n\nfor value in cols_dd: # 遍历cols_dd列表中的每个绘制值。\n    traces.append(go.Choropleth( # 代表一个钻取地图\n       locations=df['iso_alpha'], # 空间坐标\n        z=df[value].astype(float), # 数据用彩色编码\n        colorbar_title=value,\n        visible= True if value==cols_dd[0] else False)) # 根据当前遍历到的绘制值是否为初始值（cols_dd[0]）来决定是否可见。\n\n# 创建一个按钮对象，用于切换可见性\n    buttons.append(dict(label=value, # 显示的文本\n                        method=\"update\", # 指定了按钮的行为\n                        args=[{\"visible\":list(visible==value)}, # 按钮点击后执行的操作，包括设置可见性和更改标题。\n                              {\"title\":f\"&lt;b&gt;{value}&lt;/b&gt;\"}]))\n\n# 创建一个包含按钮对象的updatemenus列表，用于实现下拉菜单。active参数指定了初始时激活的按钮索引。\nupdatemenus = [{\"active\":0,\n                \"buttons\":buttons,\n               }]  \n  \n\n# 创建一个go.Figure对象\nfig = go.Figure(data=traces,  # 指定了绘制值对象的列表traces\n                layout=dict(updatemenus=updatemenus)) # 指定了图表的布局，其中updatemenus用于添加下拉菜单\n\n# 将cols_dd列表中的第一个绘制值名称赋值给变量first_title\nfirst_title = cols_dd[0]\nfig.update_layout(title=f\"&lt;b&gt;{first_title}&lt;/b&gt;\",title_x=0.5) #  更新图表的布局，其中title参数设置图表标题，title_x参数设置标题在X轴方向上的位置。\nfig.show(renderer='notebook')"
  },
  {
    "objectID": "for循环.html#为什么需要使用for循环",
    "href": "for循环.html#为什么需要使用for循环",
    "title": "17  for循环自动获取股票数据",
    "section": "为什么需要使用for循环？",
    "text": "为什么需要使用for循环？\nfor循环简化了操作、处理大量数据，自动化了重复任务，并提供灵活的遍历顺序。它是一种强大的编程工具，帮助我们优化效率、减少冗余代码。无论初学者还是经验丰富的开发人员，for循环都是不可或缺的技术，提升代码质量、处理数据轻而易举。"
  },
  {
    "objectID": "for循环.html#案例背景",
    "href": "for循环.html#案例背景",
    "title": "17  for循环自动获取股票数据",
    "section": "案例背景",
    "text": "案例背景\n使用for循环调用股票API Tushare获取日线行情。但是有限制调用页数。尝试使用for循环遍历列表，逐个发送API请求获取每只股票的日线行情数据。"
  },
  {
    "objectID": "for循环.html#操作步骤",
    "href": "for循环.html#操作步骤",
    "title": "17  for循环自动获取股票数据",
    "section": "操作步骤",
    "text": "操作步骤\n\n通过def定义函数\nfor循环遍历整个日线行情\nconcat合并上下表"
  },
  {
    "objectID": "python链接数据库.html#为什么要用sqlalchemy连接数据库",
    "href": "python链接数据库.html#为什么要用sqlalchemy连接数据库",
    "title": "18  Python连接Postgresql数据库",
    "section": "为什么要用SQLAlchemy连接数据库？",
    "text": "为什么要用SQLAlchemy连接数据库？\n在企业中，很多数据都存储在数据库当中，通过SQLAlchemy，可以轻松连接多种数据库，包括MySQL、PostgreSQL、SQLite等，并使用统一的API进行数据库操作。SQLAlchemy提供了高级的对象关系映射（ORM）功能，使数据库操作更加面向对象，简化了数据模型的开发和管理。它提供了查询构建器、事务管理、数据迁移等功能，提高了开发效率。"
  },
  {
    "objectID": "python链接数据库.html#所需环境和拓展包",
    "href": "python链接数据库.html#所需环境和拓展包",
    "title": "18  Python连接Postgresql数据库",
    "section": "所需环境和拓展包",
    "text": "所需环境和拓展包\n\njupyternotebook – 撰写python代码\nPostgreSQL & Pgadmin4 – 数据库及其GUI工具（数据库客户端）\nSQLAlchemy – python拓展包，用来连接数据库"
  },
  {
    "objectID": "python链接数据库.html#操作步骤",
    "href": "python链接数据库.html#操作步骤",
    "title": "18  Python连接Postgresql数据库",
    "section": "操作步骤",
    "text": "操作步骤\n\nDocker安装jupyternotebook & Postgresql数据库\n本地数据库备份&迁移\n安装和使用SqlAlechemy"
  },
  {
    "objectID": "Dash案例.html#为什么要使用dash",
    "href": "Dash案例.html#为什么要使用dash",
    "title": "19  Dash创建股票APP",
    "section": "为什么要使用Dash",
    "text": "为什么要使用Dash\nDash Plotly是一个基于Python的开源框架，用于构建交互式数据可视化和分析应用。\n它的优势在于简洁的语法、强大的可视化功能和灵活的布局选项。通过使用Dash Plotly，您可以轻松创建漂亮、交互式的应用程序，展示和探索数据，无论是用于内部报告、数据分析还是对外展示。它提供了丰富的图表类型、注解和样式设置，以及与其他Python库的无缝集成，如pandas和numpy。Dash Plotly还支持部署到Web服务器上，使得应用程序能够通过浏览器进行访问和共享。\n总的来说，Dash Plotly提供了一种简单而强大的方式来创建数据驱动的应用程序，使得数据可视化和交互变得更加容易和高效。"
  },
  {
    "objectID": "Dash案例.html#案例背景",
    "href": "Dash案例.html#案例背景",
    "title": "19  Dash创建股票APP",
    "section": "案例背景",
    "text": "案例背景\n使用Dash 模仿复现股票走势的交互可视化面板，可以查看股票日线级别的涨跌幅度、股票走势和买入卖出盈亏比。以英伟达股票为案例"
  },
  {
    "objectID": "Dash案例.html#相关链接",
    "href": "Dash案例.html#相关链接",
    "title": "19  Dash创建股票APP",
    "section": "相关链接",
    "text": "相关链接\n免费股票数据API\nGitHub Python调用API\n模仿案例网站"
  },
  {
    "objectID": "Dash案例.html#dash股票案例上集",
    "href": "Dash案例.html#dash股票案例上集",
    "title": "19  Dash创建股票APP",
    "section": "Dash股票案例（上集）",
    "text": "Dash股票案例（上集）\n\nAPI获取&调用\npands数据清洗\n导出csv到本地\nDash-Bootstrap主题\nDash-layout排版\nDash-调整位置和宽度"
  },
  {
    "objectID": "Dash案例.html#dash股票案例下集",
    "href": "Dash案例.html#dash股票案例下集",
    "title": "19  Dash创建股票APP",
    "section": "Dash股票案例（下集）",
    "text": "Dash股票案例（下集）\n\napp功能：涨跌百分比\npadnas数据清洗&过滤\nplotly绘制百分比图\napp功能：股票走势图\nupdate_traces VS update_layout\napp功能：滚动数据\nBootstrap组件使用"
  }
]